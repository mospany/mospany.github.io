<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>墨斯潘園 on 墨斯潘園</title>
        <link>http://mospany.github.io/</link>
        <language>zh-CN</language>
        <author>Mospan</author>
        <rights>Copyright (c) 2016, mospan; all rights reserved.</rights>
        <updated>Sat, 02 Aug 2025 15:44:09 CST</updated>
        
        <item>
            <title>Python基础与速查手册</title>
            <link>http://mospany.github.io/2025/08/02/python-in-ai/</link>
            <pubDate>Sat, 02 Aug 2025 15:44:09 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2025/08/02/python-in-ai/</guid>
            <description>

&lt;h2 id=&#34;一-基础语法速查&#34;&gt;🧠 一、基础语法速查&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;语法&lt;/th&gt;
&lt;th&gt;示例&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;变量定义&lt;/td&gt;
&lt;td&gt;&lt;code&gt;x = 10&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;不需要声明类型&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;条件语句&lt;/td&gt;
&lt;td&gt;&lt;code&gt;if x &amp;gt; 0: ... elif x==0: ... else: ...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;结构清晰&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;循环&lt;/td&gt;
&lt;td&gt;&lt;code&gt;for i in range(10):&lt;/code&gt;&lt;br&gt;&lt;code&gt;while x &amp;lt; 5:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;遍历/条件循环&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;函数定义&lt;/td&gt;
&lt;td&gt;&lt;code&gt;def func(a, b=1): return a + b&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;默认参数、返回值&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;列表推导式&lt;/td&gt;
&lt;td&gt;&lt;code&gt;[x**2 for x in range(5)]&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;快速生成新列表&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;多变量赋值&lt;/td&gt;
&lt;td&gt;&lt;code&gt;a, b = 1, 2&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;解包&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;类型注解&lt;/td&gt;
&lt;td&gt;&lt;code&gt;def add(x: int) -&amp;gt; int:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;函数签名更清晰&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;二-常用数据结构函数&#34;&gt;🧰 二、常用数据结构函数&lt;/h2&gt;

&lt;h3 id=&#34;字符串-str&#34;&gt;字符串 &lt;code&gt;str&lt;/code&gt;&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;函数&lt;/th&gt;
&lt;th&gt;示例&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;s.lower()&lt;/code&gt; / &lt;code&gt;s.upper()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;大小写转换&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;s.split(&#39;,&#39;)&lt;/code&gt; / &lt;code&gt;&#39; &#39;.join(list)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;拆分 / 合并&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;s.strip()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;去除首尾空白&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;s.replace(&#39;a&#39;,&#39;b&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;替换字符串&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;f&amp;quot;{x:.2f}&amp;quot;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;f-string 格式化字符串&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;列表-list&#34;&gt;列表 &lt;code&gt;list&lt;/code&gt;&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;函数&lt;/th&gt;
&lt;th&gt;示例&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;len(lst)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;获取长度&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;lst.append(x)&lt;/code&gt; / &lt;code&gt;lst.extend(...)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;添加元素&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;lst.pop()&lt;/code&gt; / &lt;code&gt;lst.remove(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;删除元素&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;lst.sort()&lt;/code&gt; / &lt;code&gt;sorted(lst)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;排序，原地或新列表&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;lst[::-1]&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;反转列表&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;字典-dict&#34;&gt;字典 &lt;code&gt;dict&lt;/code&gt;&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;函数&lt;/th&gt;
&lt;th&gt;示例&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;d.get(&#39;key&#39;, default)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;安全取值&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;d.keys()&lt;/code&gt; / &lt;code&gt;d.values()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;键/值视图&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;d.items()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;遍历键值对&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;dict(zip(keys, values))&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;合并为字典&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;集合-set&#34;&gt;集合 &lt;code&gt;set&lt;/code&gt;&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;操作&lt;/th&gt;
&lt;th&gt;示例&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;并&lt;/td&gt;
&lt;td&gt;`a&lt;/td&gt;
&lt;td&gt;b&lt;code&gt;/&lt;/code&gt;a.union(b)`&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;交&lt;/td&gt;
&lt;td&gt;&lt;code&gt;a &amp;amp; b&lt;/code&gt; / &lt;code&gt;a.intersection(b)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;td&gt;&lt;code&gt;a - b&lt;/code&gt; / &lt;code&gt;a.difference(b)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;三-内置函数高频使用表&#34;&gt;🔁 三、内置函数高频使用表&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;函数&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;len()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;长度&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;sum()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;求和&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;min()&lt;/code&gt; / &lt;code&gt;max()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;最小/最大&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;range()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;生成数列&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;enumerate()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;索引+元素遍历&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;zip(a, b)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;配对遍历&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;map(func, iterable)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;映射&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;filter(func, iterable)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;过滤&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;sorted(list, key=..., reverse=True)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;排序控制&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;any()&lt;/code&gt; / &lt;code&gt;all()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;判断是否有 / 是否都为真&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;四-模块与工具函数&#34;&gt;⚙️ 四、模块与工具函数&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;常用函数&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;math&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;math.sqrt()&lt;/code&gt;, &lt;code&gt;log()&lt;/code&gt;, &lt;code&gt;ceil()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;数学运算&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;random&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;random.choice()&lt;/code&gt;, &lt;code&gt;randint()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;随机操作&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;datetime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;datetime.now()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;时间戳处理&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;os&lt;/code&gt;, &lt;code&gt;sys&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;os.path&lt;/code&gt;, &lt;code&gt;sys.argv&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;路径与参数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;glob&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;glob.glob(&#39;*.py&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;文件批量匹配&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;re&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;re.findall()&lt;/code&gt;, &lt;code&gt;sub()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;正则匹配&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;json&lt;/code&gt; / &lt;code&gt;yaml&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;json.load()&lt;/code&gt;, &lt;code&gt;yaml.safe_load()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;配置处理&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;五-异常处理-文件操作&#34;&gt;🧪 五、异常处理 &amp;amp; 文件操作&lt;/h2&gt;

&lt;h3 id=&#34;异常处理&#34;&gt;异常处理&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;try:
    risky_operation()
except ValueError as e:
    print(&amp;quot;Caught error:&amp;quot;, e)
finally:
    cleanup()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;文件操作&#34;&gt;文件操作&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;with open(&#39;file.txt&#39;, &#39;r&#39;) as f:
    content = f.read()
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;七-数值计算与张量操作-numpy-pytorch&#34;&gt;🔢 七、数值计算与张量操作（NumPy &amp;amp; PyTorch）&lt;/h2&gt;

&lt;h3 id=&#34;numpy常用函数&#34;&gt;NumPy常用函数&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;函数&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;np.array()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;创建数组&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;np.zeros()&lt;/code&gt; / &lt;code&gt;np.ones()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;初始化张量&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;np.reshape()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;重塑维度&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;np.dot()&lt;/code&gt; / &lt;code&gt;np.matmul()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;向量/矩阵乘法&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;np.mean()&lt;/code&gt; / &lt;code&gt;np.std()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;均值、标准差&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;np.argmax()&lt;/code&gt; / &lt;code&gt;np.argsort()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;排序、索引最大值&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;np.concatenate()&lt;/code&gt; / &lt;code&gt;np.stack()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;合并数组&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;pytorch张量操作&#34;&gt;PyTorch张量操作&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;函数&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;torch.tensor()&lt;/code&gt; / &lt;code&gt;torch.from_numpy()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;创建张量&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;x.to(&#39;cuda&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;张量转GPU&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;x.view()&lt;/code&gt; / &lt;code&gt;x.reshape()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;改变维度&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;x.mean(dim=1)&lt;/code&gt; / &lt;code&gt;x.softmax(dim=-1)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;常见计算&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;torch.cat()&lt;/code&gt; / &lt;code&gt;torch.stack()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;拼接张量&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;torch.nn.functional&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;提供无状态的函数，如激活函数&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;八-模型开发与训练-pytorch&#34;&gt;🧠 八、模型开发与训练（PyTorch）&lt;/h2&gt;

&lt;h3 id=&#34;模型定义&#34;&gt;模型定义&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(768, 2)
    
    def forward(self, x):
        return self.linear(x)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;常用训练组件&#34;&gt;常用训练组件&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模块&lt;/th&gt;
&lt;th&gt;常用函数&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;nn&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;nn.Linear&lt;/code&gt;, &lt;code&gt;nn.Embedding&lt;/code&gt;, &lt;code&gt;nn.Transformer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;模型层&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;optim&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;SGD&lt;/code&gt;, &lt;code&gt;Adam&lt;/code&gt;, &lt;code&gt;lr_scheduler&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;优化器&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;loss&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;CrossEntropyLoss&lt;/code&gt;, &lt;code&gt;MSELoss&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;损失函数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;torch.utils.data.DataLoader&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;数据批加载&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;autograd&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;loss.backward()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;反向传播&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;九-大模型加载与推理相关库函数&#34;&gt;🚀 九、大模型加载与推理相关库函数&lt;/h2&gt;

&lt;h3 id=&#34;huggingface-transformers&#34;&gt;HuggingFace Transformers&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;函数&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;from_pretrained()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;加载模型和tokenizer&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;AutoModelForCausalLM&lt;/code&gt; / &lt;code&gt;AutoTokenizer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;大模型架构适配&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;tokenizer.encode()&lt;/code&gt; / &lt;code&gt;decode()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;文本与token转换&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;model.generate()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;文本生成&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;推理优化相关&#34;&gt;推理优化相关&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;库&lt;/th&gt;
&lt;th&gt;函数 / 说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;torch.no_grad()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;禁用梯度，加快推理&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;torch.cuda.amp.autocast()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;半精度混合精度推理&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;torch.jit.trace()&lt;/code&gt; / &lt;code&gt;script()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;模型静态图编译&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;onnxruntime&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;InferenceSession()&lt;/code&gt;，用于ONNX推理&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;vllm&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;高效推理库（异步批次 + KV Cache 管理）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;十-辅助工具库函数&#34;&gt;🧰 十、辅助工具库函数&lt;/h2&gt;

&lt;h3 id=&#34;配置与日志&#34;&gt;配置与日志&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;库&lt;/th&gt;
&lt;th&gt;常用函数&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;argparse&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;parser.add_argument()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;yaml&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;yaml.safe_load(open(&#39;config.yaml&#39;))&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;logging&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;logging.info()&lt;/code&gt;，配合训练日志记录&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;文件与路径&#34;&gt;文件与路径&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;库&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;os&lt;/code&gt;, &lt;code&gt;pathlib&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;文件路径管理&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;glob&lt;/code&gt;, &lt;code&gt;shutil&lt;/code&gt;, &lt;code&gt;zipfile&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;文件批量操作、压缩&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;tqdm&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;训练进度条显示&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;调试与性能&#34;&gt;调试与性能&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;工具&lt;/th&gt;
&lt;th&gt;用法&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;print()&lt;/code&gt; / &lt;code&gt;logging&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;日志输出&lt;/td&gt;
&lt;td&gt;可配日志等级&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;assert&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;assert x &amp;gt; 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;条件断言&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;%timeit&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;IPython魔法命令&lt;/td&gt;
&lt;td&gt;性能测试&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;pdb.set_trace()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;中断调试&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;十一-推荐学习资源&#34;&gt;📚十一、 推荐学习资源&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主题&lt;/th&gt;
&lt;th&gt;资源&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Python 3 标准库手册&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.python.org/3/library/&#34;&gt;https://docs.python.org/3/library/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;PyTorch文档&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://pytorch.org/docs/stable/index.html&#34;&gt;https://pytorch.org/docs/stable/index.html&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;HuggingFace教程&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://huggingface.co/transformers/&#34;&gt;https://huggingface.co/transformers/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Python标准库速查&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.python.org/3/library/&#34;&gt;https://docs.python.org/3/library/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;
</description>
        </item>
        
        <item>
            <title>AI中的数学知识</title>
            <link>http://mospany.github.io/2025/07/13/math-in-ai/</link>
            <pubDate>Sun, 13 Jul 2025 19:44:00 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2025/07/13/math-in-ai/</guid>
            <description>

&lt;h1 id=&#34;ai中的数学知识全景-基础-公式-证明与应用&#34;&gt;AI中的数学知识全景：基础、公式、证明与应用&lt;/h1&gt;

&lt;p&gt;人工智能（AI）作为21世纪最具变革性的技术之一，其发展离不开坚实的数学基础。无论是机器学习、深度学习、自然语言处理还是计算机视觉，背后都蕴含着丰富的数学理论与方法。本文将系统梳理AI中常用的数学知识，涵盖数学概念、所属学科、核心公式、证明过程及其在AI中的具体用途，力求为读者呈现一份详尽的“AI数学地图”。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;一-线性代数&#34;&gt;一、线性代数&lt;/h2&gt;

&lt;h3 id=&#34;1-1-基本概念与学科归属&#34;&gt;1.1 基本概念与学科归属&lt;/h3&gt;

&lt;p&gt;线性代数是研究向量、矩阵及其变换的数学分支，是AI的基石。它主要包括向量空间、线性变换、特征值与特征向量、奇异值分解等内容。&lt;/p&gt;

&lt;h3 id=&#34;1-2-主要内容与公式&#34;&gt;1.2 主要内容与公式&lt;/h3&gt;

&lt;h4 id=&#34;1-2-1-向量与矩阵&#34;&gt;1.2.1 向量与矩阵&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;向量&lt;/strong&gt;：有方向和大小的量，常用列向量表示。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;矩阵&lt;/strong&gt;：二维数组，表示线性变换或数据集。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;矩阵乘法公式&lt;/strong&gt;：&lt;br /&gt;
设$A$为$m\times n$矩阵，$B$为$n\times p$矩阵，则$C=AB$为$m\times p$矩阵，&lt;br /&gt;
$$
C&lt;em&gt;{ij} = \sum&lt;/em&gt;{k=1}^n A&lt;em&gt;{ik}B&lt;/em&gt;{kj}
$$&lt;/p&gt;

&lt;h4 id=&#34;1-2-2-特征值与特征向量&#34;&gt;1.2.2 特征值与特征向量&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：对于方阵$A$，若存在非零向量$v$和数$\lambda$，使得$Av = \lambda v$，则$\lambda$为$A$的特征值，$v$为对应特征向量。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;特征值求解公式&lt;/strong&gt;：&lt;br /&gt;
$$
\det(A - \lambda I) = 0
$$&lt;/p&gt;

&lt;h4 id=&#34;1-2-3-奇异值分解-svd&#34;&gt;1.2.3 奇异值分解（SVD）&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：任意$m\times n$矩阵$A$可分解为$A = U\Sigma V^T$，其中$U$和$V$为正交矩阵，$\Sigma$为对角矩阵。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-2-4-证明举例-特征值存在性&#34;&gt;1.2.4 证明举例：特征值存在性&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：任意$n$阶实对称矩阵都有$n$个实特征值。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;证明思路&lt;/strong&gt;：&lt;br /&gt;
1. 实对称矩阵$A$的特征多项式为实系数多项式，必有实根（代数基本定理）。
2. 可通过正交变换将$A$对角化，所有特征值为实数。&lt;/p&gt;

&lt;h3 id=&#34;1-3-ai中的用途&#34;&gt;1.3 AI中的用途&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据表示&lt;/strong&gt;：样本、特征、权重均以向量/矩阵形式存储。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;神经网络&lt;/strong&gt;：前向传播、反向传播均为矩阵运算。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;降维&lt;/strong&gt;：PCA、SVD等用于特征压缩与可视化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图像处理&lt;/strong&gt;：卷积操作本质为矩阵乘法。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;二-概率论与数理统计&#34;&gt;二、概率论与数理统计&lt;/h2&gt;

&lt;h3 id=&#34;2-1-基本概念与学科归属&#34;&gt;2.1 基本概念与学科归属&lt;/h3&gt;

&lt;p&gt;概率论研究随机现象的规律，数理统计则关注数据分析与推断。AI中的不确定性建模、模型评估、参数估计等均依赖概率统计。&lt;/p&gt;

&lt;h3 id=&#34;2-2-主要内容与公式&#34;&gt;2.2 主要内容与公式&lt;/h3&gt;

&lt;h4 id=&#34;2-2-1-概率空间与随机变量&#34;&gt;2.2.1 概率空间与随机变量&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;概率空间&lt;/strong&gt;：$(\Omega, \mathcal{F}, P)$，$\Omega$为样本空间，$\mathcal{F}$为事件集合，$P$为概率测度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;随机变量&lt;/strong&gt;：定义在概率空间上的实值函数。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;2-2-2-条件概率与贝叶斯公式&#34;&gt;2.2.2 条件概率与贝叶斯公式&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;条件概率&lt;/strong&gt;：$P(A|B) = \frac{P(A\cap B)}{P(B)}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;贝叶斯公式&lt;/strong&gt;：$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;2-2-3-数学期望与方差&#34;&gt;2.2.3 数学期望与方差&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;期望&lt;/strong&gt;：$E[X] = \sum_x xP(X=x)$（离散），$E[X] = \int x f(x) dx$（连续）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;方差&lt;/strong&gt;：$Var(X) = E[(X-E[X])^2]$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;2-2-4-常见分布&#34;&gt;2.2.4 常见分布&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;正态分布&lt;/strong&gt;：$f(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;伯努利分布&lt;/strong&gt;、&lt;strong&gt;二项分布&lt;/strong&gt;、&lt;strong&gt;泊松分布&lt;/strong&gt;等。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;2-2-5-极大似然估计-mle&#34;&gt;2.2.5 极大似然估计（MLE）&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：给定观测数据$X$，参数$\theta$的极大似然估计为
$$
\hat{\theta} = \arg\max_\theta P(X|\theta)
$$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;2-2-6-证明举例-正态分布的极大似然估计&#34;&gt;2.2.6 证明举例：正态分布的极大似然估计&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;问题&lt;/strong&gt;：已知样本$x_1, x_2, &amp;hellip;, x_n$来自$N(\mu, \sigma^2)$，求$\mu$的MLE。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;：&lt;br /&gt;
似然函数：
$$
L(\mu) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x&lt;em&gt;i-\mu)^2}{2\sigma^2}}
$$
对数似然：
$$
\ell(\mu) = -\frac{n}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum&lt;/em&gt;{i=1}^n (x&lt;em&gt;i-\mu)^2
$$
对$\mu$求导并令其为零：
$$
\frac{\partial \ell}{\partial \mu} = \frac{1}{\sigma^2}\sum&lt;/em&gt;{i=1}^n (x&lt;em&gt;i-\mu) = 0 \implies \mu = \frac{1}{n}\sum&lt;/em&gt;{i=1}^n x_i
$$&lt;/p&gt;

&lt;h3 id=&#34;2-3-ai中的用途&#34;&gt;2.3 AI中的用途&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;模型建模&lt;/strong&gt;：朴素贝叶斯、隐马尔可夫模型、生成模型等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;损失函数&lt;/strong&gt;：交叉熵、对数似然等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估指标&lt;/strong&gt;：准确率、召回率、AUC等均基于概率统计。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不确定性估计&lt;/strong&gt;：贝叶斯深度学习、置信区间等。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;三-微积分与最优化&#34;&gt;三、微积分与最优化&lt;/h2&gt;

&lt;h3 id=&#34;3-1-基本概念与学科归属&#34;&gt;3.1 基本概念与学科归属&lt;/h3&gt;

&lt;p&gt;微积分研究变化率与累积量，最优化则关注函数极值的求解。AI模型训练本质是最优化问题，微积分为其提供理论基础。&lt;/p&gt;

&lt;h3 id=&#34;3-2-主要内容与公式&#34;&gt;3.2 主要内容与公式&lt;/h3&gt;

&lt;h4 id=&#34;3-2-1-导数与梯度&#34;&gt;3.2.1 导数与梯度&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;导数&lt;/strong&gt;：$f&amp;rsquo;(x) = \lim_{h\to 0} \frac{f(x+h)-f(x)}{h}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;梯度&lt;/strong&gt;：$\nabla f(x) = \left(\frac{\partial f}{\partial x_1}, &amp;hellip;, \frac{\partial f}{\partial x_n}\right)$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-2-2-链式法则&#34;&gt;3.2.2 链式法则&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;公式&lt;/strong&gt;：若$y = f(u), u = g(x)$，则$\frac{dy}{dx} = \frac{dy}{du}\frac{du}{dx}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-2-3-泰勒展开&#34;&gt;3.2.3 泰勒展开&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;公式&lt;/strong&gt;：$f(x) = f(a) + f&amp;rsquo;(a)(x-a) + \frac{f&amp;rdquo;(a)}{2!}(x-a)^2 + &amp;hellip;$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-2-4-最优化问题&#34;&gt;3.2.4 最优化问题&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;无约束最优化&lt;/strong&gt;：$\min_x f(x)$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;有约束最优化&lt;/strong&gt;：$\min_x f(x), \text{ s.t. } g_i(x) \leq 0, h_j(x) = 0$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-2-5-梯度下降法&#34;&gt;3.2.5 梯度下降法&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;公式&lt;/strong&gt;：$x_{k+1} = x_k - \eta \nabla f(x_k)$，$\eta$为学习率。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-2-6-拉格朗日乘子法&#34;&gt;3.2.6 拉格朗日乘子法&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;公式&lt;/strong&gt;：$\mathcal{L}(x, \lambda) = f(x) + \lambda g(x)$，对$\mathcal{L}$求偏导并令其为零。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-2-7-证明举例-梯度下降收敛性&#34;&gt;3.2.7 证明举例：梯度下降收敛性&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：若$f(x)$为Lipschitz连续且凸，梯度下降法收敛到全局最优。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;证明思路&lt;/strong&gt;：&lt;br /&gt;
1. 利用凸函数性质，$f(y) \geq f(x) + \nabla f(x)^T(y-x)$。
2. 通过递推不等式证明目标函数单调下降，最终收敛。&lt;/p&gt;

&lt;h3 id=&#34;3-3-ai中的用途&#34;&gt;3.3 AI中的用途&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;模型训练&lt;/strong&gt;：神经网络、支持向量机等均通过梯度下降优化损失函数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;反向传播&lt;/strong&gt;：链式法则用于多层网络的梯度计算。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;正则化&lt;/strong&gt;：通过约束优化提升模型泛化能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自动微分&lt;/strong&gt;：深度学习框架自动计算梯度。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;四-离散数学与图论&#34;&gt;四、离散数学与图论&lt;/h2&gt;

&lt;h3 id=&#34;4-1-基本概念与学科归属&#34;&gt;4.1 基本概念与学科归属&lt;/h3&gt;

&lt;p&gt;离散数学研究离散结构，包括集合、关系、图、组合等。图论是其重要分支，AI中的知识图谱、社交网络分析等均依赖图论。&lt;/p&gt;

&lt;h3 id=&#34;4-2-主要内容与公式&#34;&gt;4.2 主要内容与公式&lt;/h3&gt;

&lt;h4 id=&#34;4-2-1-集合与关系&#34;&gt;4.2.1 集合与关系&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;集合&lt;/strong&gt;：元素的无序集合。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;关系&lt;/strong&gt;：集合间的映射，如等价关系、偏序关系。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;4-2-2-图的定义&#34;&gt;4.2.2 图的定义&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;无向图&lt;/strong&gt;：$G=(V,E)$，$V$为顶点集，$E$为边集。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;有向图&lt;/strong&gt;：边有方向。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;4-2-3-路径与连通性&#34;&gt;4.2.3 路径与连通性&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;路径&lt;/strong&gt;：顶点序列，任意相邻顶点有边相连。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;连通分量&lt;/strong&gt;：最大连通子图。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;4-2-4-最短路径算法&#34;&gt;4.2.4 最短路径算法&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Dijkstra算法&lt;/strong&gt;：用于无负权图的最短路径。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bellman-Ford算法&lt;/strong&gt;：可处理负权边。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;4-2-5-最大流问题&#34;&gt;4.2.5 最大流问题&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ford-Fulkerson算法&lt;/strong&gt;：求解网络最大流。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;4-2-6-证明举例-dijkstra算法正确性&#34;&gt;4.2.6 证明举例：Dijkstra算法正确性&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;思路&lt;/strong&gt;：&lt;br /&gt;
1. 每次选取未访问节点中距离起点最近的节点，更新其邻居距离。
2. 归纳法证明每个节点的最短路径在被访问时已确定。&lt;/p&gt;

&lt;h3 id=&#34;4-3-ai中的用途&#34;&gt;4.3 AI中的用途&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;知识图谱&lt;/strong&gt;：实体及其关系建模为图。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;社交网络分析&lt;/strong&gt;：节点为用户，边为关系。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图神经网络（GNN）&lt;/strong&gt;：在图结构上进行特征传播与学习。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推荐系统&lt;/strong&gt;：基于图的协同过滤。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;五-信息论&#34;&gt;五、信息论&lt;/h2&gt;

&lt;h3 id=&#34;5-1-基本概念与学科归属&#34;&gt;5.1 基本概念与学科归属&lt;/h3&gt;

&lt;p&gt;信息论研究信息的度量、传输与压缩。AI中的损失函数、模型评估等大量用到信息论概念。&lt;/p&gt;

&lt;h3 id=&#34;5-2-主要内容与公式&#34;&gt;5.2 主要内容与公式&lt;/h3&gt;

&lt;h4 id=&#34;5-2-1-熵&#34;&gt;5.2.1 熵&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：$H(X) = -\sum_{i} P(x_i)\log P(x_i)$，度量不确定性。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;5-2-2-交叉熵&#34;&gt;5.2.2 交叉熵&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：$H(P, Q) = -\sum_{i} P(x_i)\log Q(x_i)$，度量两个分布的差异。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;5-2-3-kl散度&#34;&gt;5.2.3 KL散度&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：$D&lt;em&gt;{KL}(P||Q) = \sum&lt;/em&gt;{i} P(x_i)\log\frac{P(x_i)}{Q(x_i)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;5-2-4-互信息&#34;&gt;5.2.4 互信息&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：$I(X;Y) = \sum_{x,y} P(x,y)\log\frac{P(x,y)}{P(x)P(y)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;5-2-5-证明举例-kl散度非负性&#34;&gt;5.2.5 证明举例：KL散度非负性&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：$D_{KL}(P||Q) \geq 0$，等号成立当且仅当$P=Q$。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;证明&lt;/strong&gt;：&lt;br /&gt;
利用Jensen不等式，$\log$为凹函数，&lt;br /&gt;
$$
D_{KL}(P||Q) = E_P\left[\log\frac{P(x)}{Q(x)}\right] \geq \log E_P\left[\frac{P(x)}{Q(x)}\right] = 0
$$&lt;/p&gt;

&lt;h3 id=&#34;5-3-ai中的用途&#34;&gt;5.3 AI中的用途&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;损失函数&lt;/strong&gt;：分类任务常用交叉熵损失。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生成模型&lt;/strong&gt;：GAN、VAE等用KL散度衡量分布差异。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特征选择&lt;/strong&gt;：互信息用于评估特征与标签的相关性。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;六-数值分析与计算方法&#34;&gt;六、数值分析与计算方法&lt;/h2&gt;

&lt;h3 id=&#34;6-1-基本概念与学科归属&#34;&gt;6.1 基本概念与学科归属&lt;/h3&gt;

&lt;p&gt;数值分析关注数学问题的近似解法，AI模型训练、推理均需高效数值计算。&lt;/p&gt;

&lt;h3 id=&#34;6-2-主要内容与公式&#34;&gt;6.2 主要内容与公式&lt;/h3&gt;

&lt;h4 id=&#34;6-2-1-线性方程组求解&#34;&gt;6.2.1 线性方程组求解&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;高斯消元法&lt;/strong&gt;、&lt;strong&gt;LU分解&lt;/strong&gt;、&lt;strong&gt;共轭梯度法&lt;/strong&gt;等。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;6-2-2-特征值分解&#34;&gt;6.2.2 特征值分解&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;幂法&lt;/strong&gt;、&lt;strong&gt;Jacobi法&lt;/strong&gt;等。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;6-2-3-插值与拟合&#34;&gt;6.2.3 插值与拟合&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;拉格朗日插值&lt;/strong&gt;、&lt;strong&gt;最小二乘法&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;6-2-4-数值积分&#34;&gt;6.2.4 数值积分&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;梯形法则&lt;/strong&gt;、&lt;strong&gt;辛普森法则&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;6-2-5-证明举例-最小二乘法&#34;&gt;6.2.5 证明举例：最小二乘法&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;问题&lt;/strong&gt;：拟合直线$y = ax + b$，最小化$\sum_{i=1}^n (y_i - (ax_i + b))^2$。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;：&lt;br /&gt;
对$a, b$分别求偏导并令其为零，解线性方程组得最优$a, b$。&lt;/p&gt;

&lt;h3 id=&#34;6-3-ai中的用途&#34;&gt;6.3 AI中的用途&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;大规模矩阵运算&lt;/strong&gt;：神经网络训练依赖高效线性代数库。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化算法实现&lt;/strong&gt;：如Adam、RMSProp等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型推理加速&lt;/strong&gt;：量化、稀疏化等技术。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;七-常用数学工具与ai算法中的应用实例&#34;&gt;七、常用数学工具与AI算法中的应用实例&lt;/h2&gt;

&lt;h3 id=&#34;7-1-主成分分析-pca&#34;&gt;7.1 主成分分析（PCA）&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数学基础&lt;/strong&gt;：协方差矩阵、特征值分解。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;公式&lt;/strong&gt;：最大化投影方差，$w^* = \arg\max_{||w||=1} w^T S w$，$S$为协方差矩阵。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;证明&lt;/strong&gt;：拉格朗日乘子法可得$Sw = \lambda w$，即$w$为$S$的特征向量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用途&lt;/strong&gt;：降维、去噪、可视化。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;7-2-支持向量机-svm&#34;&gt;7.2 支持向量机（SVM）&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数学基础&lt;/strong&gt;：凸优化、拉格朗日对偶性、核方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;公式&lt;/strong&gt;：$\min_{w,b} \frac{1}{2}||w||^2$，s.t. $y_i(w^T x_i + b) \geq 1$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;证明&lt;/strong&gt;：KKT条件推导最优解。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用途&lt;/strong&gt;：分类、回归、异常检测。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;7-3-神经网络与反向传播&#34;&gt;7.3 神经网络与反向传播&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数学基础&lt;/strong&gt;：链式法则、矩阵微分。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;公式&lt;/strong&gt;：$\frac{\partial L}{\partial w} = \frac{\partial L}{\partial y} \frac{\partial y}{\partial w}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;证明&lt;/strong&gt;：逐层递推，利用链式法则。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用途&lt;/strong&gt;：深度学习模型训练。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;7-4-马尔可夫决策过程-mdp&#34;&gt;7.4 马尔可夫决策过程（MDP）&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数学基础&lt;/strong&gt;：概率论、动态规划。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;公式&lt;/strong&gt;：贝尔曼方程$V(s) = \max&lt;em&gt;a \sum&lt;/em&gt;{s&amp;rsquo;} P(s&amp;rsquo;|s,a)[R(s,a,s&amp;rsquo;) + \gamma V(s&amp;rsquo;)]$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;证明&lt;/strong&gt;：利用最优性原理递归推导。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用途&lt;/strong&gt;：强化学习、自动决策。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;八-ai数学知识的综合应用案例&#34;&gt;八、AI数学知识的综合应用案例&lt;/h2&gt;

&lt;h3 id=&#34;8-1-图像识别中的数学&#34;&gt;8.1 图像识别中的数学&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;卷积神经网络（CNN）&lt;/strong&gt;：卷积操作（线性代数）、激活函数（微积分）、损失函数（信息论）、参数优化（最优化）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特征提取&lt;/strong&gt;：PCA降维（线性代数）、SIFT/ORB等算法（离散数学）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;8-2-自然语言处理中的数学&#34;&gt;8.2 自然语言处理中的数学&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;词向量&lt;/strong&gt;：Word2Vec中的Skip-gram模型用到概率建模、最大似然估计。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;注意力机制&lt;/strong&gt;：加权和（线性代数）、softmax归一化（概率论）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;序列建模&lt;/strong&gt;：RNN/LSTM中的链式法则、梯度消失/爆炸分析（微积分）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;8-3-强化学习中的数学&#34;&gt;8.3 强化学习中的数学&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;策略优化&lt;/strong&gt;：梯度上升法、策略梯度定理（微积分、概率论）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;值函数估计&lt;/strong&gt;：贝尔曼方程（动态规划）、蒙特卡洛方法（数理统计）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;8-4-生成模型中的数学&#34;&gt;8.4 生成模型中的数学&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;变分自编码器（VAE）&lt;/strong&gt;：变分推断（概率论）、KL散度（信息论）、反向传播（微积分）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生成对抗网络（GAN）&lt;/strong&gt;：极大极小优化（最优化）、JS散度（信息论）。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;九-ai数学学习建议与资源&#34;&gt;九、AI数学学习建议与资源&lt;/h2&gt;

&lt;h3 id=&#34;9-1-学习建议&#34;&gt;9.1 学习建议&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;打好基础&lt;/strong&gt;：线性代数、概率论、微积分是AI数学的“三驾马车”。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;理论结合实践&lt;/strong&gt;：通过编程实现数学算法，加深理解。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;关注证明过程&lt;/strong&gt;：理解公式背后的推导逻辑，提升抽象思维。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多做题多应用&lt;/strong&gt;：刷题、参加竞赛、参与开源项目。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;9-2-推荐书籍与课程&#34;&gt;9.2 推荐书籍与课程&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;《线性代数及其应用》（David C. Lay）&lt;/li&gt;
&lt;li&gt;《概率论与数理统计》（茆诗松）&lt;/li&gt;
&lt;li&gt;《统计学习方法》（李航）&lt;/li&gt;
&lt;li&gt;《深度学习》（Ian Goodfellow等）&lt;/li&gt;
&lt;li&gt;斯坦福CS229、CS231n、MIT 6.036等公开课&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;十-结语&#34;&gt;十、结语&lt;/h2&gt;

&lt;p&gt;AI的每一次突破，背后都离不开数学的支撑。从数据的表示、模型的构建、参数的优化，到结果的解释与评估，数学无处不在。掌握AI所需的数学知识，不仅能帮助我们更好地理解和应用现有技术，更能为创新和突破打下坚实的基础。希望本文能为广大AI学习者和从业者提供一份系统、详实的数学参考，助力大家在智能时代乘风破浪。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;（全文约5400字，涵盖AI常用数学知识的概念、学科、公式、证明与用途，适合作为系统学习与查阅之用。）&lt;/em&gt;&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>从会议室名称看AI</title>
            <link>http://mospany.github.io/2025/07/13/meeting-room-to-see-ai/</link>
            <pubDate>Sun, 13 Jul 2025 18:20:27 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2025/07/13/meeting-room-to-see-ai/</guid>
            <description>

&lt;h1 id=&#34;从会议室名称看ai-核心术语解读&#34;&gt;从会议室名称看AI：核心术语解读&lt;/h1&gt;

&lt;p&gt;在人工智能（AI）领域，许多会议室和项目组常以AI相关术语命名。以下是一些常见AI术语的详细解读，涵盖其英文名称、基本原理及应用场景。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;1-强化学习-reinforcement-learning&#34;&gt;1. 强化学习（Reinforcement Learning）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Reinforcement Learning&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：强化学习是一种机器学习方法，强调智能体（Agent）在与环境交互过程中，通过试错获得最大化累积奖励的策略。智能体根据当前状态选择动作，环境反馈奖励或惩罚，智能体据此调整策略。强化学习广泛应用于游戏、机器人控制和自动驾驶等领域，代表性算法有Q-learning、Deep Q Network（DQN）等。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;2-深度学习-deep-learning&#34;&gt;2. 深度学习（Deep Learning）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Deep Learning&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：深度学习是一种以多层神经网络为基础的机器学习方法。通过构建多层（深层）神经网络，能够自动从大量数据中提取高层次特征，实现图像识别、语音识别、自然语言处理等复杂任务。深度学习的核心在于端到端的特征学习和强大的表达能力，常见模型有卷积神经网络（CNN）、循环神经网络（RNN）等。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;3-知识图谱-knowledge-graph&#34;&gt;3. 知识图谱（Knowledge Graph）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Knowledge Graph&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：知识图谱是一种以图结构组织和表达知识的方法，将实体（如人、地点、事物）及其关系以节点和边的形式存储。通过语义关联，知识图谱支持复杂的推理和查询，广泛应用于搜索引擎、智能问答和推荐系统。其构建涉及信息抽取、实体消歧、关系抽取等技术。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;4-多维缩放-multidimensional-scaling-mds&#34;&gt;4. 多维缩放（Multidimensional Scaling, MDS）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Multidimensional Scaling (MDS)&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：多维缩放是一种降维方法，用于将高维数据映射到低维空间（通常是二维或三维），以便可视化和分析。MDS通过保持数据点之间的距离关系，尽量还原原始数据的结构。它常用于心理学、市场分析和生物信息学等领域的数据可视化。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;5-层次聚类-hierarchical-clustering&#34;&gt;5. 层次聚类（Hierarchical Clustering）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Hierarchical Clustering&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：层次聚类是一种无监督学习方法，通过构建数据的层次结构（树状图或树状图谱）来发现数据的内在分组。算法分为自底向上（凝聚型）和自顶向下（分裂型）两类。层次聚类无需预先指定簇的数量，适用于探索数据的多层次结构。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;6-多层感知-multilayer-perceptron-mlp&#34;&gt;6. 多层感知（Multilayer Perceptron, MLP）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Multilayer Perceptron (MLP)&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：多层感知是一种前馈神经网络，由输入层、一个或多个隐藏层和输出层组成。每层由多个神经元构成，层与层之间全连接。MLP通过反向传播算法进行训练，能够逼近任意非线性函数，是深度学习的基础结构之一，广泛用于分类和回归任务。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;7-卷积网络-convolutional-neural-network-cnn&#34;&gt;7. 卷积网络（Convolutional Neural Network, CNN）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Convolutional Neural Network (CNN)&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：卷积神经网络是一种专门处理具有网格结构数据（如图像）的深度学习模型。其核心在于卷积层，通过局部感受野和权重共享机制提取空间特征，极大减少参数数量。CNN在图像识别、目标检测、视频分析等领域表现卓越。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;8-协同过滤-collaborative-filtering&#34;&gt;8. 协同过滤（Collaborative Filtering）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Collaborative Filtering&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：协同过滤是一种推荐系统技术，通过分析用户与物品的交互行为（如评分、点击）来预测用户可能喜欢的物品。分为基于用户和基于物品的协同过滤。其核心思想是“物以类聚，人以群分”，即相似用户喜欢相似物品。常用于电商、视频、音乐等平台的个性化推荐。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;9-低秩适配-low-rank-adaptation-lora&#34;&gt;9. 低秩适配（Low-Rank Adaptation, LoRA）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Low-Rank Adaptation (LoRA)&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：低秩适配是一种参数高效微调（PEFT）方法，主要用于大模型的迁移学习。LoRA通过在预训练模型的权重矩阵中插入低秩分解模块，仅训练少量参数即可适应新任务，显著降低计算和存储成本。广泛应用于自然语言处理和多模态模型的微调。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;10-监督微调-supervised-fine-tuning&#34;&gt;10. 监督微调（Supervised Fine-tuning）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Supervised Fine-tuning&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：监督微调是指在有标签数据集上对预训练模型进行再训练，使其更好地适应特定任务。通过监督信号（如分类标签），模型参数得到针对性优化。该方法在大模型落地应用中极为常见，如BERT、GPT等模型在下游任务的微调。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;11-交叉验证-cross-validation&#34;&gt;11. 交叉验证（Cross Validation）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Cross Validation&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：交叉验证是一种模型评估方法，将数据集划分为若干子集，轮流用其中一部分作为验证集，其余作为训练集。常见的有K折交叉验证。该方法能有效评估模型的泛化能力，减少过拟合风险，是机器学习模型选择和调优的重要工具。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;12-具身智能-embodied-intelligence&#34;&gt;12. 具身智能（Embodied Intelligence）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Embodied Intelligence&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：具身智能强调智能体与物理世界的交互，认为智能的产生离不开身体和环境。具身智能体（如机器人）通过感知、运动和环境反馈实现学习和适应。该理念推动了机器人学、自动驾驶和虚拟现实等领域的发展，强调“智能在于行动”。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;13-模型量化-model-quantization&#34;&gt;13. 模型量化（Model Quantization）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Model Quantization&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：模型量化是一种模型压缩技术，通过将模型参数从高精度（如32位浮点）转换为低精度（如8位整数），以减少模型体积和加速推理速度。量化可显著降低硬件资源消耗，适用于边缘设备和移动端AI部署。常见量化方法有对称量化、非对称量化等。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;14-判别分析-discriminant-analysis&#34;&gt;14. 判别分析（Discriminant Analysis）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Discriminant Analysis&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：判别分析是一类用于分类的统计方法，通过寻找最佳投影方向，使不同类别的数据在该方向上分离度最大。典型方法有线性判别分析（LDA）和二次判别分析（QDA）。判别分析常用于模式识别、医学诊断等领域。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;15-随机森林-random-forest&#34;&gt;15. 随机森林（Random Forest）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Random Forest&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：随机森林是一种集成学习方法，通过构建多个决策树并对其结果进行投票或平均，提升模型的准确性和鲁棒性。每棵树在训练时随机选择特征和样本，减少过拟合。随机森林广泛应用于分类、回归和特征选择等任务。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;16-知识蒸馏-knowledge-distillation&#34;&gt;16. 知识蒸馏（Knowledge Distillation）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Knowledge Distillation&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：知识蒸馏是一种模型压缩技术，通过将大型“教师模型”的知识迁移到小型“学生模型”。学生模型在训练时不仅学习真实标签，还模仿教师模型的输出分布，从而获得更好的泛化能力。知识蒸馏常用于模型加速和部署。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;17-专家混合-mixture-of-experts-moe&#34;&gt;17. 专家混合（Mixture of Experts, MoE）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Mixture of Experts (MoE)&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：专家混合是一种模型结构，将多个“专家”子模型与一个门控网络结合。门控网络根据输入动态选择部分专家参与计算，实现模型容量与计算效率的平衡。MoE在大规模语言模型和多任务学习中表现突出，能有效提升模型性能。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;18-多头注意-multi-head-attention&#34;&gt;18. 多头注意（Multi-Head Attention）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Multi-Head Attention&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：多头注意是Transformer模型的核心机制，通过并行计算多个注意力头，捕捉不同子空间的信息。每个头独立学习输入序列的不同关系，最后将各头输出拼接融合。多头注意极大提升了模型对复杂依赖关系的建模能力，广泛应用于自然语言处理和计算机视觉。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;19-梯度提升-gradient-boosting&#34;&gt;19. 梯度提升（Gradient Boosting）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Gradient Boosting&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：梯度提升是一种集成学习方法，通过逐步训练一系列弱学习器（如决策树），每一步都拟合前一步的残差。最终模型是所有弱学习器的加权和。梯度提升具有强大的拟合能力，代表性算法有XGBoost、LightGBM等，广泛应用于结构化数据建模。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;20-多智能体-multi-agent&#34;&gt;20. 多智能体（Multi-Agent）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;英文名称&lt;/strong&gt;：Multi-Agent&lt;br /&gt;
&lt;strong&gt;原理&lt;/strong&gt;：多智能体系统由多个相互作用的智能体组成，每个智能体可独立感知、决策和行动。多智能体系统强调协作、竞争和通信，适用于分布式控制、博弈论、群体智能等场景。其研究推动了自动驾驶、智能交通、机器人集群等领域的发展。&lt;/p&gt;

&lt;hr /&gt;
</description>
        </item>
        
        <item>
            <title>常用AI术语</title>
            <link>http://mospany.github.io/2025/07/13/ai-term/</link>
            <pubDate>Sun, 13 Jul 2025 18:02:09 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2025/07/13/ai-term/</guid>
            <description>

&lt;h1 id=&#34;常用ai术语归类&#34;&gt;常用AI术语归类&lt;/h1&gt;

&lt;h2 id=&#34;基础概念&#34;&gt;基础概念&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;人工智能（Artificial Intelligence, AI）&lt;/strong&gt;：使机器表现出类似人类智能的技术和方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;机器学习（Machine Learning, ML）&lt;/strong&gt;：让计算机通过数据自动学习和改进的技术。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;深度学习（Deep Learning, DL）&lt;/strong&gt;：基于多层神经网络的机器学习方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;神经网络（Neural Network, NN）&lt;/strong&gt;：模仿人脑神经元结构的计算模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据集（Dataset）&lt;/strong&gt;：用于训练和测试模型的数据集合。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;机器学习相关术语&#34;&gt;机器学习相关术语&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;监督学习（Supervised Learning）&lt;/strong&gt;：利用带标签数据训练模型的方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;无监督学习（Unsupervised Learning）&lt;/strong&gt;：利用无标签数据发现数据结构的方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;半监督学习（Semi-supervised Learning）&lt;/strong&gt;：结合少量有标签和大量无标签数据进行学习的方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;强化学习（Reinforcement Learning, RL）&lt;/strong&gt;：通过奖励和惩罚机制让智能体学习策略的方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特征（Feature）&lt;/strong&gt;：用于描述数据的属性或变量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;标签（Label）&lt;/strong&gt;：数据对应的目标输出或分类。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;深度学习相关术语&#34;&gt;深度学习相关术语&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;卷积神经网络（Convolutional Neural Network, CNN）&lt;/strong&gt;：常用于图像处理的神经网络结构。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;循环神经网络（Recurrent Neural Network, RNN）&lt;/strong&gt;：适合处理序列数据的神经网络结构。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;生成对抗网络（Generative Adversarial Network, GAN）&lt;/strong&gt;：由生成器和判别器组成的生成模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自注意力机制（Self-Attention Mechanism）&lt;/strong&gt;：模型在处理序列时关注不同位置的信息机制。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;变换器（Transformer）&lt;/strong&gt;：基于自注意力机制的深度学习模型，广泛用于NLP。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;自然语言处理-nlp-相关术语&#34;&gt;自然语言处理（NLP）相关术语&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;自然语言处理（Natural Language Processing, NLP）&lt;/strong&gt;：让计算机理解和处理人类语言的技术。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;词嵌入（Word Embedding）&lt;/strong&gt;：将词语转换为向量表示的方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分词（Tokenization）&lt;/strong&gt;：将文本切分为词或子词的过程。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;命名实体识别（Named Entity Recognition, NER）&lt;/strong&gt;：识别文本中专有名词的任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文本生成（Text Generation）&lt;/strong&gt;：自动生成自然语言文本的技术。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;训练与评估相关术语&#34;&gt;训练与评估相关术语&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;损失函数（Loss Function）&lt;/strong&gt;：衡量模型预测与真实值差异的函数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化器（Optimizer）&lt;/strong&gt;：用于调整模型参数以最小化损失函数的算法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;过拟合（Overfitting）&lt;/strong&gt;：模型在训练集上表现好但在新数据上表现差的现象。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;欠拟合（Underfitting）&lt;/strong&gt;：模型无法很好地拟合训练数据的现象。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;准确率（Accuracy）&lt;/strong&gt;：预测正确的样本占总样本的比例。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;召回率（Recall）&lt;/strong&gt;：正确预测的正样本占所有正样本的比例。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;精确率（Precision）&lt;/strong&gt;：正确预测的正样本占所有预测为正样本的比例。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;F1分数（F1 Score）&lt;/strong&gt;：精确率和召回率的调和平均数。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;其他常见术语&#34;&gt;其他常见术语&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;大语言模型（Large Language Model, LLM）&lt;/strong&gt;：参数量巨大的自然语言处理模型，如GPT、BERT等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推理（Inference）&lt;/strong&gt;：使用训练好的模型对新数据进行预测的过程。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;微调（Fine-tuning）&lt;/strong&gt;：在预训练模型基础上针对特定任务进行再训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;迁移学习（Transfer Learning）&lt;/strong&gt;：将已有模型知识应用到新任务的学习方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;开源（Open Source）&lt;/strong&gt;：源代码公开、可自由使用和修改的软件。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;本文将持续补充更多AI相关术语，欢迎留言交流！&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        
        <item>
            <title>AI学习全景图</title>
            <link>http://mospany.github.io/2025/07/13/ai-study-toc/</link>
            <pubDate>Sun, 13 Jul 2025 16:27:22 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2025/07/13/ai-study-toc/</guid>
            <description>

&lt;h1 id=&#34;脑图&#34;&gt;脑图&lt;/h1&gt;

&lt;p&gt;&lt;center&gt;&lt;embed src=&#34;http://blog.mospan.cn/post/img/ai/ai-study-toc.pdf&#34; width=100% height=800&gt;&lt;/center&gt;&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>vGPU方案HAMi(01): 实现细粒度 GPU 切分</title>
            <link>http://mospany.github.io/2024/02/05/hami-vgpu-split/</link>
            <pubDate>Mon, 05 Feb 2024 19:31:10 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2024/02/05/hami-vgpu-split/</guid>
            <description>

&lt;p&gt;本文主要分享一个开源的 GPU 虚拟化方案：HAMi，包括如何安装、配置以及使用。&lt;/p&gt;

&lt;p&gt;相比于上一篇分享的 TimeSlicing 方案，HAMi 除了 GPU 共享之外还可以实现 GPU core、memory 的限制，保证共享同一 GPU 的各个 Pod 都能拿到足够的资源。&lt;/p&gt;

&lt;p&gt;本文主要对开源的 vGPU 方案 HAMi 的 GPU Core&amp;amp;Memory 隔离功能进行测试。&lt;/p&gt;

&lt;h1 id=&#34;为什么需要-gpu-共享-切分等方案&#34;&gt;为什么需要 GPU 共享、切分等方案？&lt;/h1&gt;

&lt;p&gt;开始之前我们先思考一个问题，&lt;em&gt;为什么需要 GPU 共享、切分等方案？&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;或者说是另外一个问题：&lt;em&gt;明明直接在裸机环境使用，都可以多个进程共享 GPU，怎么到 k8s 环境就不行了。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;推荐阅读前面几篇文章：这两篇分享了如何在各个环境中使用 GPU，在 k8s 环境则推荐使用 NVIDIA 提供的 gpu-operator 快速部署环境。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.mospan.cn/2024/01/16/gpu-on-k8s/&#34;&gt;K8S项目实践(08): 在ECS、Docker、K8s 等环境中使用 GPU&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.mospan.cn/2024/01/17/gpu-operator/&#34;&gt;K8S项目实践(09): 使用 GPU Operator搭建AI算力环境&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这两篇则分析了 device-plugin 原理以及在 K8s 中创建一个申请 GPU 的 Pod 后的一些列动作，最终该 Pod 是如何使用到 GPU 的。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.mospan.cn/2024/01/24/device-plugin/&#34;&gt;K8S项目实践(10): device-plugin原理到实现&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.mospan.cn/2024/01/27/pod-use-gpu/&#34;&gt;K8S项目实践(11): Pod 是如何使用到 GPU 的及源码分析&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;看完之后，大家应该就大致明白了。&lt;/p&gt;

&lt;h2 id=&#34;资源感知&#34;&gt;资源感知&lt;/h2&gt;

&lt;p&gt;首先在 k8s 中资源是和节点绑定的，对于 GPU 资源，我们使用 NVIDIA 提供的 device-plugin 进行感知，并上报到 kube-apiserver,这样我们就能在 Node 对象上看到对应的资源了。&lt;/p&gt;

&lt;p&gt;就像这样：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 ~]# kubectl  describe node k8s-worker1 | grep Capacity: -A8
Capacity:
  cpu:                   4
  ephemeral-storage:     123460788Ki
  hugepages-1Gi:         0
  hugepages-2Mi:         0
  lixueduan.com/gopher:  2
  memory:                9922140Ki
  nvidia.com/gpu:        1
  pods:                  110
[root@k8s-master1 ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，该节点除了基础的 cpu、memory 之外，还有一个nvidia.com/gpu: 1 信息，表示该节点上有 1 个 GPU。&lt;/p&gt;

&lt;h2 id=&#34;资源申请&#34;&gt;资源申请&lt;/h2&gt;

&lt;p&gt;然后我们就可以在创建 Pod 时申请对应的资源了，比如申请一个 GPU：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  name: cuda-vectoradd
spec:
  restartPolicy: OnFailure
  containers:
  - name: cuda-vectoradd
    image: &amp;quot;nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2&amp;quot;
    resources:
      limits:
        nvidia.com/gpu: 1
    command: [&amp;quot;nvidia-smi&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;apply 该 yaml 之后，kube-scheduler 在调度该 Pod 时就会将其调度到一个拥有足够 GPU 资源的 Node 上。&lt;/p&gt;

&lt;p&gt;同时该 Pod 申请的部分资源也会标记为已使用，不会再分配给其他 Pod。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;post/20224/images/2024-02-05-hami-vgpu-split/IMG_20250205-100211174.png&#34; alt=&#34;picture 0&#34; /&gt;&lt;/p&gt;

&lt;p&gt;到这里，问题的答案就已经很明显的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1）device-plugin 感知到节点上的物理 GPU 数量，上报到 kube-apiserver&lt;/li&gt;
&lt;li&gt;2）kube-scheduler 调度 Pod 时会根据 pod 中的 Request 消耗对应资源
即：&lt;em&gt;Node 上的 GPU 资源被 Pod 申请之后，在 k8s 中就被标记为已消耗了，后续创建的 Pod 会因为资源不够导致无法调度。&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实际上：可能 GPU 性能比较好，可以支持多个 Pod 共同使用，但是因为 k8s 中的调度限制导致多个 Pod 无法正常共享。&lt;/p&gt;

&lt;p&gt;因此，我们才需要 GPU 共享、切分等方案。&lt;/p&gt;

&lt;p&gt;上一篇文章&lt;a href=&#34;http://blog.mospan.cn/2024/01/31/gpu-time-slicing/&#34;&gt;K8S项目实践(12): GPU共享方案Time Slicing&lt;/a&gt;中给大家分享了一个 GPU 共享方案。&lt;/p&gt;

&lt;p&gt;可以实现多个 Pod 共享同一个 GPU，但是存在一个问题：Pod 之间并未做任何隔离，每个 Pod 能用到多少 GPU core、memory 都靠竞争，可能会导致部分 Pod 占用大部分资源导致其他 Pod 无法正常使用的情况。&lt;/p&gt;

&lt;p&gt;今天给大家分享一个开源的 vGPU 方案 &lt;a href=&#34;https://github.com/Project-HAMi/HAMi&#34;&gt;HAMi&lt;/a&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ps：NVIDIA 也有自己的 vGPU 方案，但是需要 license&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;什么是-hami&#34;&gt;什么是 HAMi？&lt;/h1&gt;

&lt;p&gt;HAMi 全称是：Heterogeneous AI Computing Virtualization Middleware，HAMi 给自己的定位或者希望是做一个异构算力虚拟化平台。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;原 第四范式 k8s-vgpu-scheduler, 这次改名 HAMi 同时也将核心的 vCUDA 库 libvgpu.so 也开源了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;但是现在比较完善的是对 NVIDIA GPU 的 vGPU 方案，因此我们可以简单认为他就是一个 vGPU 方案。&lt;/p&gt;

&lt;p&gt;整体架构如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-02-05-hami-vgpu-split/IMG_20250205-101305158.png&#34; alt=&#34;picture 1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到组件还是比较多的，涉及到 Webhook、Scheduler、Device Plugin、HAMi-Core 等等。&lt;/p&gt;

&lt;p&gt;这篇文章只讲使用，因此架构、原理就一笔带过，后续也会有相关文章,欢迎关注~。&lt;/p&gt;

&lt;h2 id=&#34;特性&#34;&gt;特性&lt;/h2&gt;

&lt;p&gt;使用 HAMi 最大的一个功能点就是可以实现 GPU 的细粒度的隔离，可以对 core 和 memory 使用 1% 级别的隔离。&lt;/p&gt;

&lt;p&gt;具体如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  containers:
    - name: ubuntu-container
      image: ubuntu:18.04
      command: [&amp;quot;bash&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;sleep 86400&amp;quot;]
      resources:
        limits:
          nvidia.com/gpu: 1 # 请求1个vGPUs
          nvidia.com/gpumem: 3000 # 每个vGPU申请3000m显存 （可选，整数类型）
          nvidia.com/gpucores: 30 # 每个vGPU的算力为30%实际显卡的算力 （可选，整数类型）
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;nvidia.com/gpu：请求一个 GPU&lt;/li&gt;
&lt;li&gt;nvidia.com/gpumem：只申请使用 3000M GPU Memory&lt;/li&gt;
&lt;li&gt;nvidia.com/gpucores：申请使用 30% 的 GPU core，也就是该 Pod 只能使用到 30% 的算力
相比于上文分享了 TimeSlicing 方案，HAMi 则是实现了 GPU core 和 memory 的隔离。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;在开源方案里面已经算是比较优秀的了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;特性-1&#34;&gt;特性&lt;/h2&gt;

&lt;p&gt;HAMi 实现GPU core 和 memory 隔离、限制是使用的 vCUDA 方案，具体设计如下：
&lt;img src=&#34;post/2024/images/2024-02-05-hami-vgpu-split/IMG_20250205-102943833.png&#34; alt=&#34;picture 2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;HAMi 使用的是软件层面的 vCUDA 方案，对 NVIDIA 原生的 CUDA 驱动进行重写(libvgpu.so)，然后挂载到 Pod 中进行替换，然后在自己的实现的 CUDA 驱动中对 API 进行拦截，实现资源隔离以及限制的效果。&lt;/p&gt;

&lt;p&gt;例如：原生 libvgpu.so 在进行内存分配时，只有在 GPU 内存真的用完的时候才会提示 CUDA OOM，但是对于 HAMi 实现的 libvgpu.so 来说，检测到 Pod 中使用的内存超过了 Resource 中的申请量就直接返回 OOM，从而实现资源的一个限制。&lt;/p&gt;

&lt;p&gt;然后在执行 nvidia-smi 命令查看 GPU 信息时，也只返回 Pod Resource 中申请的资源，这样在查看时也进行隔离。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ps：需要对 CUDA 和 NVML 的部分 API 拦截。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;hami-部署&#34;&gt;HAMi 部署&lt;/h1&gt;

&lt;p&gt;HAMi 提供了 Helm Chart 安装也是比较简单的。&lt;/p&gt;

&lt;h2 id=&#34;部署-gpu-operator&#34;&gt;部署 GPU Operator&lt;/h2&gt;

&lt;p&gt;需要注意的是 HAMi 会依赖 NVIDIA 的那一套，因此推荐先部署 GPU-Operator。&lt;/p&gt;

&lt;p&gt;参考这篇文章 –&amp;gt; &lt;a href=&#34;http://blog.mospan.cn/2024/01/17/gpu-operator/&#34;&gt;K8S项目实践(09): 使用 GPU Operator搭建AI算力环境&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;部署好 GPU Operator 之后在部署 HAMi。&lt;/p&gt;

&lt;h2 id=&#34;准备镜像&#34;&gt;准备镜像&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;crictl pull ghcr.io/stackhpc/kube-webhook-certgen:v1.1.1

ctr -n k8s.io image tag  ghcr.io/stackhpc/kube-webhook-certgen:v1.1.1  liangjw/kube-webhook-certgen:v1.1.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;部署-hami&#34;&gt;部署 HAMi&lt;/h2&gt;

&lt;p&gt;首先使用 helm 添加我们的 repo&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;helm repo add hami-charts https://project-hami.github.io/HAMi/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;随后，使用下列指令获取集群服务端版本
&amp;gt; 这里使用的是 v1.28.15版本&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在安装过程中须根据集群服务端版本（上一条指令的结果）指定调度器镜像版本，例如集群服务端版本为 v1.28.5，则可以使用如下指令进行安装&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;helm install hami hami-charts/hami --set scheduler.kubeScheduler.imageTag=v1.28.5 -n kube-system
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过kubectl get pods指令看到 vgpu-device-plugin 与 vgpu-scheduler 两个pod 状态为Running 即为安装成功&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>K8S项目实践(12): GPU共享方案Time Slicing</title>
            <link>http://mospany.github.io/2024/01/31/gpu-time-slicing/</link>
            <pubDate>Wed, 31 Jan 2024 19:31:10 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2024/01/31/gpu-time-slicing/</guid>
            <description>

&lt;p&gt;本文主要分享 GPU 共享方案，包括如何安装、配置以及使用，最后通过分析源码了 TimeSlicing 的具体实现。通过配置 TimeSlicing 可以实现 Pod 共享一块物理 GPU(使用GRID GPU代替)，以提升资源利用率。&lt;/p&gt;

&lt;h1 id=&#34;1-为什么需要-gpu-共享-切分等方案&#34;&gt;1. 为什么需要 GPU 共享、切分等方案？&lt;/h1&gt;

&lt;p&gt;开始之前我们先思考一个问题，&lt;em&gt;为什么需要 GPU 共享、切分等方案?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;或者说是另外一个问题：&lt;em&gt;明明直接在裸机环境使用，都可以多个进程共享 GPU，怎么到 k8s 环境就不行了。&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;1-1-资源感知&#34;&gt;1.1. 资源感知&lt;/h2&gt;

&lt;p&gt;首先在 k8s 中资源是和节点绑定的，对于 GPU 资源，我们使用 NVIDIA 提供的 device-plugin 进行感知，并上报到 kube-apiserver,这样我们就能在 Node 对象上看到对应的资源了。&lt;/p&gt;

&lt;p&gt;就像这样：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@liqivm:~# k describe node gpu01|grep Capacity -A 7
Capacity:
  cpu:                128
  ephemeral-storage:  879000896Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             1056457696Ki
  nvidia.com/gpu:     8
  pods:               110
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，该节点除了基础的 cpu、memory 之外，还有一个nvidia.com/gpu: 8 信息，表示该节点上有 8 个 GPU。&lt;/p&gt;

&lt;h2 id=&#34;1-2-资源申请&#34;&gt;1.2. 资源申请&lt;/h2&gt;

&lt;p&gt;然后我们就可以在创建 Pod 时申请对应的资源了，比如申请一个 GPU：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  containers:
  - name: gpu-container
    image: nvidia/cuda:11.0-base   # 一个支持 GPU 的镜像
    resources:
      limits:
        nvidia.com/gpu: 1          # 申请 1 个 GPU
    command: [&amp;quot;nvidia-smi&amp;quot;]         # 示例命令，显示 GPU 的信息
  restartPolicy: OnFailure
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;apply 该 yaml 之后，kube-scheduler 在调度该 Pod 时就会将其调度到一个拥有足够 GPU 资源的 Node 上。&lt;/p&gt;

&lt;p&gt;同时该 Pod 申请的部分资源也会标记为已使用，不会在分配给其他 Pod。&lt;/p&gt;

&lt;p&gt;到这里，问题的答案就已经很明显的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1）device-plugin 感知到节点上的物理 GPU 数量，上报到 kube-apiserver&lt;/li&gt;
&lt;li&gt;2）kube-scheduler 调度 Pod 时会根据 pod 中的 Request 消耗对应资源&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;即：&lt;em&gt;Node 上的 GPU 资源被 Pod 申请之后，在 k8s 中就被标记为已消耗了，后续创建的 Pod 会因为资源不够导致无法调度。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;实际上：可能 GPU 性能比较好，可以支持多个 Pod 共同使用，但是因为 k8s 中的调度限制导致多个 Pod 无法正常共享。&lt;/p&gt;

&lt;p&gt;因此，我们才需要 GPU 共享、切分等方案。&lt;/p&gt;

&lt;h1 id=&#34;2-什么是-time-slicing-方案&#34;&gt;2. 什么是 Time Slicing 方案&lt;/h1&gt;

&lt;p&gt;NVIDIA 提供的 &lt;a href=&#34;https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-sharing.html&#34;&gt;Time-Slicing GPUs in Kubernetes&lt;/a&gt; 是一种通过 oversubscription(超额订阅) 来实现 GPU 共享的策略，这种策略能让多个任务在同一个 GPU 上进行，而不是每个任务都独占一个 GPU。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;虽然方案名称叫做 Time Slicing，但是device-plugin 的实现上和时间切片没有任何关系，实际上是一个 GPU 超卖方案。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;2-1-为什么要叫time-slicing-时间片&#34;&gt;2.1. 为什么要叫Time Slicing(时间片)？&lt;/h2&gt;

&lt;p&gt;虽然实现上只是 *oversubscription(超额订阅)*，但是名称中的 Time Slicing(时间片)指的是 GPU 本身的时间片调度。&lt;/p&gt;

&lt;p&gt;例如：A、B、C 三个进程共享 GPU，三个进程同时把 CUDA 任务发射到 GPU 上去，GPU 并不会同时执行，而是采用时间片轮转调度的方式。&lt;/p&gt;

&lt;p&gt;首先第一个时间片，A 任务被执行，接着第二个时间片，执行 B 任务，第三个时间片， C 任务将被执行。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;时间片是依次进行轮转调度的，分别执行A、B、C中的任务。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;2-2-效果&#34;&gt;2.2. 效果&lt;/h2&gt;

&lt;p&gt;比如节点上只有一个物理 GPU，正常安装 GPU Operator 之后，device plugin 检测到该节点上有 1 个 GPU，上报给 kubelet，然后 kubelet 更新到 kube-apiserver，我们就可以在 Node 对象上看到了：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@liqivm:~# k describe node gpu01|grep Capacity -A 7
Capacity:
  cpu:                128
  ephemeral-storage:  879000896Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             1056457696Ki
  nvidia.com/gpu:     1
  pods:               110
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;此时，创建一个 Pod 申请 1 个 GPU 之后，第二个 Pod 就无法使用了，因为 GPU 资源不足无法调度。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;但是 Time Slicing 可以进行 oversubscription 设置，将 device-plugin 上报的 GPU 数量进行扩大。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;比如将其数量放大 10 倍，device plugin 就会上报该节点有 1*10 = 10 个 GPU，最终 kube-apiserver 则会记录该节点有 10 个 GPU：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@liqivm:~# k describe node gpu01|grep Capacity -A 7
Capacity:
  cpu:                128
  ephemeral-storage:  879000896Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             1056457696Ki
  nvidia.com/gpu:     10
  pods:               110
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样，就可以供 10 个 Pod 使用了。&lt;/p&gt;

&lt;p&gt;当然了，Time Slicing 方案也有缺点：多个 Pod 之间没有内存或者故障隔离，完全的共享，能使用多少内存和算力全靠多个 Pod 自行竞争。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ps：就和直接在宿主机上多个进程共享一个 GPU 基本一致&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;3-time-slicing-demo&#34;&gt;3. Time Slicing Demo&lt;/h1&gt;

&lt;p&gt;Time Slicing 由于是 NVIDIA 的方案，因此使用起来比较简单，只需要在部署完成 GPU Operator 之后进行配置即可。&lt;/p&gt;

&lt;p&gt;首先参考这篇文章完成 GPU Operator 的部署 –&amp;gt; GPU 环境搭建指南：&lt;a href=&#34;http://blog.mospan.cn/2024/01/17/gpu-operator/&#34;&gt;使用 GPU Operator搭建AI算力环境&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;然后即可开始配置 TimeSlicing。&lt;/p&gt;

&lt;p&gt;整体配置分为以下 3 个步骤：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1）创建 TimeSlicing 配置

&lt;ul&gt;
&lt;li&gt;根据官方文档描述，修改了 TimeSlicing 配置之后，device plugin Pod 不会自动重启，因此新的配置不会生效,需要手动重启对应 Pod。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2）修改集群策略开启 Time Slicing，并指定让 device-plugin 使用第一步中创建的配置

&lt;ul&gt;
&lt;li&gt;这里则是通过 Configmap 名称来指定&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;3）（可选）给要使用 GPU TimeSlicing 的节点打上对应 label，实现不同 Node 使用不同策略

&lt;ul&gt;
&lt;li&gt;比如不同节点上的 GPU 不同，那么可以根据 GPU 的算力或者内存情况设置不同的副本数以合理利用资源&lt;/li&gt;
&lt;li&gt;如果都是统一 GPU，则使用集群级别的统一配置即可&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;3-1-配置开启-timeslicing&#34;&gt;3.1. 配置开启 TimeSlicing&lt;/h2&gt;

&lt;h3 id=&#34;3-1-1-创建-timeslicing-配置&#34;&gt;3.1.1. 创建 TimeSlicing 配置&lt;/h3&gt;

&lt;p&gt;使用一个单独的 Configmap 来存放 TimeSlicing 的配置。&lt;/p&gt;

&lt;p&gt;这里使用集群级别的统一配置，配置文件 time-slicing-config-all.yaml 完整内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: ConfigMap
metadata:
  name: time-slicing-config-all
data:
  any: |-
    version: v1
    flags:
      migStrategy: none
    sharing:
      timeSlicing:
        renameByDefault: false
        failRequestsGreaterThanOne: false
        resources:
          - name: nvidia.com/gpu
            replicas: 4    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体配置含义参考官方文档：&lt;a href=&#34;https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-sharing.html#about-configuring-gpu-time-slicing&#34;&gt;about-configuring-gpu-time-slicing&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;data.&lt;key&gt;： 配置的名字，可以为不同 Node 设置单独配置，后续通过名称引用对应配置。

&lt;ul&gt;
&lt;li&gt;后续开启 TimeSlicing 时则根据 key 指定使用不同配置&lt;/li&gt;
&lt;li&gt;这里我们使用集群统一配置，因此创建一个 key 即可&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;flags.migStrategy：配置开启时间片之后如何处理 MIG 设备，默认为 none&lt;/li&gt;
&lt;li&gt;renameByDefault：是否对 GPU 资源改名。

&lt;ul&gt;
&lt;li&gt;设置为 true 之后，会使用&lt;resource-name&gt;.shared 替代原本的 &lt;resource-name&gt;。例如 nvidia.com/gpu 会变成 nvidia.com/gpu.shared ，显式告知使用者这是共享 GPU。&lt;/li&gt;
&lt;li&gt;默认为 false，即不改资源类型名，不过 Node 上的 label 也会改，比如使用时间片之前是nvidia.com/gpu.product=Tesla-T4, 使用后就会变成nvidia.com/gpu.product=Tesla-T4-SHARED 这样依旧可以通过 nodeSelector 来限制 Pod 调度节点，来控制是否使用共享的 GPU&lt;/li&gt;
&lt;li&gt;推荐使用 fasle 即可&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;failRequestsGreaterThanOne：开启后，当 Pod 请求 1 个以上的 shared GPU 时直接报错 UnexpectedAdmissionError。这个字段是通过报错的方式告诉使用者，请求多个 shared GPU 并不会增加 Pod 对该共享 GPU 的占用时间。&lt;/li&gt;
&lt;li&gt;resources.name：要通过时间分片提供访问的资源类似，比如nvidia.com/gpu&lt;/li&gt;
&lt;li&gt;resources.replicas：可共享访问的资源数量，比如这里指定的 4 也就是 1 个该类型的 GPU 可以供 4 个 Pod 共享访问，也就是最终 Pod 上看到的 GPU 数量是物理 GPU 数量的 4 倍。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;将配置 Apply 到 gpu-operator 所在的 namespace&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl create -n gpu-operator -f time-slicing-config-all.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-1-2-修改集群策略&#34;&gt;3.1.2. 修改集群策略&lt;/h3&gt;

&lt;p&gt;修改clusterpolicies.nvidia.com/cluster-policy 对象，让 device plugin 使用上一步创建的配置。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl patch clusterpolicies.nvidia.com/cluster-policy \
    -n gpu-operator --type merge \
    -p &#39;{&amp;quot;spec&amp;quot;: {&amp;quot;devicePlugin&amp;quot;: {&amp;quot;config&amp;quot;: {&amp;quot;name&amp;quot;: &amp;quot;time-slicing-config-all&amp;quot;, &amp;quot;default&amp;quot;: &amp;quot;any&amp;quot;}}}}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;name：time-slicing-config-all 指定了配置文件对应的 Configmap 名称&lt;/li&gt;
&lt;li&gt;default：any：表示默认配置为这个 Configmap 中的 key 为 any 的配置
修改后 gpu-feature-discovery 和 nvidia-device-plugin-daemonset pod 会重启，使用以下命令查看重启过程&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl get events -n gpu-operator --sort-by=&#39;.lastTimestamp&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-31-gpu-time-slicing/IMG_20250201-215925170.png&#34; alt=&#34;picture 0&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;3-2-验证-timeslicing-是否生效&#34;&gt;3.2. 验证 TimeSlicing 是否生效&lt;/h2&gt;

&lt;h3 id=&#34;3-2-1-查看-node-上的-gpu-信息&#34;&gt;3.2.1. 查看 Node 上的 GPU 信息&lt;/h3&gt;

&lt;p&gt;首先查看一下 Node 信息，确认 TimeSlicing 生效了&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl  describe node k8s-worker1 | grep Capacity -A20
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-31-gpu-time-slicing/IMG_20250201-221241899.png&#34; alt=&#34;picture 1&#34; /&gt;&lt;br /&gt;
gpu为1*4=4显示成功。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;...
Labels:
                  nvidia.com/gpu.count=1
                  nvidia.com/gpu.product=GRID-T4-2Q-SHARED
                  nvidia.com/gpu.replicas=4
Capacity:
  nvidia.com/gpu: 4
  ...
Allocatable:
  nvidia.com/gpu: 4
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;增加了几个 label，&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;nvidia.com/gpu.product=GRID-T4-2Q-SHARED&lt;/li&gt;
&lt;li&gt;nvidia.com/gpu.replicas=4&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;根据nvidia.com/gpu.count=1 可知，节点上有 1 张 GPU，然后由于使用了时间片，且配置的nvidia.com/gpu.replicas=4 副本数为 4，因此最终节点上 device plugin 上报的 GPU 数量就是 1*4 = 4 个。&lt;/p&gt;

&lt;h2 id=&#34;3-3-验证-gpu-能否正常使用&#34;&gt;3.3. 验证 GPU 能否正常使用&lt;/h2&gt;

&lt;p&gt;创建一个 Deployment 来验证，GPU 能否正常使用。&lt;/p&gt;

&lt;p&gt;这里副本数指定为 2，因为集群里只有 1 张 GPU，如果 TimeSlicing 未生效，那么有一个 Pod 肯定会应为拿不到 GPU 资源而 pending。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: time-slicing-verification
  labels:
    app: time-slicing-verification
spec:
  replicas: 2
  selector:
    matchLabels:
      app: time-slicing-verification
  template:
    metadata:
      labels:
        app: time-slicing-verification
    spec:
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      hostPID: true
      containers:
        - name: cuda-sample-vector-add
          image: &amp;quot;nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2&amp;quot;
          command: [&amp;quot;/bin/bash&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;--&amp;quot;]
          args:
            - while true; do /tmp/vectorAdd; done
          resources:
           limits:
             nvidia.com/gpu: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会启动 2个 Pod，&lt;/p&gt;

&lt;p&gt;查看情况
&lt;img src=&#34;post/2024/images/2024-01-31-gpu-time-slicing/IMG_20250201-224915379.png&#34; alt=&#34;picture 2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;2 个 Pod 都启动了，说明时间片时成功的。&lt;/p&gt;

&lt;p&gt;随便查看一个 Pod 的日志&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@k8s-master1 timeSlicing]# kubectl logs time-slicing-verification-56487b549d-nqn6s 
[Vector addition of 50000 elements]
Copy input data from the host memory to the CUDA device
CUDA kernel launch with 196 blocks of 256 threads
Copy output data from the CUDA device to the host memory
Test PASSED
Done
[Vector addition of 50000 elements]
Copy input data from the host memory to the CUDA device
CUDA kernel launch with 196 blocks of 256 threads
Copy output data from the CUDA device to the host memory
Test PASSED
Done
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;有 Test PASSED 则说明成功了。&lt;/p&gt;

&lt;p&gt;说明 TimeSlicing 配置生效了。&lt;/p&gt;

&lt;h1 id=&#34;4-使用-node-级别的单独配置&#34;&gt;4. 使用 Node 级别的单独配置&lt;/h1&gt;

&lt;p&gt;前面只创建了一个名称为 any 的配置，并在 clusterpolicy 中指明了使用该配置为默认配置，因此集群中的全部节点都会使用该配置来做时间片。&lt;/p&gt;

&lt;p&gt;但是可能*集群中不同节点上的 GPU 型号不同*，因此需要共享分副本数可以调整，性能好的副本数就调大一点，性能差的就小一点。&lt;/p&gt;

&lt;p&gt;本章主要记录怎么为不同的节点使用不同的配置。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;实际上是为不同的 GPU 准备不同的配置。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;4-1-创建时间片配置&#34;&gt;4.1. 创建时间片配置&lt;/h2&gt;

&lt;p&gt;同样的创建 TimeSlicing 配置，不过这次 Configmap 中写了两个配置，而且是以 GPU 型号命名的&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: ConfigMap
metadata:
  name: time-slicing-config-fine
data:
  a100-40gb: |-
    version: v1
    flags:
      migStrategy: mixed
    sharing:
      timeSlicing:
        resources:
        - name: nvidia.com/gpu
          replicas: 8
        - name: nvidia.com/mig-1g.5gb
          replicas: 2
        - name: nvidia.com/mig-2g.10gb
          replicas: 2
        - name: nvidia.com/mig-3g.20gb
          replicas: 3
        - name: nvidia.com/mig-7g.40gb
          replicas: 7    
  tesla-t4: |-
    version: v1
    flags:
      migStrategy: none
    sharing:
      timeSlicing:
        resources:
        - name: nvidia.com/gpu
          replicas: 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，分别对 A100 和 Tesla T4 这两种 GPU 做了配置。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a100-40gb：A100 支持 MIG，因此增加了 MIG 部分的配置，若没有则指定为 none 即可

&lt;ul&gt;
&lt;li&gt;然后根据 MIG 实例分别指定不同的 replicas 数&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;tesla-t4：Tesla T4 GPU 性能比较差，因此 replicas 指定为 4 即可
将配置 Apply 到 gpu-operator 所在的 namespace&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl  create -n gpu-operator -f time-slicing-config-fine.yaml 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-31-gpu-time-slicing/IMG_20250204-201203558.png&#34; alt=&#34;picture 3&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;4-2-修改集群策略&#34;&gt;4.2. 修改集群策略&lt;/h2&gt;

&lt;p&gt;同样的，修改一下 cluster-policy 指定 device plugin 使用的 Configmap，这次与之前的区别在于，*这里没有指定 default 配置*。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl patch clusterpolicies.nvidia.com/cluster-policy \
-n gpu-operator --type merge \
-p &#39;{&amp;quot;spec&amp;quot;: {&amp;quot;devicePlugin&amp;quot;: {&amp;quot;config&amp;quot;: {&amp;quot;name&amp;quot;: &amp;quot;time-slicing-config-fine&amp;quot;}}}}&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;没有指定 default 时，device-plugin 则会根据 node 上的 label (nvidia.com/device-plugin.config)来获取要使用的配置。&lt;/p&gt;

&lt;h2 id=&#34;4-3-为节点打-label&#34;&gt;4.3. 为节点打 label&lt;/h2&gt;

&lt;p&gt;在节点上打上下面的 label，这样该节点上的 device plugin 就会根据该 label 的 value 来使用对应名字的配置了。&lt;/p&gt;

&lt;p&gt;比如这里，就是有这个 label 的节点就使用名叫 tesla-t4 的配置。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl label node k8s-worker1 nvidia.com/device-plugin.config=tesla-t4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一般都是以 GPU 型号命名，然后给使用该 GPU 的节点都打上对应 label,这样便于查看。&lt;/p&gt;

&lt;h2 id=&#34;4-4-验证&#34;&gt;4.4. 验证&lt;/h2&gt;

&lt;p&gt;查看node节点gpu卡数是否已为5.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl  describe node k8s-worker1 | grep Capacity -A20
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-31-gpu-time-slicing/IMG_20250204-203630774.png&#34; alt=&#34;picture 4&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;5-关闭-timeslicing&#34;&gt;5. 关闭 TimeSlicing&lt;/h1&gt;

&lt;p&gt;想关闭 TimeSlicing 配置也很简单，直接更新 集群策略 把 device plugin 下的 config 这一段去掉即可。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;  devicePlugin:
    config:
      default: any
      name: time-slicing-config-fine
    enabled: true
    env:
    - name: PASS_DEVICE_SPECS
      value: &amp;quot;true&amp;quot;
    - name: FAIL_ON_INIT_ERROR
      value: &amp;quot;true&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl patch clusterpolicies.nvidia.com/cluster-policy -n gpu-operator --type json -p &#39;[{&amp;quot;op&amp;quot;: &amp;quot;remove&amp;quot;, &amp;quot;path&amp;quot;: &amp;quot;/spec/devicePlugin/config&amp;quot;}]&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后重启一下 device-plugin pod&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl rollout restart -n gpu-operator daemonset/nvidia-device-plugin-daemonset
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不出意外的话就关掉了，再次查看 Pod 信息，GPU 就变成了物理 GPU 数量，说明关闭成功。
&lt;img src=&#34;post/2024/images/2024-01-31-gpu-time-slicing/IMG_20250204-204613867.png&#34; alt=&#34;picture 5&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;6-源码分析&#34;&gt;6. 源码分析&lt;/h1&gt;

&lt;p&gt;简单看下源码，分析 TimeSlicing 是怎么实现的。&lt;/p&gt;

&lt;p&gt;首先是 device-plugin 可以接收的配置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// api/config/v1/config.go#L32
// Config is a versioned struct used to hold configuration information.
type Config struct {
	Version   string    `json:&amp;quot;version&amp;quot;             yaml:&amp;quot;version&amp;quot;`
	Flags     Flags     `json:&amp;quot;flags,omitempty&amp;quot;     yaml:&amp;quot;flags,omitempty&amp;quot;`
	Resources Resources `json:&amp;quot;resources,omitempty&amp;quot; yaml:&amp;quot;resources,omitempty&amp;quot;`
	Sharing   Sharing   `json:&amp;quot;sharing,omitempty&amp;quot;   yaml:&amp;quot;sharing,omitempty&amp;quot;`
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这也就是我们在 clusterPolicy 中配置的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: ConfigMap
metadata:
  name: time-slicing-config-all
data:
  any: |-
    version: v1
    flags:
      migStrategy: none
    sharing:
      timeSlicing:
        renameByDefault: false
        failRequestsGreaterThanOne: false
        resources:
          - name: nvidia.com/gpu
            replicas: 4    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里我们关注 resources 中的 replicas 参数，正是这个参数定义了 oversubscription(超额订阅) 的额度。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;        resources:
          - name: nvidia.com/gpu
            replicas: 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看下代码中是什么生效的&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// internal/rm/device_map.go#L282

// updateDeviceMapWithReplicas returns an updated map of resource names to devices with replica
// information from the active replicated resources config.
func updateDeviceMapWithReplicas(replicatedResources *spec.ReplicatedResources, oDevices DeviceMap) (DeviceMap, error) {
	devices := make(DeviceMap)

	// Begin by walking replicatedResources.Resources and building a map of just the resource names.
	names := make(map[spec.ResourceName]bool)
	for _, r := range replicatedResources.Resources {
		names[r.Name] = true
	}

	// Copy over all devices from oDevices without a resource reference in TimeSlicing.Resources.
	for r, ds := range oDevices {
		if !names[r] {
			devices[r] = ds
		}
	}

	// Walk shared Resources and update devices in the device map as appropriate.
	for _, resource := range replicatedResources.Resources {
		r := resource
		// Get the IDs of the devices we want to replicate from oDevices
		ids, err := oDevices.getIDsOfDevicesToReplicate(&amp;amp;r)
		if err != nil {
			return nil, fmt.Errorf(&amp;quot;unable to get IDs of devices to replicate for &#39;%v&#39; resource: %v&amp;quot;, r.Name, err)
		}
		// Skip any resources not matched in oDevices
		if len(ids) == 0 {
			continue
		}

		// Add any devices we don&#39;t want replicated directly into the device map.
		for _, d := range oDevices[r.Name].Difference(oDevices[r.Name].Subset(ids)) {
			devices.insert(r.Name, d)
		}

		// Create replicated devices add them to the device map.
		// Rename the resource for replicated devices as requested.
		name := r.Name
		if r.Rename != &amp;quot;&amp;quot; {
			name = r.Rename
		}
		for _, id := range ids {
			for i := 0; i &amp;lt; r.Replicas; i++ {
				annotatedID := string(NewAnnotatedID(id, i))
				replicatedDevice := *(oDevices[r.Name][id])
				replicatedDevice.ID = annotatedID
				replicatedDevice.Replicas = r.Replicas
				devices.insert(name, &amp;amp;replicatedDevice)
			}
		}
	}

	return devices, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;核心部分如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;for _, id := range ids {
  for i := 0; i &amp;lt; r.Replicas; i++ {
    annotatedID := string(NewAnnotatedID(id, i))
    replicatedDevice := *(oDevices[r.Name][id])
    replicatedDevice.ID = annotatedID
    replicatedDevice.Replicas = r.Replicas
    devices.insert(name, &amp;amp;replicatedDevice)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，这里是双层 for 循环，对 device 数量进行了一个复制的操作，这样每张 GPU 都可以被使用 Replicas 次了。&lt;/p&gt;

&lt;p&gt;其他属性都没变，只是把 deviceID 进行了处理，便于区分&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// NewAnnotatedID creates a new AnnotatedID from an ID and a replica number.
func NewAnnotatedID(id string, replica int) AnnotatedID {
	return AnnotatedID(fmt.Sprintf(&amp;quot;%s::%d&amp;quot;, id, replica))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在真正挂载时则进行 split 拿到 id 和 replicas 信息&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Split splits a AnnotatedID into its ID and replica number parts.
func (r AnnotatedID) Split() (string, int) {
	split := strings.SplitN(string(r), &amp;quot;::&amp;quot;, 2)
	if len(split) != 2 {
		return string(r), 0
	}
	replica, _ := strconv.ParseInt(split[1], 10, 0)
	return split[0], int(replica)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此，我们就分析完了 TimeSlicing 的具体实现，其实很简单，就是根据配置的 replicas 参数对 device plugin 感知到的设备进行复制，并在 DeviceID 使用特定格式进行标记便于区分。&lt;/p&gt;

&lt;h1 id=&#34;7-小结&#34;&gt;7. 小结&lt;/h1&gt;

&lt;p&gt;本文主要分享了 NVIDIA Time Slicing 这个 GPU 共享方案,包括即实现原理，以及配置和使用方式。&lt;/p&gt;

&lt;p&gt;最后通过分析源码的方式探索了 TimeSlicing 的代码实现。&lt;/p&gt;

&lt;h2 id=&#34;7-1-为什么需要-gpu-共享-切分&#34;&gt;7.1. 为什么需要 GPU 共享、切分？&lt;/h2&gt;

&lt;p&gt;在 k8s 中使用默认 device plugin 时，GPU 资源和物理 GPU 是一一对应的，导致一个物理 GPU 被一个 Pod 申请后，其他 Pod 就无法使用了。&lt;/p&gt;

&lt;p&gt;为了提高资源利用率，因此我们需要 GPU 共享、切分等方案。&lt;/p&gt;

&lt;h2 id=&#34;7-2-什么是-timeslicing&#34;&gt;7.2. 什么是 TimeSlicing？&lt;/h2&gt;

&lt;p&gt;TimeSlicing 是一种通过 oversubscription(超额订阅) 来实现 GPU 共享的策略，这种策略能让多个任务在同一个 GPU 上进行，而不是每个任务都独占一个 GPU。&lt;/p&gt;

&lt;h2 id=&#34;7-3-如何开启-timeslicing&#34;&gt;7.3. 如何开启 TimeSlicing&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1）创建 TimeSlicing 配置&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;可以是集群统一配置，也可以是 Node 级别的配置，主要根据不同节点上的 GPU 进行配置&lt;/li&gt;
&lt;li&gt;如果集群中所有节点 GPU 型号都一致，则使用集群统一配置即可，若不一致则根据 节点上的 GPU 性能修改配置&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2）修改 cluster-policy，增加 TimeSlicing 相关配置&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;作为这两个步骤之后，TimeSlicing 就开启了，再次查看 Node 信息时会发现 GPU 数量变多了。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;7-4-timeslicing-实现原理&#34;&gt;7.4. TimeSlicing 实现原理&lt;/h2&gt;

&lt;p&gt;根据配置的 replicas 参数对 device plugin 感知到的设备进行复制，并在 DeviceID 使用特定格式进行标记便于区分。&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>K8S项目实践(11): Pod 是如何使用到 GPU 的及源码分析</title>
            <link>http://mospany.github.io/2024/01/27/pod-use-gpu/</link>
            <pubDate>Sat, 27 Jan 2024 19:31:10 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2024/01/27/pod-use-gpu/</guid>
            <description>

&lt;p&gt;本文主要分析了在 K8s 中创建一个 Pod 并申请 GPU 资源，最终该 Pod 时怎么能够使用 GPU 的，具体的实现原理，以及 device plugin、nvidia-container-toolkit 相关源码分析。&lt;/p&gt;

&lt;h1 id=&#34;1-概述&#34;&gt;1. 概述&lt;/h1&gt;

&lt;p&gt;这篇文章则是将整个流程连起来做一个简单分析，即：宿主机上的 GPU 是怎么能够被 K8s 中的 Pod 使用的。&lt;/p&gt;

&lt;p&gt;可以分为以下两部分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;k8s 是如何感知到 GPU 的&lt;/li&gt;
&lt;li&gt;GPU 是如何分配给 Pod 的&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;2-工作流程&#34;&gt;2. 工作流程&lt;/h1&gt;

&lt;p&gt;这部分主要分享一下 NVIDIA 的 device-plugin 以及 nvidia-container-toolkit 的工作流程，以及二者是怎么配合的。&lt;/p&gt;

&lt;h2 id=&#34;2-1-k8s-是如何感知到-gpu-的&#34;&gt;2.1. k8s 是如何感知到 GPU 的&lt;/h2&gt;

&lt;p&gt;NVIDIA 实现了&lt;a href=&#34;https://github.com/NVIDIA/k8s-device-plugin&#34;&gt;NVIDIA/k8s-device-plugin&lt;/a&gt; 来使得节点上的 GPU 能够被 k8s 感知到。&lt;/p&gt;

&lt;p&gt;这个 device plugin 主要做两件事：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1）检测节点上的 GPU 设备并上报给 Kubelet，再由 Kubelet 更新节点信息时提交到 kube-apiserver。

&lt;ul&gt;
&lt;li&gt;这样 k8s 就知道每个节点上有多少 GPU 了，后续 Pod 申请 GPU 时就会往有 GPU 资源的节点上调度。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2）Pod 申请 GPU 时，为对应容器添加一个NVIDIA_VISIBLE_DEVICES环境变量，后续底层 Runtime 在真正创建容器时就能根据这些信息把 GPU 挂载到容器中

&lt;ul&gt;
&lt;li&gt;例如添加环境变量：NVIDIA_VISIBLE_DEVICES=GPU-03f69c50-207a-2038-9b45-23cac89cb67d
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NVIDIA 这个 device plugin 比较复杂，支持多种策略，device plugin 提供的 env、mounts、device 以及 annotations 等方式它都做了支持，在部署时可以通过 DEVICE_LIST_STRATEGY 环境变量进行指定，不过默认还是用的 env。&lt;/p&gt;

&lt;p&gt;另外DEVICE_ID_STRATEGY 默认也是 uuid，因此在 Pod 中看到的 NVIDIA_VISIBLE_DEVICES 就不是 Docker 环境中常见的 0,1,2 这种编号了，而是 GPU 设备对应的 UUID。&lt;/p&gt;

&lt;h2 id=&#34;2-2-gpu-是如何分配给-pod-的&#34;&gt;2.2. GPU 是如何分配给 Pod 的&lt;/h2&gt;

&lt;p&gt;NVIDIA 提供了 nvidia-container-toolkit 来处理如何将 GPU 分配给容器的问题。&lt;/p&gt;

&lt;p&gt;核心组件有以下三个：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;nvidia-container-runtime&lt;/li&gt;
&lt;li&gt;nvidia-container-runtime-hook&lt;/li&gt;
&lt;li&gt;nvidia-container-cli&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;首先需要将 docker/containerd 的 runtime 设置为nvidia-container-runtime，此后整个调用链就变成这样了：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-27-pod-use-gpu/IMG_20250127-192425835.png&#34; alt=&#34;picture 0&#34; /&gt;&lt;/p&gt;

&lt;p&gt;接下来就具体分析每个组件的作用。&lt;/p&gt;

&lt;h3 id=&#34;2-2-1-nvidia-container-runtime&#34;&gt;2.2.1. nvidia-container-runtime&lt;/h3&gt;

&lt;p&gt;nvidia-container-runtime 的作用就是负责在容器启动之前，将 nvidia-container-runtime-hook 注入到 prestart hook。
&amp;gt; 小知识：docker/containerd 都是高级 Runtime，runC 则是低级 Runtime。不同层级 Runtime 通过 OCI Spec 进行交互。&lt;/p&gt;

&lt;p&gt;也就是说 docker 调用 runC 创建容器时，会把 docker 收到的信息解析，组装成 OCI Spec，然后在往下传递。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;而 nvidia-container-runtime 的作用就是修改容器 Spec，往里面添加一个 prestart hook，这个 hook 就是 nvidia-container-runtime-hook 。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这样 runC 根据 Spec 启动容器时就会执行该 hook，即执行 nvidia-container-runtime-hook。&lt;/p&gt;

&lt;p&gt;也就是说 nvidia-container-runtime 其实没有任何逻辑，真正的逻辑都在 nvidia-container-runtime-hook 中。&lt;/p&gt;

&lt;h3 id=&#34;2-2-2-nvidia-container-runtime-hook&#34;&gt;2.2.2. nvidia-container-runtime-hook&lt;/h3&gt;

&lt;p&gt;nvidia-container-runtime-hook 包含了给容器分配 GPU 的核心逻辑，主要分为两部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1）从容器 Spec 的 mounts 和 env 中解析 GPU 信息

&lt;ul&gt;
&lt;li&gt;mounts 对应前面 device plugin 中设置的 Mount 和 Device，env 则对应 Env&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2）调用 nvidia-container-cli configure 命令，保证容器内可以使用被指定的 GPU 以及对应能力

&lt;ul&gt;
&lt;li&gt;也就是说nvidia-container-runtime-hook 最终还是调用 nvidia-container-cli 来实现的给容器分配 GPU 能力的。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;2-2-3-nvidia-container-cli&#34;&gt;2.2.3. nvidia-container-cli&lt;/h3&gt;

&lt;p&gt;nvidia-container-cli 是一个命令行工具，用于配置 Linux 容器对 GPU 硬件的使用。&lt;/p&gt;

&lt;p&gt;提供了三个命令&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;list: 打印 nvidia 驱动库及路径&lt;/li&gt;
&lt;li&gt;info: 打印所有Nvidia GPU设备&lt;/li&gt;
&lt;li&gt;configure： 进入给定进程的命名空间，执行必要操作保证容器内可以使用被指定的 GPU 以及对应能力（指定 NVIDIA 驱动库）
&lt;img src=&#34;post/2024/images/2024-01-27-pod-use-gpu/IMG_20250130-215950804.png&#34; alt=&#34;picture 3&#34; /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一般主要使用 configure 命令，它将 NVIDIA GPU Driver、CUDA Driver 等 驱动库的 so 文件 和 GPU 设备信息， 通过文件挂载的方式映射到容器中。&lt;/p&gt;

&lt;h2 id=&#34;2-3-小结&#34;&gt;2.3. 小结&lt;/h2&gt;

&lt;p&gt;整个流程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1）device plugin 上报节点上的 GPU 信息&lt;/li&gt;
&lt;li&gt;2）用户创建 Pod，在 resources.rquest 中申请 GPU，Scheduler 根据各节点 GPU 资源情况，将 Pod 调度到一个有足够 GPU 的节点&lt;/li&gt;
&lt;li&gt;3）DevicePlugin 根据 Pod 中申请的 GPU 资源，为容器添加 Env 和 Devices 配置

&lt;ul&gt;
&lt;li&gt;例如添加环境变量：NVIDIA_VISIBLE_DEVICES=GPU-03f69c50-207a-2038-9b45-23cac89cb67d&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4）docker / containerd 启动容器&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;由于配置了 nvidia-container-runtime,因此会使用 nvidia-container-runtime 来创建容器&lt;/li&gt;
&lt;li&gt;nvidia-container-runtime 额外做了一件事：将 nvidia-container-runtime-hook 作为 prestart hook 添加到容器 spec 中，然后就将容器 spec 信息往后传给 runC 了。&lt;/li&gt;
&lt;li&gt;runC 创建容器前会调用 prestart hook，其中就包括了上一步添加的 nvidia-container-runtime-hook，该 hook 主要做两件事：

&lt;ul&gt;
&lt;li&gt;从容器 Spec 的 mounts 或者 env 中解析 GPU 信息&lt;/li&gt;
&lt;li&gt;调用 nvidia-container-cli configure 命令，将 NVIDIA 的 GPU Driver、CUDA Driver 等库文件挂载进容器，保证容器内可以使用被指定的 GPU以及对应能力
以上就是在 k8s 中使用 NVIDIA GPU 的流程，简单来说就是：&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;1）device plugin 中根据 pod 申请的 GPU 资源分配 GPU，并以 ENV 环境变量方式添加到容器上。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2）nvidia-container-toolkit 则根据该 Env 拿到要分配给该容器的 GPU 最终把相关文件挂载到容器里
当然并不是只有这一种实现方法，比如天数的 ix-device-plugin 实现中就没有提供自己的 container-toolkit，只在 device plugin 中通过 Device 指定要挂载哪些设备,这样容器启动时也会把这些设备挂载到容器中：&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (p *iluvatarDevicePlugin) allocateDevicesByDeviceID(hostminor uint, num int) *pluginapi.DeviceSpec {
	var device pluginapi.DeviceSpec

	hostPathPrefix := &amp;quot;/dev/&amp;quot;
	containerPathPrefix := &amp;quot;/dev/&amp;quot;

	// Expose the device node for iluvatar pod.
	device.HostPath = hostPathPrefix + deviceName + strconv.Itoa(int(hostminor))
	device.ContainerPath = containerPathPrefix + deviceName + strconv.Itoa(num)
	device.Permissions = &amp;quot;rw&amp;quot;

	return &amp;amp;device
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不过由于没有挂载驱动进去，因此需要容器内自带驱动才行。&lt;/p&gt;

&lt;p&gt;至此，已经分析了 k8s 创建 Pod 使用 GPU 的整个流程及大致原理，接下来简单分析下相关组件源码。&lt;/p&gt;

&lt;h1 id=&#34;3-device-plugin-源码分析&#34;&gt;3. device plugin 源码分析&lt;/h1&gt;

&lt;p&gt;NVIDIA GPU 对应的 device plugin 叫做：&lt;a href=&#34;https://github.com/NVIDIA/k8s-device-plugin&#34;&gt;NVIDIA/k8s-device-plugin&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;3-1-allocate-方法&#34;&gt;3.1. Allocate 方法&lt;/h2&gt;

&lt;p&gt;主要看为容器分配资源的 Allocate 方法&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// https://github.com/NVIDIA/k8s-device-plugin/blob/main/internal/plugin/server.go#L319-L332

// Allocate which return list of devices.
func (plugin *NvidiaDevicePlugin) Allocate(ctx context.Context, reqs *pluginapi.AllocateRequest) (*pluginapi.AllocateResponse, error) {
        responses := pluginapi.AllocateResponse{}
        for _, req := range reqs.ContainerRequests {
                if err := plugin.rm.ValidateRequest(req.DevicesIDs); err != nil {
                        return nil, fmt.Errorf(&amp;quot;invalid allocation request for %q: %w&amp;quot;, plugin.rm.Resource(), err)
                }
                response, err := plugin.getAllocateResponse(req.DevicesIDs)
                if err != nil {
                        return nil, fmt.Errorf(&amp;quot;failed to get allocate response: %v&amp;quot;, err)
                }
                responses.ContainerResponses = append(responses.ContainerResponses, response)
        }

        return &amp;amp;responses, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;核心逻辑在 getAllocateResponse 中：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (plugin *NvidiaDevicePlugin) getAllocateResponse(requestIds []string) (*pluginapi.ContainerAllocateResponse, error) {
	deviceIDs := plugin.deviceIDsFromAnnotatedDeviceIDs(requestIds)

	// Create an empty response that will be updated as required below.
	response := &amp;amp;pluginapi.ContainerAllocateResponse{
		Envs: make(map[string]string),
	}
	if plugin.deviceListStrategies.AnyCDIEnabled() {
		responseID := uuid.New().String()
		if err := plugin.updateResponseForCDI(response, responseID, deviceIDs...); err != nil {
			return nil, fmt.Errorf(&amp;quot;failed to get allocate response for CDI: %v&amp;quot;, err)
		}
	}
	if plugin.config.Sharing.SharingStrategy() == spec.SharingStrategyMPS {
		plugin.updateResponseForMPS(response)
	}

	// The following modifications are only made if at least one non-CDI device
	// list strategy is selected.
	if plugin.deviceListStrategies.AllCDIEnabled() {
		return response, nil
	}

	if plugin.deviceListStrategies.Includes(spec.DeviceListStrategyEnvvar) {
		plugin.updateResponseForDeviceListEnvvar(response, deviceIDs...)
	}
	if plugin.deviceListStrategies.Includes(spec.DeviceListStrategyVolumeMounts) {
		plugin.updateResponseForDeviceMounts(response, deviceIDs...)
	}
	if *plugin.config.Flags.Plugin.PassDeviceSpecs {
		response.Devices = append(response.Devices, plugin.apiDeviceSpecs(*plugin.config.Flags.NvidiaDevRoot, requestIds)...)
	}
	if *plugin.config.Flags.GDSEnabled {
		response.Envs[&amp;quot;NVIDIA_GDS&amp;quot;] = &amp;quot;enabled&amp;quot;
	}
	if *plugin.config.Flags.MOFEDEnabled {
		response.Envs[&amp;quot;NVIDIA_MOFED&amp;quot;] = &amp;quot;enabled&amp;quot;
	}
	return response, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，根据不同 flag 以及策略分为不同的设置方式&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Constants to represent the various device list strategies
const (
	DeviceListStrategyEnvvar         = &amp;quot;envvar&amp;quot;
	DeviceListStrategyVolumeMounts   = &amp;quot;volume-mounts&amp;quot;
	DeviceListStrategyCDIAnnotations = &amp;quot;cdi-annotations&amp;quot;
	DeviceListStrategyCDICRI         = &amp;quot;cdi-cri&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;东西比较多，我们主要看设置 Env 的策略&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;if plugin.deviceListStrategies.Includes(spec.DeviceListStrategyEnvvar) {
    plugin.updateResponseForDeviceListEnvvar(response, deviceIDs...)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;核心如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// updateResponseForDeviceListEnvvar sets the environment variable for the requested devices.
func (plugin *NvidiaDevicePlugin) updateResponseForDeviceListEnvvar(response *pluginapi.ContainerAllocateResponse, deviceIDs ...string) {
        response.Envs[plugin.deviceListEnvvar] = strings.Join(deviceIDs, &amp;quot;,&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，逻辑很简单，就是给容器添加了一个环境变量，value 为设备 id，具体 deviceID 提供了两种策略，可以是编号或者 uuid&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;const (
        DeviceIDStrategyUUID  = &amp;quot;uuid&amp;quot;
        DeviceIDStrategyIndex = &amp;quot;index&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;key 是一个变量 plugin.deviceListEnvvar，初始化如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;        plugin := NvidiaDevicePlugin{
                deviceListEnvvar:     &amp;quot;NVIDIA_VISIBLE_DEVICES&amp;quot;,
                socket:               pluginPath + &amp;quot;.sock&amp;quot;,
          // ...
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是说 NVIDIA 这个 device plugin 实现 Allocate 主要就是给容器增加了环境变量，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;NVIDIA_VISIBLE_DEVICES=GPU-03f69c50-207a-2038-9b45-23cac89cb67d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;或者&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;NVIDIA_VISIBLE_DEVICES=1,2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-2-小结&#34;&gt;3.2. 小结&lt;/h2&gt;

&lt;p&gt;NVIDIA device plugin 核心逻辑就是给容器添加NVIDIA_VISIBLE_DEVICES 环境变量，告知后续组件，需要给该组件分配 GPU。&lt;/p&gt;

&lt;p&gt;比如当我们仅使用 Docker 时就可以在启动容器时指定 GPU，&amp;ndash;gpus flag 和 NVIDIA_VISIBLE_DEVICES 环境变量效果一致。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# --gpus
docker run --gpus device=0 -it tensorflow/tensorflow:latest-gpu bash
# 或者环境变量 NVIDIA_VISIBLE_DEVICES
docker run -e NVIDIA_VISIBLE_DEVICES=0 -it tensorflow/tensorflow:latest-gpu bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至于为什么添加了NVIDIA_VISIBLE_DEVICES 环境变量就会给该容器分配 GPU，就是接下来的 nvidi-container-toolkit 组件实现的。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;nvidia 在 device plugin 中也使用NVIDIA_VISIBLE_DEVICES 环境变量正好能够兼容 nvidia-container-toolkit。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;4-nvidia-container-toolkit-源码分析&#34;&gt;4. nvidia-container-toolkit 源码分析&lt;/h1&gt;

&lt;p&gt;这部分我们主要分析，为什么添加了NVIDIA_VISIBLE_DEVICES 环境变量就会给该容器分配 GPU，nvidia-container-toolkit 中做了哪些处理。&lt;/p&gt;

&lt;p&gt;nvidia-container-toolkit 包含以下 3 个部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1）&lt;a href=&#34;https://github.com/NVIDIA/nvidia-container-toolkit/tree/main/cmd/nvidia-container-runtime&#34;&gt;nvidia-container-runtime&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2）&lt;a href=&#34;https://github.com/NVIDIA/nvidia-container-toolkit/tree/main/cmd/nvidia-container-runtime-hook&#34;&gt;nvidia-container-runtime-hook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3）&lt;a href=&#34;https://github.com/NVIDIA/libnvidia-container/tree/master/src/cli&#34;&gt;nvidia-container-cli&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;4-1-nvidia-container-runtime&#34;&gt;4.1. nvidia-container-runtime&lt;/h2&gt;

&lt;p&gt;nvidia-container-runtime 可以看做是一个 docker/containerd 的底层 runtime（类似 runC），在模块在创建容器的整个调用链中处在如下位置：
&lt;img src=&#34;post/2024/images/2024-01-27-pod-use-gpu/IMG_20250128-155337940.png&#34; alt=&#34;picture 1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;它只做一件事，就是在容器启动之前，将 nvidia-container-runtime-hook 注入到 prestart hook。
&amp;gt; 以修改容器 Spec 的方式添加一个 prestart hook 进去&lt;/p&gt;

&lt;p&gt;这样，后续 runC 使用容器 Spec 创建容器时就会执行该 prestart hook。&lt;/p&gt;

&lt;p&gt;简单分析下源码，首先是启动命令：&lt;a href=&#34;https://github.com/NVIDIA/nvidia-container-toolkit/blob/main/cmd/nvidia-container-runtime/main.go&#34;&gt;nvidia-container-runtime/main.go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;就是 New 了一个 nvidia runtime 对象，并执行其 Run 方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// https://github.com/NVIDIA/nvidia-container-toolkit/blob/main/cmd/nvidia-container-runtime/main.go#L9-L15

import (
    &amp;quot;os&amp;quot;

    &amp;quot;github.com/NVIDIA/nvidia-container-toolkit/internal/runtime&amp;quot;
)

func main() {
    r := runtime.New()
    err := r.Run(os.Args)
    if err != nil {
       os.Exit(1)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体的 New 方法也很简单，返回的是一个名为 Interface 的 Interface，包含一个 Run 方法&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// https://github.com/NVIDIA/nvidia-containertoolkit/blob/main/internal/runtime/api.go#L17-L26

type rt struct {
    logger       *Logger
    modeOverride string
}

// Interface is the interface for the runtime library.
type Interface interface {
    Run([]string) error
}
func New(opts ...Option) Interface {
    r := rt{}
    for _, opt := range opts {
       opt(&amp;amp;r)
    }
    if r.logger == nil {
       r.logger = NewLogger()
    }
    return &amp;amp;r
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Run 方法具体实现如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// https://github.com/NVIDIA/nvidia-container-toolkit/blob/main/internal/runtime/runtime.go#L34-L91

// Run is an entry point that allows for idiomatic handling of errors
// when calling from the main function.
func (r rt) Run(argv []string) (rerr error) {
    defer func() {
       if rerr != nil {
          r.logger.Errorf(&amp;quot;%v&amp;quot;, rerr)
       }
    }()

    printVersion := hasVersionFlag(argv)
    if printVersion {
       fmt.Printf(&amp;quot;%v version %v\n&amp;quot;, &amp;quot;NVIDIA Container Runtime&amp;quot;, info.GetVersionString(fmt.Sprintf(&amp;quot;spec: %v&amp;quot;, specs.Version)))
    }

    cfg, err := config.GetConfig()
    if err != nil {
       return fmt.Errorf(&amp;quot;error loading config: %v&amp;quot;, err)
    }
    r.logger.Update(
       cfg.NVIDIAContainerRuntimeConfig.DebugFilePath,
       cfg.NVIDIAContainerRuntimeConfig.LogLevel,
       argv,
    )
    defer func() {
       if rerr != nil {
          r.logger.Errorf(&amp;quot;%v&amp;quot;, rerr)
       }
       if err := r.logger.Reset(); err != nil {
          rerr = errors.Join(rerr, fmt.Errorf(&amp;quot;failed to reset logger: %v&amp;quot;, err))
       }
    }()

    // We apply some config updates here to ensure that the config is valid in
    // all cases.
    if r.modeOverride != &amp;quot;&amp;quot; {
       cfg.NVIDIAContainerRuntimeConfig.Mode = r.modeOverride
    }
    //nolint:staticcheck  // TODO(elezar): We should swith the nvidia-container-runtime from using nvidia-ctk to using nvidia-cdi-hook.
    cfg.NVIDIACTKConfig.Path = config.ResolveNVIDIACTKPath(&amp;amp;logger.NullLogger{}, cfg.NVIDIACTKConfig.Path)
    cfg.NVIDIAContainerRuntimeHookConfig.Path = config.ResolveNVIDIAContainerRuntimeHookPath(&amp;amp;logger.NullLogger{}, cfg.NVIDIAContainerRuntimeHookConfig.Path)

    // Log the config at Trace to allow for debugging if required.
    r.logger.Tracef(&amp;quot;Running with config: %+v&amp;quot;, cfg)

    driver := root.New(
       root.WithLogger(r.logger),
       root.WithDriverRoot(cfg.NVIDIAContainerCLIConfig.Root),
    )

    r.logger.Tracef(&amp;quot;Command line arguments: %v&amp;quot;, argv)
    runtime, err := newNVIDIAContainerRuntime(r.logger, cfg, argv, driver)
    if err != nil {
       return fmt.Errorf(&amp;quot;failed to create NVIDIA Container Runtime: %v&amp;quot;, err)
    }

    if printVersion {
       fmt.Print(&amp;quot;\n&amp;quot;)
    }
    return runtime.Exec(argv)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;核心部分：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;runtime, err := newNVIDIAContainerRuntime(r.logger, cfg, argv, driver)
if err != nil {
   return fmt.Errorf(&amp;quot;failed to create NVIDIA Container Runtime: %v&amp;quot;, err)
}

if printVersion {
   fmt.Print(&amp;quot;\n&amp;quot;)
}
return runtime.Exec(argv)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;继续查看 newNVIDIAContainerRuntime 实现&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// https://github.com/NVIDIA/nvidia-container-toolkit/blob/main/internal/runtime/runtime_factory.go#L32-L62

// newNVIDIAContainerRuntime is a factory method that constructs a runtime based on the selected configuration and specified logger
func newNVIDIAContainerRuntime(logger logger.Interface, cfg *config.Config, argv []string, driver *root.Driver) (oci.Runtime, error) {
    lowLevelRuntime, err := oci.NewLowLevelRuntime(logger, cfg.NVIDIAContainerRuntimeConfig.Runtimes)
    if err != nil {
       return nil, fmt.Errorf(&amp;quot;error constructing low-level runtime: %v&amp;quot;, err)
    }

    logger.Tracef(&amp;quot;Using low-level runtime %v&amp;quot;, lowLevelRuntime.String())
    if !oci.HasCreateSubcommand(argv) {
       logger.Tracef(&amp;quot;Skipping modifier for non-create subcommand&amp;quot;)
       return lowLevelRuntime, nil
    }

    ociSpec, err := oci.NewSpec(logger, argv)
    if err != nil {
       return nil, fmt.Errorf(&amp;quot;error constructing OCI specification: %v&amp;quot;, err)
    }

    specModifier, err := newSpecModifier(logger, cfg, ociSpec, driver)
    if err != nil {
       return nil, fmt.Errorf(&amp;quot;failed to construct OCI spec modifier: %v&amp;quot;, err)
    }

    // Create the wrapping runtime with the specified modifier.
    r := oci.NewModifyingRuntimeWrapper(
       logger,
       lowLevelRuntime,
       ociSpec,
       specModifier,
    )

    return r, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;暂时只需要关注 specModifier 这个对象,就是它在修改容器的 spec 以添加 hook&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// newSpecModifier is a factory method that creates constructs an OCI spec modifer based on the provided config.
func newSpecModifier(logger logger.Interface, cfg *config.Config, ociSpec oci.Spec, driver *root.Driver) (oci.SpecModifier, error) {
    rawSpec, err := ociSpec.Load()
    if err != nil {
       return nil, fmt.Errorf(&amp;quot;failed to load OCI spec: %v&amp;quot;, err)
    }

    image, err := image.NewCUDAImageFromSpec(rawSpec)
    if err != nil {
       return nil, err
    }

    mode := info.ResolveAutoMode(logger, cfg.NVIDIAContainerRuntimeConfig.Mode, image)
    modeModifier, err := newModeModifier(logger, mode, cfg, ociSpec, image)
    if err != nil {
       return nil, err
    }
    // For CDI mode we make no additional modifications.
    if mode == &amp;quot;cdi&amp;quot; {
       return modeModifier, nil
    }

    graphicsModifier, err := modifier.NewGraphicsModifier(logger, cfg, image, driver)
    if err != nil {
       return nil, err
    }

    featureModifier, err := modifier.NewFeatureGatedModifier(logger, cfg, image)
    if err != nil {
       return nil, err
    }

    modifiers := modifier.Merge(
       modeModifier,
       graphicsModifier,
       featureModifier,
    )
    return modifiers, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改 hook 的 modifier 在 newModeModifier 里面&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func newModeModifier(logger logger.Interface, mode string, cfg *config.Config, ociSpec oci.Spec, image image.CUDA) (oci.SpecModifier, error) {
    switch mode {
    case &amp;quot;legacy&amp;quot;:
       return modifier.NewStableRuntimeModifier(logger, cfg.NVIDIAContainerRuntimeHookConfig.Path), nil
    case &amp;quot;csv&amp;quot;:
       return modifier.NewCSVModifier(logger, cfg, image)
    case &amp;quot;cdi&amp;quot;:
       return modifier.NewCDIModifier(logger, cfg, ociSpec)
    }

    return nil, fmt.Errorf(&amp;quot;invalid runtime mode: %v&amp;quot;, cfg.NVIDIAContainerRuntimeConfig.Mode)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体为 stableRuntimeModifier：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (m stableRuntimeModifier) Modify(spec *specs.Spec) error {
    // If an NVIDIA Container Runtime Hook already exists, we don&#39;t make any modifications to the spec.
    if spec.Hooks != nil {
       for _, hook := range spec.Hooks.Prestart {
          hook := hook
          if isNVIDIAContainerRuntimeHook(&amp;amp;hook) {
             m.logger.Infof(&amp;quot;Existing nvidia prestart hook (%v) found in OCI spec&amp;quot;, hook.Path)
             return nil
          }
       }
    }

    path := m.nvidiaContainerRuntimeHookPath
    m.logger.Infof(&amp;quot;Using prestart hook path: %v&amp;quot;, path)
    args := []string{filepath.Base(path)}
    if spec.Hooks == nil {
       spec.Hooks = &amp;amp;specs.Hooks{}
    }
    spec.Hooks.Prestart = append(spec.Hooks.Prestart, specs.Hook{
       Path: path,
       Args: append(args, &amp;quot;prestart&amp;quot;),
    })

    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;核心部分：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;path := m.nvidiaContainerRuntimeHookPath
spec.Hooks.Prestart = append(spec.Hooks.Prestart, specs.Hook{
   Path: path,
   Args: append(args, &amp;quot;prestart&amp;quot;),
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，最终就是添加了一个 prestart hook，hook 的 path 就是 nvidia-container-runtime-hook 这个二进制文件的位置。&lt;/p&gt;

&lt;p&gt;至此，nvidia-container-runtime 的工作就完成了，容器真正启动时，底层 runtime（比如 runC）检测到容器的 Spec 中有这个 hook 就会去执行了，最终 nvidia-container-runtime-hook 就会被运行了。&lt;/p&gt;

&lt;h2 id=&#34;4-2-nvidia-container-runtime-hook&#34;&gt;4.2. nvidia-container-runtime-hook&lt;/h2&gt;

&lt;p&gt;该组件则是 nvidia-container-toolkit 中的核心，所有的逻辑都在这里面实现。&lt;/p&gt;

&lt;p&gt;主要做两件事：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1）从容器的 env 中解析 GPU 信息&lt;/li&gt;
&lt;li&gt;2）调用 nvidia-container-cli configure 命令，挂载相关文件，保证容器内可以使用被指定的GPU以及对应能力
也是先从启动命令看起：&lt;a href=&#34;https://github.com/NVIDIA/nvidia-container-toolkit/blob/main/cmd/nvidia-container-runtime-hook/main.go&#34;&gt;nvidia-container-runtime-hook/main.go&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;switch args[0] {
case &amp;quot;prestart&amp;quot;:
    doPrestart()
    os.Exit(0)
case &amp;quot;poststart&amp;quot;:
    fallthrough
case &amp;quot;poststop&amp;quot;:
    os.Exit(0)
default:
    flag.Usage()
    os.Exit(2)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们是添加的 prestart hook，因此会走 prestart 分支 执行doPrestart()方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func doPrestart() {
    var err error

    defer exit()
    log.SetFlags(0)

    hook, err := getHookConfig()
    if err != nil || hook == nil {
       log.Panicln(&amp;quot;error getting hook config:&amp;quot;, err)
    }
    cli := hook.NVIDIAContainerCLIConfig

    container := getContainerConfig(*hook)
    nvidia := container.Nvidia
    if nvidia == nil {
       // Not a GPU container, nothing to do.
       return
    }

    if !hook.NVIDIAContainerRuntimeHookConfig.SkipModeDetection &amp;amp;&amp;amp; info.ResolveAutoMode(&amp;amp;logInterceptor{}, hook.NVIDIAContainerRuntimeConfig.Mode, container.Image) != &amp;quot;legacy&amp;quot; {
       log.Panicln(&amp;quot;invoking the NVIDIA Container Runtime Hook directly (e.g. specifying the docker --gpus flag) is not supported. Please use the NVIDIA Container Runtime (e.g. specify the --runtime=nvidia flag) instead.&amp;quot;)
    }

    rootfs := getRootfsPath(container)

    args := []string{getCLIPath(cli)}
    if cli.Root != &amp;quot;&amp;quot; {
       args = append(args, fmt.Sprintf(&amp;quot;--root=%s&amp;quot;, cli.Root))
    }
    if cli.LoadKmods {
       args = append(args, &amp;quot;--load-kmods&amp;quot;)
    }
    if cli.NoPivot {
       args = append(args, &amp;quot;--no-pivot&amp;quot;)
    }
    if *debugflag {
       args = append(args, &amp;quot;--debug=/dev/stderr&amp;quot;)
    } else if cli.Debug != &amp;quot;&amp;quot; {
       args = append(args, fmt.Sprintf(&amp;quot;--debug=%s&amp;quot;, cli.Debug))
    }
    if cli.Ldcache != &amp;quot;&amp;quot; {
       args = append(args, fmt.Sprintf(&amp;quot;--ldcache=%s&amp;quot;, cli.Ldcache))
    }
    if cli.User != &amp;quot;&amp;quot; {
       args = append(args, fmt.Sprintf(&amp;quot;--user=%s&amp;quot;, cli.User))
    }
    args = append(args, &amp;quot;configure&amp;quot;)

    if ldconfigPath := cli.NormalizeLDConfigPath(); ldconfigPath != &amp;quot;&amp;quot; {
       args = append(args, fmt.Sprintf(&amp;quot;--ldconfig=%s&amp;quot;, ldconfigPath))
    }
    if cli.NoCgroups {
       args = append(args, &amp;quot;--no-cgroups&amp;quot;)
    }
    if len(nvidia.Devices) &amp;gt; 0 {
       args = append(args, fmt.Sprintf(&amp;quot;--device=%s&amp;quot;, nvidia.Devices))
    }
    if len(nvidia.MigConfigDevices) &amp;gt; 0 {
       args = append(args, fmt.Sprintf(&amp;quot;--mig-config=%s&amp;quot;, nvidia.MigConfigDevices))
    }
    if len(nvidia.MigMonitorDevices) &amp;gt; 0 {
       args = append(args, fmt.Sprintf(&amp;quot;--mig-monitor=%s&amp;quot;, nvidia.MigMonitorDevices))
    }
    if len(nvidia.ImexChannels) &amp;gt; 0 {
       args = append(args, fmt.Sprintf(&amp;quot;--imex-channel=%s&amp;quot;, nvidia.ImexChannels))
    }

    for _, cap := range strings.Split(nvidia.DriverCapabilities, &amp;quot;,&amp;quot;) {
       if len(cap) == 0 {
          break
       }
       args = append(args, capabilityToCLI(cap))
    }

    for _, req := range nvidia.Requirements {
       args = append(args, fmt.Sprintf(&amp;quot;--require=%s&amp;quot;, req))
    }

    args = append(args, fmt.Sprintf(&amp;quot;--pid=%s&amp;quot;, strconv.FormatUint(uint64(container.Pid), 10)))
    args = append(args, rootfs)

    env := append(os.Environ(), cli.Environment...)
    //nolint:gosec // TODO: Can we harden this so that there is less risk of command injection?
    err = syscall.Exec(args[0], args, env)
    log.Panicln(&amp;quot;exec failed:&amp;quot;, err)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们只需要关注下面这个就行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;args := []string{getCLIPath(cli)}
container := getContainerConfig(*hook)
err = syscall.Exec(args[0], args, env)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一个是 getContainerConfig 解析容器配置 ，另一个就是 exec 真正开始执行命令。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;这里执行的命令其实就是 nvidia-container-cli&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;4-2-1-getcontainerconfig&#34;&gt;4.2.1. getContainerConfig&lt;/h3&gt;

&lt;p&gt;这部分就是解析 Env 拿到要分配给该容器的 GPU，如果没有 NVIDIA_VISIBLE_DEVICES 环境变量就不会做任何事情。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func getContainerConfig(hook HookConfig) (config containerConfig) {
    var h HookState
    d := json.NewDecoder(os.Stdin)
    if err := d.Decode(&amp;amp;h); err != nil {
       log.Panicln(&amp;quot;could not decode container state:&amp;quot;, err)
    }

    b := h.Bundle
    if len(b) == 0 {
       b = h.BundlePath
    }

    s := loadSpec(path.Join(b, &amp;quot;config.json&amp;quot;))

    image, err := image.New(
       image.WithEnv(s.Process.Env),
       image.WithDisableRequire(hook.DisableRequire),
    )
    if err != nil {
       log.Panicln(err)
    }

    privileged := isPrivileged(s)
    return containerConfig{
       Pid:    h.Pid,
       Rootfs: s.Root.Path,
       Image:  image,
       Nvidia: getNvidiaConfig(&amp;amp;hook, image, s.Mounts, privileged),
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;构建了一个 image 对象，注意这里把 ENV 也传进去了&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;之前说了需要给容器分配什么 GPU 是通过 NVIDIA_VISIBLE_DEVICES 环境变量指定的&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;image, err := image.New(
    image.WithEnv(s.Process.Env),
    image.WithDisableRequire(hook.DisableRequire),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后解析配置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func getNvidiaConfig(hookConfig *HookConfig, image image.CUDA, mounts []Mount, privileged bool) *nvidiaConfig {
    legacyImage := image.IsLegacy()

    var devices string
    if d := getDevices(hookConfig, image, mounts, privileged); d != nil {
       devices = *d
    } else {
       // &#39;nil&#39; devices means this is not a GPU container.
       return nil
    }

    var migConfigDevices string
    if d := getMigConfigDevices(image); d != nil {
       migConfigDevices = *d
    }
    if !privileged &amp;amp;&amp;amp; migConfigDevices != &amp;quot;&amp;quot; {
       log.Panicln(&amp;quot;cannot set MIG_CONFIG_DEVICES in non privileged container&amp;quot;)
    }

    var migMonitorDevices string
    if d := getMigMonitorDevices(image); d != nil {
       migMonitorDevices = *d
    }
    if !privileged &amp;amp;&amp;amp; migMonitorDevices != &amp;quot;&amp;quot; {
       log.Panicln(&amp;quot;cannot set MIG_MONITOR_DEVICES in non privileged container&amp;quot;)
    }

    var imexChannels string
    if c := getImexChannels(image); c != nil {
       imexChannels = *c
    }

    driverCapabilities := hookConfig.getDriverCapabilities(image, legacyImage).String()

    requirements, err := image.GetRequirements()
    if err != nil {
       log.Panicln(&amp;quot;failed to get requirements&amp;quot;, err)
    }

    return &amp;amp;nvidiaConfig{
       Devices:            devices,
       MigConfigDevices:   migConfigDevices,
       MigMonitorDevices:  migMonitorDevices,
       ImexChannels:       imexChannels,
       DriverCapabilities: driverCapabilities,
       Requirements:       requirements,
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;核心是 getDevice，就是根据 Mounts 信息或者 Env 解析要分配给该容器的 GPU&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func getDevices(hookConfig *HookConfig, image image.CUDA, mounts []Mount, privileged bool) *string {
    // If enabled, try and get the device list from volume mounts first
    if hookConfig.AcceptDeviceListAsVolumeMounts {
       devices := getDevicesFromMounts(mounts)
       if devices != nil {
          return devices
       }
    }

    // Fallback to reading from the environment variable if privileges are correct
    devices := getDevicesFromEnvvar(image, hookConfig.getSwarmResourceEnvvars())
    if devices == nil {
       return nil
    }
    if privileged || hookConfig.AcceptEnvvarUnprivileged {
       return devices
    }

    configName := hookConfig.getConfigOption(&amp;quot;AcceptEnvvarUnprivileged&amp;quot;)
    log.Printf(&amp;quot;Ignoring devices specified in NVIDIA_VISIBLE_DEVICES (privileged=%v, %v=%v) &amp;quot;, privileged, configName, hookConfig.AcceptEnvvarUnprivileged)

    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到这里根据配置不同，提供了两种解析 devices 的方法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;getDevicesFromMounts&lt;/li&gt;
&lt;li&gt;getDevicesFromEnvvar
这也就是为什么 nvidia device plugin 除了实现 Env 之外还实现了另外的方式，二者配置应该要对应才行。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里我们只关注 getDevicesFromEnvvar，从环境变量里解析 Device：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;envNVVisibleDevices     = &amp;quot;NVIDIA_VISIBLE_DEVICES&amp;quot;

func getDevicesFromEnvvar(image image.CUDA, swarmResourceEnvvars []string) *string {
	// We check if the image has at least one of the Swarm resource envvars defined and use this
	// if specified.
	var hasSwarmEnvvar bool
	for _, envvar := range swarmResourceEnvvars {
		if image.HasEnvvar(envvar) {
			hasSwarmEnvvar = true
			break
		}
	}

	var devices []string
	if hasSwarmEnvvar {
		devices = image.DevicesFromEnvvars(swarmResourceEnvvars...).List()
	} else {
		devices = image.DevicesFromEnvvars(envNVVisibleDevices).List()
	}

	if len(devices) == 0 {
		return nil
	}

	devicesString := strings.Join(devices, &amp;quot;,&amp;quot;)

	return &amp;amp;devicesString
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;核心如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;devices = image.DevicesFromEnvvars(envNVVisibleDevices).List()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从 image 里面提取NVIDIA_VISIBLE_DEVICES环境变量，至于这个 Env 是哪里来的，也是容器 Spec 中定义的，之前 image 是这样初始化的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;s := loadSpec(path.Join(b, &amp;quot;config.json&amp;quot;))

	image, err := image.New(
		image.WithEnv(s.Process.Env), // 这里把容器 env 传给了 image 对象
		image.WithDisableRequire(hook.DisableRequire),
	)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际这里还有一个特殊逻辑：&lt;em&gt;如果没有设置 NVIDIA_VISIBLE_DEVICES环境变量，也没通过其他方式解析到 device 并且还是是一个 legacy image，那么默认使用全部 GPU。&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Environment variable unset with legacy image: default to &amp;quot;all&amp;quot;.
if !isSet &amp;amp;&amp;amp; len(devices) == 0 &amp;amp;&amp;amp; i.IsLegacy() {
  return NewVisibleDevices(&amp;quot;all&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么什么算是 legacy image 呢：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// IsLegacy returns whether the associated CUDA image is a &amp;quot;legacy&amp;quot; image. An
// image is considered legacy if it has a CUDA_VERSION environment variable defined
// and no NVIDIA_REQUIRE_CUDA environment variable defined.
func (i CUDA) IsLegacy() bool {
	legacyCudaVersion := i.env[envCUDAVersion]
	cudaRequire := i.env[envNVRequireCUDA]
	return len(legacyCudaVersion) &amp;gt; 0 &amp;amp;&amp;amp; len(cudaRequire) == 0
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这也就是为什么，有时候启动 Pod 并没有申请 GPU，但是 Pod 里面依旧可以看到所有 GPU，就是走了这个 legacy image 的分支逻辑。&lt;/p&gt;

&lt;p&gt;至此，我们知道了这边 runtime 是怎么指定要把哪些 GPU 分配给容器了，接下来进入 Exec 逻辑。&lt;/p&gt;

&lt;h3 id=&#34;4-2-2-exec&#34;&gt;4.2.2. Exec&lt;/h3&gt;

&lt;p&gt;Exec 部分比较短，就是这两行代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;args := []string{getCLIPath(cli)}
err = syscall.Exec(args[0], args, env)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先是 getCLIPath，用于寻找 nvidia-container-cli 工具的位置并作为第一个参数。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func getCLIPath(config config.ContainerCLIConfig) string {
    if config.Path != &amp;quot;&amp;quot; {
       return config.Path
    }

    if err := os.Setenv(&amp;quot;PATH&amp;quot;, lookup.GetPath(config.Root)); err != nil {
       log.Panicln(&amp;quot;couldn&#39;t set PATH variable:&amp;quot;, err)
    }

    path, err := exec.LookPath(&amp;quot;nvidia-container-cli&amp;quot;)
    if err != nil {
       log.Panicln(&amp;quot;couldn&#39;t find binary nvidia-container-cli in&amp;quot;, os.Getenv(&amp;quot;PATH&amp;quot;), &amp;quot;:&amp;quot;, err)
    }
    return path
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，如果单独配置了 cli 的位置参数就使用配置的位置，否则使用 LookPath 根据名字寻找。&lt;/p&gt;

&lt;p&gt;然后是相关的参数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;    args := []string{getCLIPath(cli)}
    if cli.Root != &amp;quot;&amp;quot; {
       args = append(args, fmt.Sprintf(&amp;quot;--root=%s&amp;quot;, cli.Root))
    }
    if cli.LoadKmods {
       args = append(args, &amp;quot;--load-kmods&amp;quot;)
    }
    if cli.NoPivot {
       args = append(args, &amp;quot;--no-pivot&amp;quot;)
    }
    if *debugflag {
       args = append(args, &amp;quot;--debug=/dev/stderr&amp;quot;)
    } else if cli.Debug != &amp;quot;&amp;quot; {
       args = append(args, fmt.Sprintf(&amp;quot;--debug=%s&amp;quot;, cli.Debug))
    }
    if cli.Ldcache != &amp;quot;&amp;quot; {
       args = append(args, fmt.Sprintf(&amp;quot;--ldcache=%s&amp;quot;, cli.Ldcache))
    }
    if cli.User != &amp;quot;&amp;quot; {
       args = append(args, fmt.Sprintf(&amp;quot;--user=%s&amp;quot;, cli.User))
    }
    args = append(args, &amp;quot;configure&amp;quot;)

    if ldconfigPath := cli.NormalizeLDConfigPath(); ldconfigPath != &amp;quot;&amp;quot; {
       args = append(args, fmt.Sprintf(&amp;quot;--ldconfig=%s&amp;quot;, ldconfigPath))
    }
    if cli.NoCgroups {
       args = append(args, &amp;quot;--no-cgroups&amp;quot;)
    }
    if len(nvidia.Devices) &amp;gt; 0 {
       args = append(args, fmt.Sprintf(&amp;quot;--device=%s&amp;quot;, nvidia.Devices))
    }
    if len(nvidia.MigConfigDevices) &amp;gt; 0 {
       args = append(args, fmt.Sprintf(&amp;quot;--mig-config=%s&amp;quot;, nvidia.MigConfigDevices))
    }
    if len(nvidia.MigMonitorDevices) &amp;gt; 0 {
       args = append(args, fmt.Sprintf(&amp;quot;--mig-monitor=%s&amp;quot;, nvidia.MigMonitorDevices))
    }
    if len(nvidia.ImexChannels) &amp;gt; 0 {
       args = append(args, fmt.Sprintf(&amp;quot;--imex-channel=%s&amp;quot;, nvidia.ImexChannels))
    }

    for _, cap := range strings.Split(nvidia.DriverCapabilities, &amp;quot;,&amp;quot;) {
       if len(cap) == 0 {
          break
       }
       args = append(args, capabilityToCLI(cap))
    }

    for _, req := range nvidia.Requirements {
       args = append(args, fmt.Sprintf(&amp;quot;--require=%s&amp;quot;, req))
    }

    args = append(args, fmt.Sprintf(&amp;quot;--pid=%s&amp;quot;, strconv.FormatUint(uint64(container.Pid), 10)))
    args = append(args, rootfs)

    env := append(os.Environ(), cli.Environment...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;args = append(args, &amp;quot;configure&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;表示执行的是nvidia-container-cli configure 命令。&lt;/p&gt;

&lt;p&gt;最后则是调用 syscall.Exec 真正开始执行命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;err = syscall.Exec(args[0], args, env)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该命令具体在做什么呢，接着分析 nvidia-container-cli 实现。&lt;/p&gt;

&lt;h2 id=&#34;4-3-nvidia-container-cli&#34;&gt;4.3. nvidia-container-cli&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/NVIDIA/libnvidia-container/tree/master/src/cli&#34;&gt;nvidia-container-cli&lt;/a&gt; 是一个 C 写的小工具，主要作用就是根据上执行命令时传递的参数，把GPU 设备及其相关依赖库挂载到容器中，使得容器能够正常使用 GPU 能力。&lt;/p&gt;

&lt;p&gt;简单看下部分代码。&lt;/p&gt;

&lt;p&gt;首先是驱动信息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// https://github.com/NVIDIA/libnvidia-container/blob/master/src/cli/configure.c#L279-L288

/* Query the driver and device information. */
if (perm_set_capabilities(&amp;amp;err, CAP_EFFECTIVE, ecaps[NVC_INFO], ecaps_size(NVC_INFO)) &amp;lt; 0) {
        warnx(&amp;quot;permission error: %s&amp;quot;, err.msg);
        goto fail;
}
if ((drv = libnvc.driver_info_new(nvc, NULL)) == NULL ||
    (dev = libnvc.device_info_new(nvc, NULL)) == NULL) {
        warnx(&amp;quot;detection error: %s&amp;quot;, libnvc.error(nvc));
        goto fail;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;nvc_driver_info_new()：获取 CUDA Driver 信息&lt;/li&gt;
&lt;li&gt;nvc_device_info_new()：获取 GPU Drvier 信息
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;然后获取容器中可见的 GPU 列表&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// https://github.com/NVIDIA/libnvidia-container/blob/master/src/cli/configure.c#L308-L314

        /* Select the visible GPU devices. */
        if (dev-&amp;gt;ngpus &amp;gt; 0) {
                if (select_devices(&amp;amp;err, ctx-&amp;gt;devices, dev, &amp;amp;devices) &amp;lt; 0) {
                        warnx(&amp;quot;device error: %s&amp;quot;, err.msg);
                        goto fail;
                }
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后则是将相关驱动挂载到容器里去：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// https://github.com/NVIDIA/libnvidia-container/blob/master/src/cli/configure.c#L362-L408

/* Mount the driver, visible devices, mig-configs and mig-monitors. */
if (perm_set_capabilities(&amp;amp;err, CAP_EFFECTIVE, ecaps[NVC_MOUNT], ecaps_size(NVC_MOUNT)) &amp;lt; 0) {
        warnx(&amp;quot;permission error: %s&amp;quot;, err.msg);
        goto fail;
}
if (libnvc.driver_mount(nvc, cnt, drv) &amp;lt; 0) {
        warnx(&amp;quot;mount error: %s&amp;quot;, libnvc.error(nvc));
        goto fail;
}
for (size_t i = 0; i &amp;lt; devices.ngpus; ++i) {
        if (libnvc.device_mount(nvc, cnt, devices.gpus[i]) &amp;lt; 0) {
                warnx(&amp;quot;mount error: %s&amp;quot;, libnvc.error(nvc));
                goto fail;
        }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;libnvidia-container是采用 linux c mount &amp;ndash;bind功能将 CUDA Driver Libraries/Binaries一个个挂载到容器里，而不是将整个目录挂载到容器中。&lt;/p&gt;

&lt;p&gt;可通过NVIDIA_DRIVER_CAPABILITIES环境变量指定要挂载的 driver libraries/binaries。&lt;/p&gt;

&lt;p&gt;例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -e NVIDIA_VISIBLE_DEVICES=0,1 -e NVIDIA_DRIVER_CAPABILITIES=compute,utility -it tensorflow/tensorflow:latest-gpu bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;指定NVIDIA_DRIVER_CAPABILITIES=compute,utility 就会把 compute 和 utility 相关的库挂载进去。&lt;/p&gt;

&lt;p&gt;这样容器里就可以使用 GPU 了。&lt;/p&gt;

&lt;p&gt;至此，相关源码就分析完成了。&lt;/p&gt;

&lt;h1 id=&#34;5-小结&#34;&gt;5. 小结&lt;/h1&gt;

&lt;p&gt;整个流程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1）device plugin 上报节点上的 GPU 信息&lt;/li&gt;
&lt;li&gt;2）用户创建 Pod，在 resources.rquest 中申请 GPU，Scheduler 根据各节点 GPU 资源情况，将 Pod 调度到一个有足够 GPU 的节点&lt;/li&gt;
&lt;li&gt;3）DevicePlugin 根据 Pod 中申请的 GPU 资源，为容器添加NVIDIA_VISIBLE_DEVICES环境变量
 &amp;gt; 例如：NVIDIA_VISIBLE_DEVICES=GPU-03f69c50-207a-2038-9b45-23cac89cb67d&lt;/li&gt;

&lt;li&gt;&lt;p&gt;4）docker / containerd 启动容器&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;由于配置了 nvidia-container-runtime,因此会使用 nvidia-container-runtime 来创建容器&lt;/li&gt;
&lt;li&gt;nvidia-container-runtime 额外做了一件事：将 nvidia-container-runtime-hook 作为 prestart hook 添加到容器 spec 中，然后就将容器 spec 信息往后传给 runC 了。&lt;/li&gt;
&lt;li&gt;runC 创建容器前会调用 prestart hook，其中就包括了上一步添加的 nvidia-container-runtime-hook，该 hook 主要做两件事：

&lt;ul&gt;
&lt;li&gt;从容器 Spec 的 mounts 或者 env 中解析 GPU 信息&lt;/li&gt;
&lt;li&gt;调用 nvidia-container-cli 命令，将 NVIDIA 的 GPU Driver、CUDA Driver 等库文件挂载进容器，保证容器内可以使用被指定的 GPU以及对应能力
核心就是两个部分：&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;device plugin 根据 GPU 资源申请为容器添加 NVIDIA_VISIBLE_DEVICES环境变量&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;nvidia-container-toolkit 则是根据 NVIDIA_VISIBLE_DEVICES环境变量将 GPU、驱动等相关文件挂载到容器里。
看源码同时顺带解决了一个，之前遇到过的问题：&lt;em&gt;为什么 Pod 明明没有申请 GPU，启动后也能看到所有 GPU？&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这是因为 nvidia-container-toolkit 中存在特殊逻辑，没有设置 NVIDIA_VISIBLE_DEVICES环境变量，也没通过其他方式解析到 device 并且还是一个 legacy image，那么默认会返回all，即：NVIDIA_VISIBLE_DEVICES=all ，因此该 Pod 能看到全部 GPU。&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>K8S项目实践(10): device-plugin原理到实现</title>
            <link>http://mospany.github.io/2024/01/24/device-plugin/</link>
            <pubDate>Wed, 24 Jan 2024 19:31:10 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2024/01/24/device-plugin/</guid>
            <description>

&lt;p&gt;本文主要分析 k8s 中的 device-plugin 机制工作原理，并通过实现一个简单的 device-plugin 来加深理解。&lt;/p&gt;

&lt;h1 id=&#34;1-背景&#34;&gt;1. 背景&lt;/h1&gt;

&lt;p&gt;默认情况下，k8s 中的 Pod 只能申请 CPU 和 Memory 这两种资源，就像下面这样：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;resources:
  requests:
    memory: &amp;quot;1024Mi&amp;quot;
    cpu: &amp;quot;100m&amp;quot;
  limits:
    memory: &amp;quot;2048Mi&amp;quot;
    cpu: &amp;quot;200m&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;随着 AI 热度越来越高，更多的业务 Pod 需要申请 GPU 资源，&lt;a href=&#34;http://127.0.0.1:1313/2024/01/16/gpu-on-k8s/&#34;&gt;在ECS、Docker、K8s 等环境中使用 GPU&lt;/a&gt;中我们分析了如何在 k8s 环境中使用 GPU，就是靠 Device Plugin 机制，通过该机制使得 k8s 能感知到节点上的 GPU 资源，就像原生的 CPU 和 Memory 资源一样使用。&lt;/p&gt;

&lt;p&gt;实际上在早期，K8s 也提供了一种名为 alpha.kubernetes.io/nvidia-gpu 的资源来支持 NVIDIA GPU，不过后面也发现了很多问题，每增加一种资源都要修改 k8s 核心代码，k8s 社区压力山大。于是在 1.8 版本引入了 device plugin 机制，通过插件形式来接入其他资源，设备厂家只需要开发对应的 xxx-device-plugin 就可以将资源接入到 k8s 了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ps：类似的还有引入 CSI 让存储插件从 Kubernetes 内部（in-tree）代码库中分离出来，改为独立的、可插拔的外部组件（out-of-tree），还有 CRI、CNI 等等，这里的 Device Plugin 也能算作其中的一种。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Device Plugin 有两层含义，下文中根据语义自行区分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先它可以代表 k8s 中的 Device Plugin framework&lt;/li&gt;
&lt;li&gt;其次也可以代表厂家的具体实现，比如 NVIDIA/k8s-device-plugin，就是用于接入 NVIDIA GPU 资源的 Device Plugin 实现&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;2-原理&#34;&gt;2. 原理&lt;/h1&gt;

&lt;p&gt;Device Plugin 的工作原理其实不复杂，可以分为 插件注册 和 kubelet 调用插件两部分。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;插件注册：DevicePlugin 启动时会想节点上的 Kubelet 发起注册，这样 Kubelet就可以感知到该插件的存在了&lt;/li&gt;
&lt;li&gt;kubelet 调用插件：注册完成后，当有 Pod 申请对于资源时，kubelet 就会调用该插件 API 实现具体功能
如 k8s 官网上的图所示：
&lt;img src=&#34;post/2024/images/2024-01-24-device-plugin/IMG_20250124-111704478.png&#34; alt=&#34;picture 0&#34; /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-1-kubelet-部分&#34;&gt;2.1. Kubelet 部分&lt;/h2&gt;

&lt;p&gt;为了提供该功能，Kubelet 新增了一个 Registration gRPC service:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;service Registration {
	rpc Register(RegisterRequest) returns (Empty) {}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;device plugin 可以调用该接口向 Kubelet 进行注册，注册接口需要提供三个参数：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;device plugin 对应的 unix socket 名字：后续 kubelet 根据名称找到对应的 unix socket，并向插件发起调用&lt;/li&gt;
&lt;li&gt;device plugin 调 API version：用于区分不同版本的插件&lt;/li&gt;
&lt;li&gt;device plugin 提供的 ResourceName：遇到不能处理的资源申请时(CPU和Memory之外的资源)，Kubelet 就会根据申请的资源名称来匹配对应的插件&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;ResourceName 需要按照vendor-domain/resourcetype 格式，例如nvidia.com/gpu。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;2-2-device-plugin-部分&#34;&gt;2.2. device plugin 部分&lt;/h2&gt;

&lt;p&gt;要进行设备管理，device plugin 插件需要实现以下接口：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GetDevicePluginOptions：这个接口用于获取设备插件的信息，可以在其返回的响应中指定一些设备插件的配置选项，可以看做是插件的元数据&lt;/li&gt;
&lt;li&gt;ListAndWatch：该接口用于列出可用的设备并持续监视这些设备的状态变化。&lt;/li&gt;
&lt;li&gt;GetPreferredAllocation：将分配偏好信息提供给 device plugin,以便 device plugin 在分配时可以做出更好的选择&lt;/li&gt;
&lt;li&gt;Allocate：该接口用于向设备插件请求分配指定数量的设备资源。&lt;/li&gt;
&lt;li&gt;PreStartContainer： 该接口在容器启动之前调用，用于配置容器使用的设备资源。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;只有 ListAndWatch 和 Allocate 两个接口是必须的，其他都是可以选的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;2-3-工作流程&#34;&gt;2.3. 工作流程&lt;/h2&gt;

&lt;p&gt;一般所有的 Device Plugin 实现最终都会以 Pod 形式运行在 k8s 集群中，又因为需要管理所有节点，因此都会以 DaemonSet 方式部署。&lt;/p&gt;

&lt;p&gt;device plugin 启动之后第一步就是向 Kubelet 注册，让 Kubelet 知道有一个新的设备接入了。&lt;/p&gt;

&lt;p&gt;为了能够调用 Kubelet 的 Register 接口，Device Plugin Pod 会将宿主机上的 kubelet.sock 文件(unix socket)挂载到容器中，通过 kubelet.sock 文件发起调用以实现注册。&lt;/p&gt;

&lt;p&gt;集群部署后，Kubelet 就会启动，&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Kubelet 启动 Registration gRPC 服务（kubelet.sock），提供 Register 接口&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;device-plugin 启动后，通过 kubelet.sock 调用 Register 接口，向 Kubelet 进行注册，注册信息包括 device plugin 的 unix socket，API Version，ResourceName&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;注册成功后，Kubelet 通过 device-plugin 的 unix socket 向 device plugin 调用 ListAndWatch， 获取当前节点上的资源&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kubelet 向 api-server 更新节点状态来记录上一步中发现的资源&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;此时 kubelet get node -oyaml 就能查看到 Node 对象的 Capacity 中多了对应的资源&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
&lt;li&gt;用户创建 Pod 并申请该资源，调度完成后，对应节点上的 kubelet 调用 device plugin 的 Allocate 接口进行资源分配
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;大致如下：
&lt;img src=&#34;post/2024/images/2024-01-24-device-plugin/IMG_20250124-141629596.png&#34; alt=&#34;picture 1&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;3-实现&#34;&gt;3. 实现&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;源码：&lt;a href=&#34;https://github.com/mospany/i-device-plugin&#34;&gt;https://github.com/mospany/i-device-plugin&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;device plugin 实现大致分为三部分：&lt;/p&gt;

&lt;p&gt;1）启动时向 Kubelet 发起注册
   - 注意监控 kubelet 的重启，一般是使用 fsnotify 类似的库监控 kubelet.sock 的重新创建事件。如果 kubelet.sock 重新创建了，则认为 kubelet 是重启了，那么需要重新注册
2）gRPC Server：主要是实现 ListAndWatch 和 Allocate两个方法&lt;/p&gt;

&lt;h2 id=&#34;3-1-实现-grpc-server&#34;&gt;3.1. 实现 gRPC Server&lt;/h2&gt;

&lt;p&gt;简单起见，这里只实现了ListAndWatch 和 Allocate 这两个必须的方法。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;对 gRPC 不熟悉的童鞋可以看下这个 –&amp;gt; &lt;a href=&#34;https://www.lixueduan.com/tags/grpc/&#34;&gt;gRPC 系列教程&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;3-1-1-listandwatch&#34;&gt;3.1.1. ListAndWatch&lt;/h3&gt;

&lt;p&gt;这是一个 gRPC 的 Stream 方法，建立长连接，可以持续向 Kubelet 发送设备的信息。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// ListAndWatch returns a stream of List of Devices
// Whenever a Device state change or a Device disappears, ListAndWatch
// returns the new list
func (c *GopherDevicePlugin) ListAndWatch(_ *pluginapi.Empty, srv pluginapi.DevicePlugin_ListAndWatchServer) error {
	devs := c.dm.Devices()
	klog.Infof(&amp;quot;find devices [%s]&amp;quot;, String(devs))

	err := srv.Send(&amp;amp;pluginapi.ListAndWatchResponse{Devices: devs})
	if err != nil {
		return errors.WithMessage(err, &amp;quot;send device failed&amp;quot;)
	}

	klog.Infoln(&amp;quot;waiting for device update&amp;quot;)
	for range c.dm.notify {
		devs = c.dm.Devices()
		klog.Infof(&amp;quot;device update,new device list [%s]&amp;quot;, String(devs))
		_ = srv.Send(&amp;amp;pluginapi.ListAndWatchResponse{Devices: devs})
	}
	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现设备的部分代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// List all device
func (d *DeviceMonitor) List() error {
	err := filepath.Walk(d.path, func(path string, info fs.FileInfo, err error) error {
		if info.IsDir() {
			klog.Infof(&amp;quot;%s is dir,skip&amp;quot;, path)
			return nil
		}

		d.devices[info.Name()] = &amp;amp;pluginapi.Device{
			ID:     info.Name(),
			Health: pluginapi.Healthy,
		}
		return nil
	})

	return errors.WithMessagef(err, &amp;quot;walk [%s] failed&amp;quot;, d.path)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;很简单，就是遍历查看 /etc/gophers 目录下的所有文件，每个文件都会当做一个设备。&lt;/p&gt;

&lt;p&gt;然后再启动一个 Goroutine 监控设备的变化,即/etc/gophers 目录下文件有变化时通过 chan 发送通知,将最新的设备信息发送给 Kubelet。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Watch device change
func (d *DeviceMonitor) Watch() error {
	klog.Infoln(&amp;quot;watching devices&amp;quot;)

	w, err := fsnotify.NewWatcher()
	if err != nil {
		return errors.WithMessage(err, &amp;quot;new watcher failed&amp;quot;)
	}
	defer w.Close()

	errChan := make(chan error)
	go func() {
		defer func() {
			if r := recover(); r != nil {
				errChan &amp;lt;- fmt.Errorf(&amp;quot;device watcher panic:%v&amp;quot;, r)
			}
		}()
		for {
			select {
			case event, ok := &amp;lt;-w.Events:
				if !ok {
					continue
				}
				klog.Infof(&amp;quot;fsnotify device event: %s %s&amp;quot;, event.Name, event.Op.String())

				if event.Op == fsnotify.Create {
					dev := path.Base(event.Name)
					d.devices[dev] = &amp;amp;pluginapi.Device{
						ID:     dev,
						Health: pluginapi.Healthy,
					}
					d.notify &amp;lt;- struct{}{}
					klog.Infof(&amp;quot;find new device [%s]&amp;quot;, dev)
				} else if event.Op&amp;amp;fsnotify.Remove == fsnotify.Remove {
					dev := path.Base(event.Name)
					delete(d.devices, dev)
					d.notify &amp;lt;- struct{}{}
					klog.Infof(&amp;quot;device [%s] removed&amp;quot;, dev)
				}

			case err, ok := &amp;lt;-w.Errors:
				if !ok {
					continue
				}
				klog.Errorf(&amp;quot;fsnotify watch device failed:%v&amp;quot;, err)
			}
		}
	}()

	err = w.Add(d.path)
	if err != nil {
		return fmt.Errorf(&amp;quot;watch device error:%v&amp;quot;, err)
	}

	return &amp;lt;-errChan
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-1-2-allocate&#34;&gt;3.1.2. Allocate&lt;/h3&gt;

&lt;p&gt;Allocate 则是需要告知 kubelet 怎么将设备分配给容器，这里实现比较简单，就是在对应容器中增加一个环境变量，Gopher=$deviceId&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Allocate is called during container creation so that the Device
// Plugin can run device specific operations and instruct Kubelet
// of the steps to make the Device available in the container
func (c *GopherDevicePlugin) Allocate(_ context.Context, reqs *pluginapi.AllocateRequest) (*pluginapi.AllocateResponse, error) {
	ret := &amp;amp;pluginapi.AllocateResponse{}
	for _, req := range reqs.ContainerRequests {
		klog.Infof(&amp;quot;[Allocate] received request: %v&amp;quot;, strings.Join(req.DevicesIDs, &amp;quot;,&amp;quot;))
		resp := pluginapi.ContainerAllocateResponse{
			Envs: map[string]string{
				&amp;quot;Gopher&amp;quot;: strings.Join(req.DevicesIDs, &amp;quot;,&amp;quot;),
			},
		}
		ret.ContainerResponses = append(ret.ContainerResponses, &amp;amp;resp)
	}
	return ret, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;简单看一下 NVIDIA 的 device plugin 是怎么实现 Allocate 的。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Allocate which return list of devices.
func (plugin *NvidiaDevicePlugin) Allocate(ctx context.Context, reqs *pluginapi.AllocateRequest) (*pluginapi.AllocateResponse, error) {
	responses := pluginapi.AllocateResponse{}
	for _, req := range reqs.ContainerRequests {
		if err := plugin.rm.ValidateRequest(req.DevicesIDs); err != nil {
			return nil, fmt.Errorf(&amp;quot;invalid allocation request for %q: %w&amp;quot;, plugin.rm.Resource(), err)
		}
		response, err := plugin.getAllocateResponse(req.DevicesIDs)
		if err != nil {
			return nil, fmt.Errorf(&amp;quot;failed to get allocate response: %v&amp;quot;, err)
		}
		responses.ContainerResponses = append(responses.ContainerResponses, response)
	}

	return &amp;amp;responses, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;核心其实是这个方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// updateResponseForDeviceListEnvvar sets the environment variable for the requested devices.
func (plugin *NvidiaDevicePlugin) updateResponseForDeviceListEnvvar(response *pluginapi.ContainerAllocateResponse, deviceIDs ...string) {
	response.Envs[plugin.deviceListEnvvar] = strings.Join(deviceIDs, &amp;quot;,&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;给容器添加了一个环境变量，value 为设备 id，具体 deviceID 提供了两种测量，可能是编号或者 uuid&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;const (
	DeviceIDStrategyUUID  = &amp;quot;uuid&amp;quot;
	DeviceIDStrategyIndex = &amp;quot;index&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;key 是一个变量 plugin.deviceListEnvvar，初始化如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;	plugin := NvidiaDevicePlugin{
		deviceListEnvvar:     &amp;quot;NVIDIA_VISIBLE_DEVICES&amp;quot;,
		socket:               pluginPath + &amp;quot;.sock&amp;quot;,
	  // ...
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是说 NVIDIA 这个 device plugin 实现 Allocate 主要就是给容器增加了环境变量，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;NVIDIA_VISIBLE_DEVICES=GPU-03f69c50-207a-2038-9b45-23cac89cb67d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;或者&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;NVIDIA_VISIBLE_DEVICES=1,2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在文章 &lt;a href=&#34;http://blog.mospan.cn/2024/01/17/gpu-operator/&#34;&gt;使用 GPU Operator搭建AI算力环境&lt;/a&gt;, 提到 GPU Operator 会使用 NVIDIA Container Toolit Installer 安装 NVIDIA Container Toolit。&lt;/p&gt;

&lt;p&gt;这个 NVIDIA Container Toolit 的作用就是添加对 GPU 的支持，也包括了识别 NVIDIA_VISIBLE_DEVICES 这个环境变量，然后将对应设备挂载到容器里。&lt;/p&gt;

&lt;p&gt;除此之外还会把设备挂载到容器里：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (plugin *NvidiaDevicePlugin) apiDeviceSpecs(devRoot string, ids []string) []*pluginapi.DeviceSpec {
	optional := map[string]bool{
		&amp;quot;/dev/nvidiactl&amp;quot;:        true,
		&amp;quot;/dev/nvidia-uvm&amp;quot;:       true,
		&amp;quot;/dev/nvidia-uvm-tools&amp;quot;: true,
		&amp;quot;/dev/nvidia-modeset&amp;quot;:   true,
	}

	paths := plugin.rm.GetDevicePaths(ids)

	var specs []*pluginapi.DeviceSpec
	for _, p := range paths {
		if optional[p] {
			if _, err := os.Stat(p); err != nil {
				continue
			}
		}
		spec := &amp;amp;pluginapi.DeviceSpec{
			ContainerPath: p,
			HostPath:      filepath.Join(devRoot, p),
			Permissions:   &amp;quot;rw&amp;quot;,
		}
		specs = append(specs, spec)
	}

	return specs
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;核心为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;		spec := &amp;amp;pluginapi.DeviceSpec{
			ContainerPath: p,
			HostPath:      filepath.Join(devRoot, p),
			Permissions:   &amp;quot;rw&amp;quot;,
		}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里指定了设备在宿主机上的 Path 和挂载到容器之后的 Path，后续就可以根据这些信息进行设备挂载了。&lt;/p&gt;

&lt;p&gt;实际上 device plugin 提供了多种方法来完成设备分配，实现时只需要根据具体情况选择其中一种即可：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Env: 设备插件可以通过环境变量将设备的相关信息传递给容器。这种方式通常用于将设备的配置信息、路径或其他参数传递给容器中的应用程序。&lt;/li&gt;
&lt;li&gt;Mounts: 设备插件通过挂载设备到容器的文件系统中，使容器能够直接访问设备。这个方法适用于需要直接与硬件设备交互的情况，例如 GPU、网络设备、块存储等。&lt;/li&gt;
&lt;li&gt;Devices: 设备插件可以通过 Devices 字段将设备直接映射到容器。此方法允许设备被显式地添加到容器中，类似于 Linux 中的 &amp;ndash;device 选项。&lt;/li&gt;
&lt;li&gt;Annotations: 设备插件还可以使用注解来提供额外的信息，供调度器使用。注解通常不会直接影响容器的行为，而是为 Kubernetes 调度器提供信息，帮助调度器做出更合适的决策。&lt;/li&gt;
&lt;li&gt;CDIDevices: CDI（Container Device Interface）是一种 Kubernetes API 扩展，允许设备插件通过 CDI 标准进行设备分配。通过 CDI，Kubernetes 可以更容易地管理和调度设备，如 GPU、FPGA、网络卡等。
比如 nvidia device plugin 在实现时就同时使用了 Env 和 Devices 方式。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;又比如 &lt;a href=&#34;https://github.com/Deep-Spark/ix-device-plugin/blob/master/pkg/dpm/plugin.go#L144-L156&#34;&gt;ix-device-plugin&lt;/a&gt; 就是用的 Devices 方式,直接指定分配给容器的设备在宿主机的位置，以及要挂载到容器中的位置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (p *iluvatarDevicePlugin) allocateDevicesByDeviceID(hostminor uint, num int) *pluginapi.DeviceSpec {
	var device pluginapi.DeviceSpec

	hostPathPrefix := &amp;quot;/dev/&amp;quot;
	containerPathPrefix := &amp;quot;/dev/&amp;quot;

	// Expose the device node for iluvatar pod.
	device.HostPath = hostPathPrefix + deviceName + strconv.Itoa(int(hostminor))
	device.ContainerPath = containerPathPrefix + deviceName + strconv.Itoa(num)
	device.Permissions = &amp;quot;rw&amp;quot;

	return &amp;amp;device
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-1-3-其他方法&#34;&gt;3.1.3. 其他方法&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// GetDevicePluginOptions returns options to be communicated with Device
// Manager
func (c *GopherDevicePlugin) GetDevicePluginOptions(_ context.Context, _ *pluginapi.Empty) (*pluginapi.DevicePluginOptions, error) {
	return &amp;amp;pluginapi.DevicePluginOptions{PreStartRequired: true}, nil
}

// GetPreferredAllocation returns a preferred set of devices to allocate
// from a list of available ones. The resulting preferred allocation is not
// guaranteed to be the allocation ultimately performed by the
// devicemanager. It is only designed to help the devicemanager make a more
// informed allocation decision when possible.
func (c *GopherDevicePlugin) GetPreferredAllocation(_ context.Context, _ *pluginapi.PreferredAllocationRequest) (*pluginapi.PreferredAllocationResponse, error) {
	return &amp;amp;pluginapi.PreferredAllocationResponse{}, nil
}

// PreStartContainer is called, if indicated by Device Plugin during registeration phase,
// before each container start. Device plugin can run device specific operations
// such as reseting the device before making devices available to the container
func (c *GopherDevicePlugin) PreStartContainer(_ context.Context, _ *pluginapi.PreStartContainerRequest) (*pluginapi.PreStartContainerResponse, error) {
	return &amp;amp;pluginapi.PreStartContainerResponse{}, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-2-向-kubelet-进行注册&#34;&gt;3.2. 向 Kubelet 进行注册&lt;/h2&gt;

&lt;p&gt;注册也是很简单，调用 deviceplugin 提供的 RegisterRequest 方法即可。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Register registers the device plugin for the given resourceName with Kubelet.
func (c *GopherDevicePlugin) Register() error {
	conn, err := connect(pluginapi.KubeletSocket, common.ConnectTimeout)
	if err != nil {
		return errors.WithMessagef(err, &amp;quot;connect to %s failed&amp;quot;, pluginapi.KubeletSocket)
	}
	defer conn.Close()

	client := pluginapi.NewRegistrationClient(conn)
	reqt := &amp;amp;pluginapi.RegisterRequest{
		Version:      pluginapi.Version,
		Endpoint:     path.Base(common.DeviceSocket),
		ResourceName: common.ResourceName,
	}

	_, err = client.Register(context.Background(), reqt)
	if err != nil {
		return errors.WithMessage(err, &amp;quot;register to kubelet failed&amp;quot;)
	}
	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-3-监控-kubelet-sock-状态&#34;&gt;3.3. 监控 kubelet.sock 状态&lt;/h2&gt;

&lt;p&gt;使用 fsnotify 库监控 kubelet.sock 文件状态，通过 kubelet.sock 文件的变化来判断 kubelet 是否重启，当 kubelet 重启后 device plugin 也需要重启，然后注册到新的 kubelet.sock。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// WatchKubelet restart device plugin when kubelet restarted
func WatchKubelet(stop chan&amp;lt;- struct{}) error {
	watcher, err := fsnotify.NewWatcher()
	if err != nil {
		return errors.WithMessage(err, &amp;quot;Unable to create fsnotify watcher&amp;quot;)
	}
	defer watcher.Close()

	go func() {
		// Start listening for events.
		for {
			select {
			case event, ok := &amp;lt;-watcher.Events:
				if !ok {
					continue
				}
				klog.Infof(&amp;quot;fsnotify events: %s %v&amp;quot;, event.Name, event.Op.String())
				if event.Name == pluginapi.KubeletSocket &amp;amp;&amp;amp; event.Op == fsnotify.Create {
					klog.Warning(&amp;quot;inotify: kubelet.sock created, restarting.&amp;quot;)
					stop &amp;lt;- struct{}{}
				}
			case err, ok := &amp;lt;-watcher.Errors:
				if !ok {
					continue
				}
				klog.Errorf(&amp;quot;fsnotify failed restarting,detail:%v&amp;quot;, err)
			}
		}
	}()

	// watch kubelet.sock
	err = watcher.Add(pluginapi.KubeletSocket)
	if err != nil {
		return errors.WithMessagef(err, &amp;quot;Unable to add path %s to watcher&amp;quot;, pluginapi.KubeletSocket)
	}
	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;为什么需要重新注册&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;因为Kubelet 中使用一个 map 来存储注册的插件，因此每次 Kubelet 重启都会丢失，所以我们在实现 device plugin 时就要监控 Kubelet 重启状态并重新注册。&lt;/p&gt;

&lt;p&gt;Kubelet Register 方法 实现如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// /pkg/kubelet/cm/devicemanager/plugin/v1beta1/server.go#L143-L165
func (s *server) Register(ctx context.Context, r *api.RegisterRequest) (*api.Empty, error) {
	klog.InfoS(&amp;quot;Got registration request from device plugin with resource&amp;quot;, &amp;quot;resourceName&amp;quot;, r.ResourceName)
	metrics.DevicePluginRegistrationCount.WithLabelValues(r.ResourceName).Inc()

	if !s.isVersionCompatibleWithPlugin(r.Version) {
		err := fmt.Errorf(errUnsupportedVersion, r.Version, api.SupportedVersions)
		klog.InfoS(&amp;quot;Bad registration request from device plugin with resource&amp;quot;, &amp;quot;resourceName&amp;quot;, r.ResourceName, &amp;quot;err&amp;quot;, err)
		return &amp;amp;api.Empty{}, err
	}

	if !v1helper.IsExtendedResourceName(core.ResourceName(r.ResourceName)) {
		err := fmt.Errorf(errInvalidResourceName, r.ResourceName)
		klog.InfoS(&amp;quot;Bad registration request from device plugin&amp;quot;, &amp;quot;err&amp;quot;, err)
		return &amp;amp;api.Empty{}, err
	}

	if err := s.connectClient(r.ResourceName, filepath.Join(s.socketDir, r.Endpoint)); err != nil {
		klog.InfoS(&amp;quot;Error connecting to device plugin client&amp;quot;, &amp;quot;err&amp;quot;, err)
		return &amp;amp;api.Empty{}, err
	}

	return &amp;amp;api.Empty{}, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;核心在 connectClient 方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (s *server) connectClient(name string, socketPath string) error {
	c := NewPluginClient(name, socketPath, s.chandler)

	s.registerClient(name, c)
	if err := c.Connect(); err != nil {
		s.deregisterClient(name)
		klog.ErrorS(err, &amp;quot;Failed to connect to new client&amp;quot;, &amp;quot;resource&amp;quot;, name)
		return err
	}

	go func() {
		s.runClient(name, c)
	}()

	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;怎么保存这个 client 的呢?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (s *server) registerClient(name string, c Client) {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	s.clients[name] = c
	klog.V(2).InfoS(&amp;quot;Registered client&amp;quot;, &amp;quot;name&amp;quot;, name)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type server struct {
	socketName string
	socketDir  string
	mutex      sync.Mutex
	wg         sync.WaitGroup
	grpc       *grpc.Server
	rhandler   RegistrationHandler
	chandler   ClientHandler
	clients    map[string]Client // 使用 map 存储，并为持久化
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-4-main-go&#34;&gt;3.4. main.go&lt;/h2&gt;

&lt;p&gt;main 方法分为三个部分：&lt;/p&gt;

&lt;p&gt;1) 启动 gRPC 服务
2) 向 Kubelet 进行注册
3) 监控 kubelet.sock 状态&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func main() {
	klog.Infof(&amp;quot;device plugin starting&amp;quot;)
	dp := device_plugin.NewGopherDevicePlugin()
	go dp.Run()

	// register when device plugin start
	if err := dp.Register(); err != nil {
		klog.Fatalf(&amp;quot;register to kubelet failed: %v&amp;quot;, err)
	}

	// watch kubelet.sock,when kubelet restart,exit device plugin,then will restart by DaemonSet
	stop := make(chan struct{})
	err := utils.WatchKubelet(stop)
	if err != nil {
		klog.Fatalf(&amp;quot;start to kubelet failed: %v&amp;quot;, err)
	}

	&amp;lt;-stop
	klog.Infof(&amp;quot;kubelet restart,exiting&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;4-测试&#34;&gt;4. 测试&lt;/h1&gt;

&lt;h2 id=&#34;4-1-编译&#34;&gt;4.1. 编译&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:mospany/i-device-plugin.git
cd i-device-plugin
make build-image
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-24-device-plugin/IMG_20250125-200208751.png&#34; alt=&#34;picture 2&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;4-2-打包镜像&#34;&gt;4.2. 打包镜像&lt;/h2&gt;

&lt;p&gt;由于国内不能直接访问hub.docker.io了，需本地导入。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker save mospany/i-device-plugin:latest -o i-device-plugin_latest.tar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将在本地目录下生成i-device-plugin_latest.tar。&lt;/p&gt;

&lt;h2 id=&#34;4-3-导入镜像&#34;&gt;4.3. 导入镜像&lt;/h2&gt;

&lt;p&gt;将编译机上生成的镜像上传到目标worker上，再导入。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ctr -n k8s.io image import i-device-plugin_latest.tar 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@k8s-worker1 img]# crictl images | grep i-device
docker.io/mospany/i-device-plugin                                                     latest                             5954f214c8b06       23.5MB
[root@k8s-worker1 img]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;4-4-部署&#34;&gt;4.4. 部署&lt;/h2&gt;

&lt;p&gt;首先是部署 i-device-plugin，一般使用 DaemonSet 方式部署，完整 yaml 如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: i-device-plugin
  namespace: kube-system
  labels:
    app: i-device-plugin
spec:
  selector:
    matchLabels:
      app: i-device-plugin
  template:
    metadata:
      labels:
        app: i-device-plugin
    spec:
      containers:
        - name: i-device-plugin
          image: mospany/i-device-plugin:latest
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: &amp;quot;1&amp;quot;
              memory: &amp;quot;512Mi&amp;quot;
            requests:
              cpu: &amp;quot;0.1&amp;quot;
              memory: &amp;quot;128Mi&amp;quot;
          volumeMounts:
            - name: device-plugin
              mountPath: /var/lib/kubelet/device-plugins
            - name: gophers
              mountPath: /etc/gophers
      volumes:
        - name: device-plugin
          hostPath:
            path: /var/lib/kubelet/device-plugins
        - name: gophers
          hostPath:
            path: /etc/gophers

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以 hostPath 方式将用到的两个目录挂载到 Pod 里：
&lt;img src=&#34;post/2024/images/2024-01-24-device-plugin/IMG_20250125-214446131.png&#34; alt=&#34;picture 3&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;/var/lib/kubelet/device-plugins：请求 kubelet.sock 发起调用，同时将 device-plugin gRPC 服务的 sock 文件写入该目录供 kubelet 调用&lt;/li&gt;
&lt;li&gt;/etc/gophers：在该 Demo 中，把 /etc/gophers 目录下的文件作为设备，因此需要将其挂载到 Pod 里。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用kubectl进行apply下yaml文件，确保 i-device-plugin 已经启动。
&lt;img src=&#34;post/2024/images/2024-01-24-device-plugin/IMG_20250125-214524956.png&#34; alt=&#34;picture 4&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;4-5-初始化&#34;&gt;4.5. 初始化&lt;/h2&gt;

&lt;p&gt;在该 Demo 中，把 /etc/gophers 目录下的文件作为设备，因此我们只需要到 /etc/gophers 目录下创建文件，模拟有新的设备接入即可。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir /etc/gophers

touch /etc/gophers/g1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看 device plugin 日志
&lt;img src=&#34;post/2024/images/2024-01-24-device-plugin/IMG_20250125-214911049.png&#34; alt=&#34;picture 5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到，已经感知到新增的设备了。&lt;/p&gt;

&lt;p&gt;不出意外的话可以在 node 上看到新资源了&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-24-device-plugin/IMG_20250125-215648627.png&#34; alt=&#34;picture 6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;果然，node capacity 中新增了lixueduan.com/gopher: &amp;ldquo;1&amp;rdquo;， 代表创建了2个设备：/etc/gophers/g1和/etc/gophers/g2。&lt;/p&gt;

&lt;h2 id=&#34;4-6-创建测试-pod&#34;&gt;4.6. 创建测试 Pod&lt;/h2&gt;

&lt;p&gt;接下来创建一个 Pod 申请该资源试试&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  name: gopher-pod
spec:
  containers:
  - name: gopher-container
    image: docker.m.daocloud.io/busybox
    command: [&amp;quot;sh&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;echo Hello, Kubernetes! &amp;amp;&amp;amp; sleep 3600&amp;quot;]
    resources:
      requests:
        lixueduan.com/gopher: &amp;quot;1&amp;quot;
      limits:
        lixueduan.com/gopher: &amp;quot;1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pod 启动成功&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 yaml]# kubectl  get pod -A | grep gopher
default        gopher-pod                                                        1/1     Running     0               4m18s
[root@k8s-master1 yaml]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之前分配设备是添加 Gopher=xxx 这个环境变量，现在看下是否正常分配&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 yaml]# kubectl  exec -ti gopher-pod -- env | grep -i goph
HOSTNAME=gopher-pod
Gopher=g2
[root@k8s-master1 yaml]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ok,环境变量存在，可以看到分配给该 Pod 的设备是 g2。&lt;/p&gt;

&lt;h1 id=&#34;5-小结&#34;&gt;5. 小结&lt;/h1&gt;

&lt;p&gt;本文主要分析了 k8s 中的 Device Plugin 机制的工作原理，并实现了一个简单的 &lt;strong&gt;i-device-plugin&lt;/strong&gt;来进一步加深理解。&lt;/p&gt;

&lt;p&gt;Device Plugin 的工作原理其实不复杂，可以分为 插件注册 和 kubelet 调用插件两部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;插件注册：DevicePlugin 启动时会想节点上的 Kubelet 发起注册，这样 Kubelet 就可以感知到该插件的存在了&lt;/li&gt;
&lt;li&gt;kubelet 调用插件：注册完成后，当有 Pod 申请对于资源时，kubelet 就会调用该插件 API 实现具体功能&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-24-device-plugin/IMG_20250125-223139774.png&#34; alt=&#34;picture 7&#34; /&gt;&lt;/p&gt;

&lt;p&gt;以下是总结的几个常见问题：&lt;/p&gt;

&lt;p&gt;1）device plugin 是怎么感知节点上的设备的？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一般设备都会在 /dev/ 目录下，比如 NVIDIA GPU 就是 /dev/nvidia0、/dev/nvidia1 这样，不过具体逻辑还是得硬件厂商自己实现&lt;/li&gt;
&lt;li&gt;然后 device plugin 会以 DaemonSet 方式部署到所有节点，因此能发现每个节点上的设备
&lt;img src=&#34;post/2024/images/2024-01-24-device-plugin/IMG_20250125-223501456.png&#34; alt=&#34;picture 8&#34; /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2）device plugin Allocate 方法怎么实现分配设备给容器的？
&amp;gt; 需要注意一点：Allocate 方法并没有真正将设备分配给容器，因为这个时候甚至都还没创建容器，只是在该方法中可以通过 Env、Mounts、Devices、Annotations、CDIDevices 等不同形式来传递 要将那些设备分配给该容器 这个信息给后续组件。&lt;/p&gt;

&lt;p&gt;这些信息传给 Kubelet，然后 Kubelet 通过 CRI 调用 Runtime（Docker/Containerd 等等）真正开始创建容器。&lt;/p&gt;

&lt;p&gt;比如 NVIDIA 在 Allocate 中就传递了 NVIDIA_VISIBLE_DEVICES 这个 Env，然后自己实现了 nvidia-container-runtime，该 runtime 就可以根据该 Env 知道要把哪个 GPU 分配给容器，然后修改容器的 OCI Spec，最终 runC(或者其他实现)真正创建容器时就会按照这个描述去处理。&lt;/p&gt;

&lt;p&gt;又比如 ix-device-plugin 就是用的 Devices 方式,直接指定分配给容器的设备在宿主机的位置，以及要挂载到容器中的位置，这样就不需要实现自己的 container-runtime 了，runC 创建容器时也能把对应设备分配给容器。&lt;/p&gt;

&lt;p&gt;这样又引出一个小问题，既然天数(ix-device-plugin)这个实现只用 Devices 就能正常运行，那为什么 NVIDIA 实现了 Devices 又实现了一个 Env？&lt;/p&gt;

&lt;p&gt;其实这个 Env 的实现是为了兼容非 k8s 环境，比如 Docker 环境：&lt;/p&gt;

&lt;p&gt;nvidia 可以在启动容器时指定 GPU&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# --gpus
docker run --gpus device=0 -it tensorflow/tensorflow:latest-gpu bash
# 或者环境变量 NVIDIA_VISIBLE_DEVICES
docker run -e NVIDIA_VISIBLE_DEVICES=0 -it tensorflow/tensorflow:latest-gpu bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;而天数则不行，就像这样：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo docker run --shm-size=&amp;quot;32g&amp;quot; -it -v /usr/src:/usr/src -v /lib/modules:/lib/modules -v /dev:/dev --privileged --cap-add=ALL --pid=host corex:4.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，需要自己使用 -v 将相关文件挂载进容器才能使用，nvidia-container-runtime 实则是将这部分进行了封装简化，用户只需要传一个参数即可。&lt;/p&gt;

&lt;p&gt;3）为什么 device plugin 要 Watch Kubelet 状态，当 Kubelet 重启后 device plugin 也要跟着重启。&lt;/p&gt;

&lt;p&gt;这个问题实际上可以翻译为：为什么 Kubelet 重启后，device plugin 需要重新向 Kubelet 注册？&lt;/p&gt;

&lt;p&gt;因为 device plugin 的注册信息 Kubelet 是存在内存中的，使用 Go 中的 Map 结构进行存储。重启后就会丢失，因此各个 device plugin 都需要重新注册。&lt;/p&gt;

&lt;p&gt;至于为什么 device plugin 一般也会跟着重启，是因为 device plugin 在启动时会调用因此注册接口，因此感知到 Kubelet 重启了，直接让 device plugin 退出即可，然后 DaemonSet 会重新拉起 Pod，这样启动后自动调用注册接口。&lt;/p&gt;

&lt;h1 id=&#34;6-参考&#34;&gt;6. 参考&lt;/h1&gt;

&lt;p&gt;【01】&lt;a href=&#34;https://www.lixueduan.com/posts/kubernetes/21-device-plugin/&#34;&gt;Kubernetes教程(二一)&amp;mdash;自定义资源支持：K8s Device Plugin 从原理到实现&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>K8S项目实践(09): 使用 GPU Operator搭建AI算力环境</title>
            <link>http://mospany.github.io/2024/01/17/gpu-operator/</link>
            <pubDate>Wed, 17 Jan 2024 19:31:10 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2024/01/17/gpu-operator/</guid>
            <description>

&lt;h1 id=&#34;1-引言&#34;&gt;1. 引言&lt;/h1&gt;

&lt;p&gt;为了学习AI应用、算法与算力等技术，应用需跑在GPU卡上，需要在节点上安装 GPU Driver、Container Toolkit 等组件，当集群规模较大时还是比较麻烦的。&lt;/p&gt;

&lt;p&gt;为了解决这个问题，NVIDIA 推出了 GPU Operator，GPU Operator 旨在简化在 Kubernetes 环境中使用 GPU 的过程，通过自动化的方式处理 GPU 驱动程序安装、Controller Toolkit、Device-Plugin 、监控等组件。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;基本上把需要手动安装、配置的地方全部自动化处理了，极大简化了 k8s 环境中的 GPU 使用。&lt;/p&gt;

&lt;p&gt;ps：只有 NVIDIA GPU 可以使用，其他厂家现在基本还是手动安装。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;2-规划&#34;&gt;2. 规划&lt;/h1&gt;

&lt;p&gt;本文主要分享如何使用 GPU Operator 快速搭建 Kubernetes GPU 环境。&lt;/p&gt;

&lt;p&gt;基于如下环境搭建：
&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250117-194645644.png&#34; alt=&#34;picture 0&#34; /&gt;&lt;br /&gt;
查看worker节点GPU信息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-worker1 ~]# lspci | grep -i nvidia
00:07.0 VGA compatible controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)
[root@k8s-worker1 ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;说明该worker节点有1张NVIDIA Tesla T4的GPU卡。&lt;/p&gt;

&lt;h1 id=&#34;3-组件介绍&#34;&gt;3. 组件介绍&lt;/h1&gt;

&lt;p&gt;这部分主要分析下 GPU Operator 涉及到的各个组件及其作用。&lt;/p&gt;

&lt;p&gt;NVIDIA GPU Operator总共包含如下的几个组件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;NFD(Node Feature Discovery)：用于给节点打上某些标签，这些标签包括 cpu id、内核版本、操作系统版本、是不是 GPU 节点等，其中需要关注的标签是nvidia.com/gpu.present=true，如果节点存在该标签，那么说明该节点是 GPU 节点。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;GFD(GPU Feature Discovery)：用于收集节点的 GPU 设备属性（GPU 驱动版本、GPU型号等），并将这些属性以节点标签的方式透出。在k8s 集群中以 DaemonSet 方式部署，只有节点拥有标签nvidia.com/gpu.present=true时，DaemonSet 控制的 Pod 才会在该节点上运行。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;新版本 GFD 迁移到了 &lt;a href=&#34;https://github.com/NVIDIA/k8s-device-plugin/tree/main/docs/gpu-feature-discovery&#34;&gt;NVIDIA/k8s-device-plugin&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;NVIDIA Driver Installer：基于容器的方式在节点上安装 NVIDIA GPU 驱动，在 k8s 集群中以 DaemonSet 方式部署，只有节点拥有标签nvidia.com/gpu.present=true时，DaemonSet 控制的 Pod 才会在该节点上运行。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;NVIDIA Container Toolkit Installer：能够实现在容器中使用 GPU 设备，在 k8s 集群中以 DaemonSet 方式部署，同样的，只有节点拥有标签nvidia.com/gpu.present=true时，DaemonSet 控制的 Pod 才会在该节点上运行。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;NVIDIA Device Plugin：NVIDIA Device Plugin 用于实现将 GPU 设备以 Kubernetes 扩展资源的方式供用户使用，在 k8s 集群中以 DaemonSet 方式部署，只有节点拥有标签nvidia.com/gpu.present=true时，DaemonSet 控制的 Pod 才会在该节点上运行。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;DCGM Exporter：周期性的收集节点 GPU 设备的状态（当前温度、总的显存、已使用显存、使用率等）并暴露 Metrics，结合 Prometheus 和 Grafana 使用。在 k8s 集群中以DaemonSet 方式部署，只有节点拥有标签nvidia.com/gpu.present=true时，DaemonSet 控制的 Pod 才会在该节点上运行。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;首先是 GFD、NFD，二者都是用于发现 Node 上的信息，并以 label 形式添加到 k8s node 对象上，特别是 GFD 会添加nvidia.com/gpu.present=true 标签表示该节点有 GPU，只有携带该标签的节点才会安装后续组件。&lt;/p&gt;

&lt;p&gt;然后则是 Driver Installer、Container Toolkit Installer 用于安装 GPU 驱动和 container toolkit。&lt;/p&gt;

&lt;p&gt;接下来则是 device-plugin 让 k8s 能感知到 GPU 资源信息便于调度和管理。&lt;/p&gt;

&lt;p&gt;最后的 exporter 则是采集 GPU 监控并以 Prometheus Metrics 格式暴露，用于做 GPU 监控。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;这些组件基本就把需要手动配置的东西都自动化了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;NVIDIA GPU Operator 依如下的顺序部署各个组件，并且如果前一个组件部署失败，那么其后面的组件将停止部署：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;NVIDIA Driver Installer&lt;/li&gt;
&lt;li&gt;NVIDIA Container Toolkit Installer&lt;/li&gt;
&lt;li&gt;NVIDIA Device Plugin&lt;/li&gt;
&lt;li&gt;DCGM Exporter&lt;/li&gt;
&lt;li&gt;GFD&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每个组件都是以 DaemonSet 方式部署，并且只有当节点存在标签 nvidia.com/gpu.present=true 时，各 DaemonSet控制的 Pod 才会在节点上运行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nvidia.com/gpu.deploy.driver=pre-installed
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-1-gfd-nfd&#34;&gt;3.1. GFD &amp;amp; NFD&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;GFD：GPU Feature Discovery&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;NFD：Node Feature Discovery&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;根据名称基本能猜到这两个组件的功能，发现节点信息和 GPU 信息并以 Label 形式添加到 k8s 中的 node 对象上。&lt;/p&gt;

&lt;p&gt;其中 NFD 添加的 label 以   feature.node.kubernetes.io 作为前缀，比如:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;feature.node.kubernetes.io/cpu-cpuid.ADX=true
feature.node.kubernetes.io/system-os_release.ID=ubuntu
feature.node.kubernetes.io/system-os_release.VERSION_ID.major=22
feature.node.kubernetes.io/system-os_release.VERSION_ID.minor=04
feature.node.kubernetes.io/system-os_release.VERSION_ID=22.04
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于 GFD 则主要记录 GPU 信息&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nvidia.com/cuda.runtime.major=12
nvidia.com/cuda.runtime.minor=2
nvidia.com/cuda.driver.major=535
nvidia.com/cuda.driver.minor=161
nvidia.com/gpu.product=Tesla-T4
nvidia.com/gpu.memory=15360
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-2-driver-installer&#34;&gt;3.2. Driver Installer&lt;/h2&gt;

&lt;p&gt;NVIDIA 官方提供了一种基于容器安装 NVIDIA 驱动的方式，GPU Operator 安装 nvidia 驱动也是采用的这种方式。&lt;/p&gt;

&lt;p&gt;当 NVIDIA 驱动基于容器化安装后，整个架构将演变成图中描述的样子：
&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250123-152421553.png&#34; alt=&#34;picture 5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Driver Installer 组件对应的 DaemonSet 就是nvidia-driver-daemonset-5.15.0-105-generic-ubuntu22.04。&lt;/p&gt;

&lt;p&gt;该 DaemonSet 对应的镜像为&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@test:~# kgo get ds nvidia-driver-daemonset-5.15.0-105-generic-ubuntu22.04 -oyaml|grep image
        image: nvcr.io/nvidia/driver:535-5.15.0-105-generic-ubuntu22.04
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 DaemonSet 名称/镜像由几部分组件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;nvidia-driver-daemonset 这部分为前缀&lt;/li&gt;
&lt;li&gt;5.15.0-105-generic 为内核版本，使用uname -r 命令查看&lt;/li&gt;
&lt;li&gt;ubuntu22.04 操作系统版本，使用cat /etc/os-release 命令查看&lt;/li&gt;
&lt;li&gt;535：这个是 GPU Driver 的版本号，这里表示安装 535 版本驱动，在部署时可以指定。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GPU Operator 会自动根据节点上的内核版本和操作系统生成 DaemonSet 镜像，因为是以 DaemonSet 方式运行的，所有节点上都是跑的同一个 Pod，&lt;strong&gt;因此要限制集群中的所有 GPU 节点操作系统和内核版本必须一致。&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ps：如果提前手动在节点上安装 GPU 驱动，那么 GPU Operator 检测到之后就不会在该节点上启动 Installer Pod，这样该节点就可以不需要管操作系统和内核版本。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;3-3-nvidia-container-toolkit-installer&#34;&gt;3.3. NVIDIA Container Toolkit Installer&lt;/h2&gt;

&lt;p&gt;该组件用于安装 NVIDIA Container Toolkit。&lt;/p&gt;

&lt;p&gt;手动安装的时候有两个步骤：&lt;/p&gt;

&lt;p&gt;1）安装 NVIDIA Container Toolkit&lt;/p&gt;

&lt;p&gt;2）修改 Runtime 配置指定使用 nvidia-runtime&lt;/p&gt;

&lt;p&gt;在整个调用链中新增 nvidia-container-runtime，以便处理 GPU 相关操作。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250123-153551818.png&#34; alt=&#34;picture 6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这个 Installer 做的操作也就是这两步：&lt;/p&gt;

&lt;p&gt;1）将容器中NVIDIA Container Toolkit组件所涉及的命令行工具和库文件移动到/usr/local/nvidia/toolkit目录下&lt;/p&gt;

&lt;p&gt;2）在 /usr/local/nvidia/toolkit/.config/nvidia-container-runtime创建nvidia-container-runtime的配置文件config.toml，并设置nvidia-container-cli.root的值为/run/nvidia/driver。&lt;/p&gt;

&lt;h1 id=&#34;4-部署&#34;&gt;4. 部署&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;参考官方文档： &lt;a href=&#34;https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/getting-started.html#operator-install-guide&#34;&gt;operator-install-guide&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;4-1-准备工作&#34;&gt;4.1. 准备工作&lt;/h2&gt;

&lt;p&gt;要求：&lt;/p&gt;

&lt;p&gt;1）GPU 节点必须运行相同的操作系统，&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果提前手动在节点上安装驱动的话，该节点可以使用不同的操作系统&lt;/li&gt;
&lt;li&gt;CPU 节点操作系统没要求，因为 gpu-operator 只会在 GPU 节点上运行
2）GPU 节点必须配置相同容器引擎，例如都是 containerd 或者都是 docker&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;3）如果使用了 Pod Security Admission (PSA) ，需要为 gpu-operator 标记特权模式&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 ~]# kubectl create ns gpu-operator
namespace/gpu-operator created
[root@k8s-master1 ~]# kubectl label --overwrite ns gpu-operator pod-security.kubernetes.io/enforce=privileged
namespace/gpu-operator labeled
[root@k8s-master1 ~]# kubectl get ns gpu-operator --show-labels
NAME           STATUS   AGE   LABELS
gpu-operator   Active   30s   kubernetes.io/metadata.name=gpu-operator,pod-security.kubernetes.io/enforce=privileged
[root@k8s-master1 ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4）集群中不要安装 NFD，如果已经安装了需要再安装 gpu-operator 时禁用 NFD 部署。&lt;/p&gt;

&lt;p&gt;使用以下命令查看集群中是否部署 NFD&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl get nodes -o json | jq &#39;.items[].metadata.labels | keys | any(startswith(&amp;quot;feature.node.kubernetes.io&amp;quot;))&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果返回 true 则说明集群中安装了 NFD。&lt;/p&gt;

&lt;h2 id=&#34;4-2-helm部署&#34;&gt;4.2. helm部署&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;参考官方文档： &lt;a href=&#34;https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/getting-started.html#operator-install-guide&#34;&gt;operator-install-guide&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;4-2-1-安装helm命令&#34;&gt;4.2.1. 安装helm命令&lt;/h3&gt;

&lt;p&gt;如果master节点上还未安装helm命令，需安装&lt;/p&gt;

&lt;h4 id=&#34;4-2-1-1-下载-helm-3-的最新版本&#34;&gt;4.2.1.1. 下载 Helm 3 的最新版本&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl https://get.helm.sh/helm-v3.11.1-linux-amd64.tar.gz -o helm-v3.11.1-linux-amd64.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;4-2-1-2-解压安装包&#34;&gt;4.2.1.2. 解压安装包&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 helm]# ls
helm-v3.11.1-linux-amd64.tar.gz
[root@k8s-master1 helm]# tar -zxvf helm-v3.11.1-linux-amd64.tar.gz 
linux-amd64/
linux-amd64/helm
linux-amd64/LICENSE
linux-amd64/README.md
[root@k8s-master1 helm]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;4-2-1-3-移动-helm-到系统的可执行路径&#34;&gt;4.2.1.3. 移动 helm 到系统的可执行路径&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mv linux-amd64/helm /usr/local/bin/helm`
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;4-2-1-4-验证安装&#34;&gt;4.2.1.4. 验证安装&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 helm]# helm version
version.BuildInfo{Version:&amp;quot;v3.11.1&amp;quot;, GitCommit:&amp;quot;293b50c65d4d56187cd4e2f390f0ada46b4c4737&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, GoVersion:&amp;quot;go1.18.10&amp;quot;}
[root@k8s-master1 helm]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;说明安装成功。&lt;/p&gt;

&lt;h3 id=&#34;4-2-2-chart部署&#34;&gt;4.2.2. chart部署&lt;/h3&gt;

&lt;h4 id=&#34;4-2-2-1-添加repo仓库&#34;&gt;4.2.2.1. 添加repo仓库&lt;/h4&gt;

&lt;p&gt;添加 nvidia helm 仓库并更新&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;helm repo add nvidia https://helm.ngc.nvidia.com/nvidia \
    &amp;amp;&amp;amp; helm repo update
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;4-2-2-2-拉取chart包&#34;&gt;4.2.2.2. 拉取chart包&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;helm pull nvidia/gpu-operator --version v24.9.1 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将在本地生成gpu-operator-v24.9.1.tgz文件。&lt;/p&gt;

&lt;h4 id=&#34;4-2-2-3-准备镜像&#34;&gt;4.2.2.3. 准备镜像&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;所有节点上执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;由于有些镜像国内不能直接访问，需从国内镜像地址拉取后再修改tag。
1）拉取国内代理镜像：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;crictl pull swr.cn-north-4.myhuaweicloud.com/ddn-k8s/registry.k8s.io/nfd/node-feature-discovery:v0.16.6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2）修改镜像tag：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ctr -n k8s.io image tag  swr.cn-north-4.myhuaweicloud.com/ddn-k8s/registry.k8s.io/nfd/node-feature-discovery:v0.16.6 registry.k8s.io/nfd/node-feature-discovery:v0.16.6 
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;4-2-2-4-安装chart包&#34;&gt;4.2.2.4. 安装chart包&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 添加 nvidia helm 仓库并更新
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia \
    &amp;amp;&amp;amp; helm repo update
# 以默认配置安装
helm install --wait --generate-name \
    -n gpu-operator --create-namespace \
    nvidia/gpu-operator

# 如果提前手动安装了 gpu 驱动，operator 中要禁止 gpu 安装
helm install --wait --generate-name \
     -n gpu-operator --create-namespace \
     nvidia/gpu-operator \
     --set driver.enabled=false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;完成后 会启动 Pod 安装驱动，如果节点上已经安装了驱动了，那么 gpu-operaotr 就不会启动安装驱动的 Pod,通过 label 进行筛选。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;没安装驱动的节点会打上 nvidia.com/gpu.deploy.driver=true ,表示需要安装驱动&lt;/li&gt;
&lt;li&gt;已经手动安装过驱动的节点会打上nvidia.com/gpu.deploy.driver=pre-install,Daemonset 则不会在该节点上运行
&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250123-113127922.png&#34; alt=&#34;picture 1&#34; /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;当然，并不是每个操作系统+内核版本的组合，NVIDIA 都提供了对应的镜像，可以提前在 NVIDIA/driver tags 查看当前 NVIDIA 提供的驱动版本。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;5-测试&#34;&gt;5. 测试&lt;/h1&gt;

&lt;p&gt;部署后，会在gpu-operator namespace 下启动相关 Pod，查看一下 Pod 的运行情况，除了一个 Completed 之外其他应该都是 Running 状态。
&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250123-113933891.png&#34; alt=&#34;picture 2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后进入nvidia-device-plugin-daemonset-xxx Pod，在该 Pod 中可以执行 nvidia-smi命令,比如查看 GPU 信息：
&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250123-115125616.png&#34; alt=&#34;picture 3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;最后再查看 node 信息
&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250123-115436263.png&#34; alt=&#34;picture 4&#34; /&gt;&lt;br /&gt;
可以看出nvidia.com/gpu: &amp;ldquo;1&amp;rdquo;总量为1， 可分配也为1。&lt;/p&gt;

&lt;p&gt;至此，说明我们的 GPU Operator 已经安装成功，K8s 也能感知到节点上的 GPU，接下来就可以在 Pod 中使用 GPU 了。&lt;/p&gt;

&lt;p&gt;创建一个测试 Pod，申请一个 GPU：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: v1
kind: Pod
metadata:
  name: cuda-vectoradd
spec:
  restartPolicy: OnFailure
  containers:
  - name: cuda-vectoradd
    image: &amp;quot;nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2&amp;quot;
    resources:
      limits:
        nvidia.com/gpu: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常的 Pod 日志如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 yaml]# kubectl logs cuda-vectoradd 
[Vector addition of 50000 elements]
Copy input data from the host memory to the CUDA device
CUDA kernel launch with 196 blocks of 256 threads
Copy output data from the CUDA device to the host memory
Test PASSED
Done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此，我们已经可以在 k8s 中使用 GPU 了。&lt;/p&gt;

&lt;h1 id=&#34;6-原理&#34;&gt;6. 原理&lt;/h1&gt;

&lt;p&gt;这部分主要分析一下 Driver Installer 和 NVIDIA Container Toolkit Installer 这两个组件是怎么实现的，大致原理。&lt;/p&gt;

&lt;h2 id=&#34;6-1-driver-installer&#34;&gt;6.1. Driver Installer&lt;/h2&gt;

&lt;p&gt;NVIDIA 官方提供了一种基于容器安装 NVIDIA 驱动的方式，GPU Operator 安装 nvidia 驱动也是采用的这种方式。&lt;/p&gt;

&lt;p&gt;当 NVIDIA 驱动基于容器化安装后，整个架构将演变成图中描述的样子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250123-184040318.png&#34; alt=&#34;picture 7&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;6-2-nvidia-container-toolkit-installer&#34;&gt;6.2. NVIDIA Container Toolkit Installer&lt;/h2&gt;

&lt;p&gt;该组件用于安装 NVIDIA Container Toolkit。&lt;/p&gt;

&lt;p&gt;手动安装的时候有两个步骤：&lt;/p&gt;

&lt;p&gt;1）安装 NVIDIA Container Toolkit&lt;/p&gt;

&lt;p&gt;2）修改 Runtime 配置指定使用 nvidia-runtime
&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250123-190232787.png&#34; alt=&#34;picture 9&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在整个调用链中新增 nvidia-container-runtime，以便处理 GPU 相关操作。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250123-185351436.png&#34; alt=&#34;picture 8&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这个 Installer 做的操作也就是这两步：&lt;/p&gt;

&lt;p&gt;1）将容器中NVIDIA Container Toolkit组件所涉及的命令行工具和库文件移动到/usr/local/nvidia/toolkit目录下
&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250123-211806300.png&#34; alt=&#34;picture 10&#34; /&gt;&lt;/p&gt;

&lt;p&gt;2）在 /usr/local/nvidia/toolkit/.config/nvidia-container-runtime创建nvidia-container-runtime的配置文件config.toml，并设置nvidia-container-cli.root的值为/run/nvidia/driver。
&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250123-212557933.png&#34; alt=&#34;picture 11&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;7-小结&#34;&gt;7. 小结&lt;/h1&gt;

&lt;p&gt;小结
本文主要分享如何使用 GPU Operator 自动化完成 GPU Driver、NVIDIA Container Toolkit、device-plugin、exporter 等组件的部署，快速实现在 k8s 环境中使用 GPU。&lt;/p&gt;

&lt;p&gt;最后简单分析了 Driver Installer 和 NVIDIA Container Toolkit Installer 这两个组件的工作原理。&lt;/p&gt;

&lt;p&gt;GPU Operator 极大简化了在 k8s 中使用 GPU 的繁琐过程，但是也存在一些缺点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Driver Installer 以 DaemonSet 方式运行的，每个节点上运行的 Pod 都一样，但是镜像由 驱动版本+内核版本+操作系统版本拼接而成，因此需要集群中所有节点操作系统一致。&lt;/li&gt;
&lt;li&gt;NVIDIA Container Toolkit Installer 同样是以 DaemonSet 方式运行的，另外安装时需要指定 Runtime，这也造成了集群的节点必须安装相同的 Container Runtime。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;8-参考资料&#34;&gt;8. 参考资料&lt;/h1&gt;

&lt;p&gt;【01】&lt;a href=&#34;https://www.lixueduan.com/posts/ai/02-gpu-operator/#2-%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D&#34;&gt;GPU 环境搭建指南：使用 GPU Operator 加速 Kubernetes GPU 环境搭建&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>K8S项目实践(08): 在ECS、Docker、K8s 等环境中使用 GPU</title>
            <link>http://mospany.github.io/2024/01/16/gpu-on-k8s/</link>
            <pubDate>Tue, 16 Jan 2024 19:31:10 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2024/01/16/gpu-on-k8s/</guid>
            <description>

&lt;h1 id=&#34;1-引言&#34;&gt;1. 引言&lt;/h1&gt;

&lt;p&gt;本文主要分享在不同环境，例如ECS、Docker 和 Kubernetes 等环境中如何使用 GPU。
&lt;strong&gt;注&lt;/strong&gt;：由于没有物理机裸机，在阿里云上申请ECS也可满足学习使用。&lt;/p&gt;

&lt;h1 id=&#34;2-规划&#34;&gt;2. 规划&lt;/h1&gt;

&lt;p&gt;基于如下环境搭建：
&lt;img src=&#34;post/2024/images/2024-01-17-gpu-operator/IMG_20250117-194645644.png&#34; alt=&#34;picture 0&#34; /&gt;&lt;br /&gt;
查看worker节点GPU信息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-worker1 ~]# lspci | grep -i nvidia
00:07.0 VGA compatible controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)
[root@k8s-worker1 ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;说明该worker节点有1张NVIDIA Tesla T4的GPU卡。&lt;/p&gt;

&lt;h1 id=&#34;3-概述&#34;&gt;3. 概述&lt;/h1&gt;

&lt;p&gt;仅以比较常见的 NVIDIA GPU 举例，系统为 Linux，对于其他厂家的 GPU 设备理论上流程都是一样的。&lt;/p&gt;

&lt;p&gt;省流：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;对于ECS环境，只需要安装对应的 &lt;a href=&#34;https://help.aliyun.com/zh/egs/user-guide/installation-guideline-for-nvidia-drivers?spm=a2c4g.11186623.help-menu-155040.d_1_5_0.726f718evZrl7t&#34;&gt;GPU Driver&lt;/a&gt;（GPU计算型实例为Tesla驱动，GPU虚拟化型实例为GRID驱动） 以及 CUDA Toolkit 。&lt;/li&gt;
&lt;li&gt;对应 Docker 环境，需要额外安装 nvidia-container-toolkit 并配置 docker 使用 nvidia runtime。&lt;/li&gt;
&lt;li&gt;对应 k8s 环境，需要额外安装对应的 device-plugin 使得 kubelet 能够感知到节点上的 GPU 设备，以便 k8s 能够进行 GPU 管理。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;注：一般在 k8s 中使用都会直接使用 gpu-operator 方式进行安装，本文主要为了搞清各个组件的作用，因此进行手动安装。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ps；下一篇分享下如何使用 gpu-operator 快速完成安装&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;4-ecs环境&#34;&gt;4. ECS环境&lt;/h1&gt;

&lt;p&gt;裸机中要使用上 GPU 需要安装以下组件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GPU Driver&lt;/li&gt;
&lt;li&gt;CUDA Toolkit
二者的关系如 NVIDIA 官网上的这个图所示：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250120-152256220.png&#34; alt=&#34;picture 0&#34; /&gt;&lt;/p&gt;

&lt;p&gt;GPU Driver 包括了 GPU 驱动和 CUDA 驱动，CUDA Toolkit 则包含了 CUDA Runtime。&lt;/p&gt;

&lt;p&gt;GPU 作为一个 PCIE 设备，只要安装好之后，在系统中就可以通过 lspci 命令查看到，先确认机器上是否有 GPU：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-worker1 ~]# lspci | grep -i nvidia
00:07.0 VGA compatible controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)
[root@k8s-worker1 ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;说明该worker节点有1张NVIDIA Tesla T4的GPU卡。&lt;/p&gt;

&lt;h2 id=&#34;4-1-安装grid驱动&#34;&gt;4.1. 安装GRID驱动&lt;/h2&gt;

&lt;p&gt;由于主机规格是ecs.sgn6i-vws-m2.xlarge，是虚拟化型规格，不能安装Tesla驱动的，需要安装grid驱动。
安装Tesla驱动的话将会出现&lt;a href=&#34;#61-error-unable-to-load-the-kernel-module-nvidiako&#34;&gt;ERROR: Unable to load the kernel module &amp;lsquo;nvidia.ko&amp;rsquo;.&lt;/a&gt;错误安装失败。&lt;/p&gt;

&lt;p&gt;安装步骤参考：&lt;a href=&#34;https://help.aliyun.com/zh/egs/user-guide/use-cloud-assistant-to-automatically-install-and-upgrade-grid-drivers?spm=a2c4g.11186623.help-menu-155040.d_1_5_2_1.65bd2ef7tthoW5&#34;&gt;在GPU虚拟化型实例中安装GRID驱动（Linux）&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-1-1-准备安装脚本&#34;&gt;4.1.1. 准备安装脚本&lt;/h3&gt;

&lt;p&gt;install-grid.sh内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
if acs-plugin-manager --list --local | grep grid_driver_install &amp;gt; /dev/null 2&amp;gt;&amp;amp;1
then
            acs-plugin-manager --remove --plugin grid_driver_install
fi

acs-plugin-manager --exec --plugin grid_driver_install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-1-2-安装grid&#34;&gt;4.1.2. 安装grid&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-worker1 ~]# sh install-grid.sh 
RemovePlugin success, plugin[grid_driver_install]
INFO[0000] Starting environment pre-check               
INFO[0000] environment pre-check done                   
INFO[0000] Check gpu device present                     
INFO[0000] Check gpu device present done                
INFO[0000] current installed gird driver is, 470.239.06 
INFO[0000] current installed gird driver is already SWL driver 
[root@k8s-worker1 ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-1-3-验证&#34;&gt;4.1.3. 验证&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@k8s-worker1 ~]# nvidia-smi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行成功，可看到有一张T4-2Q的GPU卡。
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250121-192347251.png&#34; alt=&#34;picture 6&#34; /&gt;&lt;br /&gt;
至此，我们就安装好 GPU 驱动了，系统也能正常识别到 GPU。&lt;/p&gt;

&lt;p&gt;这里显示的 CUDA 版本表示当前驱动最大支持的 CUDA 版本。&lt;/p&gt;

&lt;h2 id=&#34;4-2-安装cuda&#34;&gt;4.2. 安装CUDA&lt;/h2&gt;

&lt;h3 id=&#34;4-2-1-安装软件&#34;&gt;4.2.1. 安装软件&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run
sudo sh cuda_11.4.0_470.42.01_linux.run
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于已安装了GRID驱动，需取消cuda自带的驱动安装：
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250121-200338239.png&#34; alt=&#34;picture 7&#34; /&gt;&lt;br /&gt;
01) 安装全部组件：
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250121-200453794.png&#34; alt=&#34;picture 8&#34; /&gt;&lt;br /&gt;
02) 输出：
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250121-201735441.png&#34; alt=&#34;picture 9&#34; /&gt;&lt;/p&gt;

&lt;p&gt;03) 执行以下命令，重启GPU实例&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;04) 依次执行以下命令，配置CUDA环境变量。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &#39;export PATH=/usr/local/cuda/bin:$PATH&#39; | sudo tee /etc/profile.d/cuda.sh
source /etc/profile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;05) 检查CUDA是否成功安装。&lt;/p&gt;

&lt;p&gt;a) 执行nvcc -V命令，检查CUDA安装版本是否正确。
   &lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250121-202721754.png&#34; alt=&#34;picture 10&#34; /&gt;&lt;/p&gt;

&lt;p&gt;b) 依次执行以下命令，测试CUDA Samples，验证CUDA是否安装成功。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    [root@k8s-worker1 ~]# cd /usr/local/cuda-11.4/extras/demo_suite/
    [root@k8s-worker1 demo_suite]# ./deviceQuery  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果返回结果显示Result=PASS，则表示CUDA安装成功。
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250121-203410971.png&#34; alt=&#34;picture 11&#34; /&gt;&lt;/p&gt;

&lt;p&gt;06) 测试
我们使用一个简单的 Pytorch 程序来检测 GPU 和 CUDA 是否正常。&lt;/p&gt;

&lt;p&gt;整个调用链大概是这样的：
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250121-204049273.png&#34; alt=&#34;picture 12&#34; /&gt;&lt;br /&gt;
使用下面代码来测试能够正常使用， check_cuda_pytorch.py 内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch

def check_cuda_with_pytorch():
    &amp;quot;&amp;quot;&amp;quot;检查 PyTorch CUDA 环境是否正常工作&amp;quot;&amp;quot;&amp;quot;
    try:
        print(&amp;quot;检查 PyTorch CUDA 环境:&amp;quot;)
        if torch.cuda.is_available():
            print(f&amp;quot;CUDA 设备可用，当前 CUDA 版本是: {torch.version.cuda}&amp;quot;)
            print(f&amp;quot;PyTorch 版本是: {torch.__version__}&amp;quot;)
            print(f&amp;quot;检测到 {torch.cuda.device_count()} 个 CUDA 设备。&amp;quot;)
            for i in range(torch.cuda.device_count()):
                print(f&amp;quot;设备 {i}: {torch.cuda.get_device_name(i)}&amp;quot;)
                print(f&amp;quot;设备 {i} 的显存总量: {torch.cuda.get_device_properties(i).total_memory / (1024 ** 3):.2f} GB&amp;quot;)
                print(f&amp;quot;设备 {i} 的显存当前使用量: {torch.cuda.memory_allocated(i) / (1024 ** 3):.2f} GB&amp;quot;)
                print(f&amp;quot;设备 {i} 的显存最大使用量: {torch.cuda.memory_reserved(i) / (1024 ** 3):.2f} GB&amp;quot;)
        else:
            print(&amp;quot;CUDA 设备不可用。&amp;quot;)
    except Exception as e:
        print(f&amp;quot;检查 PyTorch CUDA 环境时出现错误: {e}&amp;quot;)

if __name__ == &amp;quot;__main__&amp;quot;:
    check_cuda_with_pytorch()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先安装下 torch&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m pip install torch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行一下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python check_cuda_pytorch.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常输出应该是这样的：
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250121-210940440.png&#34; alt=&#34;picture 13&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;4-3-更新cuda&#34;&gt;4.3. 更新CUDA&lt;/h2&gt;

&lt;p&gt;由于有些应用需要更高级的版本的CUDA，需升级，如下升级为12.6版本。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo
sudo dnf clean all
sudo dnf -y install cuda-toolkit-12-6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-203151909.png&#34; alt=&#34;picture 18&#34; /&gt;&lt;br /&gt;
验证:
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-203406637.png&#34; alt=&#34;picture 19&#34; /&gt;&lt;br /&gt;
说明12.6版本安装成功。
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-213858800.png&#34; alt=&#34;picture 20&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;5-docker环境&#34;&gt;5. Docker环境&lt;/h1&gt;

&lt;p&gt;上一步中我们已经在裸机上安装了 GPU Driver，CUDA Toolkit 等工具，实现了在宿主机上使用 GPU。&lt;/p&gt;

&lt;p&gt;现在希望在 Docker 容器中使用 GPU，需要怎么处理呢?&lt;/p&gt;

&lt;p&gt;为了让 Docker 容器中也能使用 GPU，大致步骤如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;安装docker，已有则跳过这步骤。&lt;/li&gt;
&lt;li&gt;安装 nvidia-container-toolkit 组件&lt;/li&gt;
&lt;li&gt;docker 配置使用 nvidia-runtime&lt;/li&gt;
&lt;li&gt;启动容器时增加 &amp;ndash;gpu 参数&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;5-1-docker安装&#34;&gt;5.1. Docker安装&lt;/h2&gt;

&lt;h3 id=&#34;5-1-1-安装必要的一些系统工具&#34;&gt;5.1.1. 安装必要的一些系统工具&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo yum install -y yum-utils
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-1-2-添加软件源信息&#34;&gt;5.1.2. 添加软件源信息&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-1-3-安装docker&#34;&gt;5.1.3. 安装Docker&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-1-4-开启docker服务&#34;&gt;5.1.4. 开启Docker服务&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo service docker start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-1-5-验证&#34;&gt;5.1.5. 验证&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@k8s-worker1 pytorch]# docker version
Client: Docker Engine - Community
 Version:           26.1.3
 API version:       1.45
 Go version:        go1.21.10
 Git commit:        b72abbb
 Built:             Thu May 16 08:34:39 2024
 OS/Arch:           linux/amd64
 Context:           default

Server: Docker Engine - Community
 Engine:
  Version:          26.1.3
  API version:      1.45 (minimum version 1.24)
  Go version:       go1.21.10
  Git commit:       8e96db1
  Built:            Thu May 16 08:33:34 2024
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.6.32
  GitCommit:        8b3b7ca2e5ce38e8f31a34f35b2b68ceb8470d89
 runc:
  Version:          1.1.12
  GitCommit:        v1.1.12-0-g51d5e94
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
[root@k8s-worker1 pytorch]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;5-2-安装-nvidia-container-toolkit&#34;&gt;5.2. 安装 nvidia-container-toolkit&lt;/h2&gt;

&lt;p&gt;NVIDIA Container Toolkit 的主要作用是将 NVIDIA GPU 设备挂载到容器中。
&amp;gt;兼容生态系统中的任意容器运行时，docker、containerd、cri-o 等。&lt;/p&gt;

&lt;p&gt;NVIDIA 官方安装文档：&lt;a href=&#34;https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html&#34;&gt;nvidia-container-toolkit-install-guide&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ALIOS或centos安装命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Configure the production repository:
curl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo | \
sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo

# Optionally, configure the repository to use experimental packages:
sudo yum-config-manager --enable nvidia-container-toolkit-experimental

#Install the NVIDIA Container Toolkit packages:
sudo yum install -y nvidia-container-toolkit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;安装成功如下：
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-185247937.png&#34; alt=&#34;picture 14&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;5-3-配置使用该-runtime&#34;&gt;5.3. 配置使用该 runtime&lt;/h2&gt;

&lt;p&gt;支持 Docker, Containerd, CRI-O, Podman 等 CRI。
&amp;gt;具体见官方文档 &lt;a href=&#34;https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuration&#34;&gt;container-toolkit#install-guide&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里以 Docker 为例进行配置：
旧版本需要手动在 /etc/docker/daemon.json 中增加配置，指定使用 nvidia 的 runtime。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;    &amp;quot;runtimes&amp;quot;: {
        &amp;quot;nvidia&amp;quot;: {
            &amp;quot;args&amp;quot;: [],
            &amp;quot;path&amp;quot;: &amp;quot;nvidia-container-runtime&amp;quot;
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;新版 toolkit 带了一个nvidia-ctk 工具，执行以下命令即可一键配置然后重启docker：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-191008933.png&#34; alt=&#34;picture 15&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;5-4-验证&#34;&gt;5.4. 验证&lt;/h2&gt;

&lt;p&gt;安装nvidia-container-toolkit 后，整个调用链如下：
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-191407685.png&#34; alt=&#34;picture 16&#34; /&gt;&lt;/p&gt;

&lt;p&gt;调用链从 containerd –&amp;gt; runC 变成 containerd –&amp;gt; nvidia-container-runtime –&amp;gt; runC 。&lt;/p&gt;

&lt;p&gt;然后 nvidia-container-runtime 在中间拦截了容器 spec，就可以把 gpu 相关配置添加进去，再传给 runC 的 spec 里面就包含 gpu 信息了。&lt;/p&gt;

&lt;p&gt;Docker 环境中的 CUDA 调用大概是这样的：
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-191542185.png&#34; alt=&#34;picture 17&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从图中可以看到，CUDA Toolkit 跑到容器里了，因此宿主机上不需要再安装 CUDA Toolkit。&lt;/p&gt;

&lt;p&gt;使用一个带 CUDA Toolkit 的镜像即可。&lt;/p&gt;

&lt;p&gt;最后我们启动一个 Docker 容器进行测试，其中命令中增加 &amp;ndash;gpu参数来指定要分配给容器的 GPU。&lt;/p&gt;

&lt;p&gt;gpu 参数可选值：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;gpus all：表示将所有 GPU 都分配给该容器&lt;/li&gt;
&lt;li&gt;gpus &amp;ldquo;device=&lt;id&gt;[,&lt;id&gt;&amp;hellip;]&amp;ldquo;：对于多 GPU 场景，可以通过 id 指定分配给容器的 GPU，例如 –gpu “device=0” 表示只分配 0 号 GPU 给该容器
GPU 编号则是通过nvidia-smi 命令进行查看&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里我们直接使用一个带 cuda 的镜像来测试，启动该容器并执行nvidia-smi 命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-worker1 ~]# docker run --rm --gpus all  nvcr.io/nvidia/cuda:11.0.3-runtime-ubuntu20.04 nvidia-smi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-214303643.png&#34; alt=&#34;picture 22&#34; /&gt;&lt;br /&gt;
正常情况下应该是可以打印出容器中的 GPU 信息的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;： 镜像需与grid驱动版本兼容，否则报错。&lt;/p&gt;

&lt;h1 id=&#34;6-k8s环境&#34;&gt;6. K8S环境&lt;/h1&gt;

&lt;p&gt;更进一步，在 k8s 环境中使用 GPU，则需要在集群中部署以下组件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;gpu-device-plugin 用于管理 GPU，device-plugin 以 DaemonSet 方式运行到集群各个节点，以感知节点上的 GPU 设备，从而让 k8s 能够对节点上的 GPU 设备进行管理。&lt;/li&gt;
&lt;li&gt;gpu-exporter：用于监控 GPU&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;各组件关系如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-215913188.png&#34; alt=&#34;picture 23&#34; /&gt;&lt;/p&gt;

&lt;p&gt;左图为手动安装的场景，只需要在集群中安装 device-plugin 和 监控即可使用。&lt;/p&gt;

&lt;p&gt;右图为使用 gpu-operotar 安装场景，本篇暂时忽略&lt;/p&gt;

&lt;p&gt;大致工作流程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每个节点的 kubelet 组件维护该节点的 GPU 设备状态（哪些已用，哪些未用）并定时报告给调度器，调度器知道每一个节点有多少张 GPU 卡可用。&lt;/li&gt;
&lt;li&gt;调度器为 pod 选择节点时，从符合条件的节点中选择一个节点。&lt;/li&gt;
&lt;li&gt;当 pod 调度到节点上后，kubelet 组件为 pod 分配 GPU 设备 ID，并将这些 ID 作为参数传递给 NVIDIA Device Plugin&lt;/li&gt;
&lt;li&gt;NVIDIA Device Plugin 将分配给该 pod 的容器的 GPU 设备 ID 写入到容器的环境变量 NVIDIA_VISIBLE_DEVICES中，然后将信息返回给 kubelet。&lt;/li&gt;
&lt;li&gt;kubelet 启动容器。&lt;/li&gt;
&lt;li&gt;NVIDIA Container Toolkit 检测容器的 spec 中存在环境变量 NVIDIA_VISIBLE_DEVICES，然后根据环境变量的值将 GPU 设备挂载到容器中。
在 Docker 环境我们在启动容器时通过 &amp;ndash;gpu 参数手动指定分配给容器的 GPU，k8s 环境则由 device-plugin 自行管理。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;6-1-集群环境&#34;&gt;6.1. 集群环境&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-220923122.png&#34; alt=&#34;picture 24&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;安装-device-plugin&#34;&gt;安装 device-plugin&lt;/h2&gt;

&lt;p&gt;device-plugin 一般由对应的 GPU 厂家提供，比如 NVIDIA 的 &lt;a href=&#34;https://github.com/NVIDIA/k8s-device-plugin&#34;&gt;k8s-device-plugin&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;安装其实很简单，将对应的 yaml apply 到集群即可。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.15.0/deployments/static/nvidia-device-plugin.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就像这样
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-221359266.png&#34; alt=&#34;picture 25&#34; /&gt;&lt;/p&gt;

&lt;p&gt;device-plugin 启动之后，会感知节点上的 GPU 设备并上报给 kubelet，最终由 kubelet 提交到 kube-apiserver。&lt;/p&gt;

&lt;p&gt;因此我们可以在 Node 可分配资源中看到 GPU，就像这样：
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250122-221933864.png&#34; alt=&#34;picture 26&#34; /&gt;&lt;br /&gt;
可以看到，除了常见的 cpu、memory 之外，还有nvidia.com/gpu, 这个就是 GPU 资源，数量为 0，应该为1，错误原因待查。
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250123-095336709.png&#34; alt=&#34;picture 27&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;安装-gpu-监控&#34;&gt;安装 GPU 监控&lt;/h2&gt;

&lt;p&gt;除此之外，如果你需要监控集群 GPU 资源使用情况，你可能还需要安装 DCCM exporter 结合 Prometheus 输出 GPU 资源监控信息。&lt;/p&gt;

&lt;p&gt;安装略。&lt;/p&gt;

&lt;h1 id=&#34;小结&#34;&gt;小结&lt;/h1&gt;

&lt;p&gt;本文主要分享了在ECS、Docker 环境、k8s 环境中如何使用 GPU。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;对于ECS环境，只需要安装对应的 GPU Driver 即可。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;对应 Docker 环境，需要额外安装 nvidia-container-toolkit 并配置 docker 使用 nvidia runtime。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;对应 k8s 环境，需要额外安装对应的 device-plugin 使得 kubelet 能够感知到节点上的 GPU 设备，以便 k8s 能够进行 GPU 管理。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;现在一般都是在 k8s 环境中使用，为了简化安装步骤， NVIDIA 也提供了 gpu-operator来简化安装部署，后续分享一下如何使用 gpu-operator来快速安装。&lt;/p&gt;

&lt;h1 id=&#34;7-参考资料&#34;&gt;7. 参考资料&lt;/h1&gt;

&lt;p&gt;【01】&lt;a href=&#34;https://blog.csdn.net/Doudou_Mylove/article/details/114388633&#34;&gt;阿里云GPU服务器安装驱动（完整版）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;【02】&lt;a href=&#34;https://help.aliyun.com/zh/egs/user-guide/install-a-gpu-driver-on-a-gpu-accelerated-compute-optimized-linux-instance?spm=a2c4g.11186623.help-menu-155040.d_1_5_1_1.6b70fb7cljEZnN&amp;amp;scm=20140722.H_163824._.OR_help-T_cn~zh-V_1&#34;&gt;在GPU计算型实例中手动安装Tesla驱动（Linux）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;【03】&lt;a href=&#34;https://help.aliyun.com/zh/egs/user-guide/use-cloud-assistant-to-automatically-install-and-upgrade-grid-drivers?spm=a2c4g.11186623.help-menu-155040.d_1_5_2_1.660551bd3LBP63&#34;&gt;在GPU虚拟化型实例中安装GRID驱动（Linux）&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;8-faq&#34;&gt;8. FAQ&lt;/h1&gt;

&lt;h2 id=&#34;8-1-error-unable-to-load-the-kernel-module-nvidia-ko&#34;&gt;8.1. ERROR: Unable to load the kernel module &amp;lsquo;nvidia.ko&amp;rsquo;.&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250120-155358481.png&#34; alt=&#34;picture 4&#34; /&gt;&lt;br /&gt;
错误详情提示：
&lt;img src=&#34;post/2024/images/2024-01-16-gpu-on-k8s/IMG_20250120-155501141.png&#34; alt=&#34;picture 5&#34; /&gt;&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>K8S项目实践(07): kubeadm安装k8s集群(containerd版)</title>
            <link>http://mospany.github.io/2024/01/15/kubeadm-install-k8s/</link>
            <pubDate>Mon, 15 Jan 2024 15:42:11 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2024/01/15/kubeadm-install-k8s/</guid>
            <description>

&lt;h1 id=&#34;1-规划&#34;&gt;1. 规划&lt;/h1&gt;

&lt;p&gt;使用 kubeadm 安装 Kubernetes 集群并使用 containerd 作为容器运行时（container runtime）是一种常见的安装方法。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;OS&lt;/th&gt;
&lt;th&gt;配置&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;aliOS(172.17.197.69)&lt;/td&gt;
&lt;td&gt;2核(vCPU) 4GiB 5 Mbps&lt;/td&gt;
&lt;td&gt;k8s-master1&lt;/td&gt;
&lt;td&gt;乌兰察布 可用区 C&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;aliOS(172.17.197.68)&lt;/td&gt;
&lt;td&gt;4核(vCPU) 10 GiB 5 Mbps GPU：NVIDIA T4/8&lt;/td&gt;
&lt;td&gt;k8s-worker1&lt;/td&gt;
&lt;td&gt;乌兰察布 可用区 C&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：这是演示 k8s 集群安装的实验环境，配置较低，生产环境中我们的服务器配置至少都是 8C/16G 的基础配置。&lt;/p&gt;

&lt;h1 id=&#34;2-版本选择&#34;&gt;2. 版本选择&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Alibaba Cloud Linux 3.2104 LTS 64位
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-1-配置主机名&#34;&gt;2.1. 配置主机名&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;所有节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 ~]# hostnamectl set-hostname k8s-master1
[root@k8s-worker1 ~]# hostnamectl set-hostname k8s-worker1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;2-2-关闭防火墙&#34;&gt;2.2. 关闭防火墙&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;所有节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; # 关闭firewalld
2  [root@k8s-master1 ~]# systemctl stop firewalld
3  
4  # 关闭selinux
5  [root@k8s-master1 ~]# sed -i &#39;s/enforcing/disabled/&#39; /etc/selinux/config
6  [root@k8s-master1 ~]# setenforce 0
7   setenforce: SELinux is disabled
8  [root@k8s-master1 ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;2-3-互做本地解析&#34;&gt;2.3. 互做本地解析&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;所有节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@k8s-master1 ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
8.130.117.184 k8s-master1
8.130.92.114  k8s-worker1
[root@k8s-master1 ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;2-4-ssh-免密通信-可选&#34;&gt;2.4. SSH 免密通信（可选）&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;master节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@k8s-master1 ~]# ssh-keygen
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-15-kubeadm-install-k8s/IMG_20250115-192630256.png&#34; alt=&#34;picture 0&#34; /&gt;&lt;br /&gt;
互发公钥&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 ~]# ssh-copy-id root@k8s-worker1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-15-kubeadm-install-k8s/IMG_20250115-193004163.png&#34; alt=&#34;picture 1&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;2-5-加载-br-netfilter-模块&#34;&gt;2.5. 加载 br_netfilter 模块&lt;/h2&gt;

&lt;p&gt;确保 br_netfilter 模块被加载
&amp;gt; 所有节点执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 加载模块
root@k8s-master1 ~]# modprobe br_netfilter
## 查看加载请看
[root@k8s-master1 ~]# lsmod | grep br_netfilter
br_netfilter           32768  0
bridge                270336  1 br_netfilter

# 永久生效
[root@k8s-master1 ~]# cat &amp;lt;&amp;lt;EOF | tee /etc/modules-load.d/k8s.conf
&amp;gt; br_netfilter
&amp;gt; EOF
br_netfilter
[root@k8s-master1 ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;2-6-允许-iptables-检查桥接流量&#34;&gt;2.6. 允许 iptables 检查桥接流量&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;所有节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 ~]# cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.d/k8s.conf
&amp;gt; net.bridge.bridge-nf-call-ip6tables = 1
&amp;gt; net.bridge.bridge-nf-call-iptables = 1
&amp;gt; EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
[root@k8s-master1 ~]# sysctl --system
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;2-7-关闭-swap&#34;&gt;2.7. 关闭 swap&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;所有节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 临时关闭
[root@k8s-master1 ~]# swapoff -a

# 永久关闭
[root@k8s-master1 ~]# sed -ri &#39;s/.*swap.*/#&amp;amp;/&#39; /etc/fstab
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;2-8-安装ipset及ipvsadm&#34;&gt;2.8. 安装ipset及ipvsadm&lt;/h2&gt;

&lt;p&gt;安装ipset及ipvsadm&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 ~]# dnf install -y ipset ipvsadm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置ipvsadm模块加载方式，添加需要加载的模块&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat &amp;gt; /etc/sysconfig/modules/ipvs.modules &amp;lt;&amp;lt;EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack
EOF

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;授权、运行、检查是否加载&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;amp;&amp;amp; bash /etc/sysconfig/modules/ipvs.modules &amp;amp;&amp;amp; lsmod | grep -e ip_vs -e nf_conntrack
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-15-kubeadm-install-k8s/IMG_20250116-135626938.png&#34; alt=&#34;picture 2&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;3-安装containerd&#34;&gt;3. 安装containerd&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;所有节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;3-1-安装-containerd&#34;&gt;3.1. 安装 containerd&lt;/h2&gt;

&lt;p&gt;通过 yum 安装 containerd：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@k8s-master1 ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
Adding repo from: http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
[root@k8s-master1 ~]# yum install containerd -y

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-2-配置-containerd&#34;&gt;3.2. 配置 containerd&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ /usr/bin/containerd config default &amp;gt; /etc/containerd/config.toml
$ sed -i &#39;s/SystemdCgroup = false/SystemdCgroup = true/g&#39; /etc/containerd/config.toml
$ sed -i &#39;s/sandbox_image = &amp;quot;registry.k8s.io\/pause:3.6&amp;quot;/sandbox_image = &amp;quot;registry.aliyuncs.com\/google_containers\/pause:3.9&amp;quot;/g&#39; /etc/containerd/config.toml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;： 记得确保配置修改成功，尤其是pause版本。&lt;/p&gt;

&lt;h2 id=&#34;3-3-启动containerd&#34;&gt;3.3. 启动containerd&lt;/h2&gt;

&lt;p&gt;启动并使 containerd 随系统启动：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@k8s-master1 ~]# sudo systemctl start containerd
root@k8s-master1 ~]# sudo systemctl enable containerd
root@k8s-master1 ~]# ps -ef | grep containerd
root       37760       1  0 07:35 ?        00:00:00 /usr/bin/containerd
root       37807   36202  0 07:35 pts/0    00:00:00 grep --color=auto containerd
[root@k8s-master1 ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;说明containerd已启动成功。
&lt;img src=&#34;post/2024/images/2024-01-15-kubeadm-install-k8s/IMG_20250116-160630369.png&#34; alt=&#34;picture 3&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;4-安装-kubeadm-kubelet&#34;&gt;4. 安装 kubeadm、kubelet&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;所有节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;4-1-添加-k8s-镜像源&#34;&gt;4.1. 添加 k8s 镜像源&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;地址： &lt;a href=&#34;https://developer.aliyun.com/mirror/kubernetes?spm=a2c6h.13651102.0.0.1cd01b116JYQIn&#34;&gt;https://developer.aliyun.com/mirror/kubernetes?spm=a2c6h.13651102.0.0.1cd01b116JYQIn&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat &amp;lt;&amp;lt;EOF | tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/
enabled=1
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.28/rpm/repodata/repomd.xml.key
EOF
setenforce 0
yum install -y --nogpgcheck kubelet kubeadm kubectl
systemctl enable kubelet &amp;amp;&amp;amp; systemctl start kubelet
echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;4-2-建立-k8s-yum-缓存&#34;&gt;4.2. 建立 k8s YUM 缓存&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;所有节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 ~]# yum makecache
alinux3-os                                                                                       1.3 MB/s | 3.8 kB     00:00    
alinux3-updates                                                                                  1.4 MB/s | 4.1 kB     00:00    
alinux3-module                                                                                   354 kB/s | 4.2 kB     00:00    
alinux3-plus                                                                                     645 kB/s | 3.0 kB     00:00    
alinux3-powertools                                                                               598 kB/s | 3.0 kB     00:00    
Extra Packages for Enterprise Linux 8 - x86_64                                                   1.8 MB/s | 4.4 kB     00:00    
Extra Packages for Enterprise Linux Modular 8 - x86_64                                           620 kB/s | 3.0 kB     00:00    
Kubernetes                                                                                        17 kB/s | 1.7 kB     00:00    
Metadata cache created.
[root@k8s-master1 ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;4-3-安装-k8s-相关工具&#34;&gt;4.3. 安装 k8s 相关工具&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;所有节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 ~]# yum list kubelet --showduplicates
Last metadata expiration check: 0:01:46 ago on Wed 15 Jan 2025 10:55:44 PM CST.
Installed Packages
kubelet.x86_64                                           1.28.15-150500.1.1                                           @kubernetes
Available Packages
kubelet.aarch64                                          1.28.0-150500.1.1                                            kubernetes 
kubelet.ppc64le                                          1.28.0-150500.1.1                                            kubernetes 
kubelet.s390x                                            1.28.0-150500.1.1                                            kubernetes 
kubelet.src                                              1.28.0-150500.1.1                                            kubernetes 
kubelet.x86_64                                           1.28.0-150500.1.1                                            kubernetes 
kubelet.aarch64                                          1.28.1-150500.1.1                                            kubernetes 
kubelet.ppc64le                                          1.28.1-150500.1.1                                            kubernetes 
kubelet.s390x                                            1.28.1-150500.1.1                                            kubernetes 
kubelet.src                                              1.28.1-150500.1.1                                            kubernetes 
.....
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;设置crictl连接 containerd&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ crictl config --set runtime-endpoint=unix:///run/containerd/containerd.sock
$ crictl images ls
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;设置kubectl命令自动补全：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &#39;source &amp;lt;(kubectl completion bash)&#39; &amp;gt;&amp;gt; ~/.bashrc
source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;5-master节点&#34;&gt;5. master节点&lt;/h1&gt;

&lt;h2 id=&#34;5-1-k8s-初始化&#34;&gt;5.1. k8s 初始化&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Master 节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：记得修改&amp;ndash;apiserver-advertise-address与&amp;ndash;kubernetes-version修改正确。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@k8s-master ~]# kubeadm init \
  --apiserver-advertise-address=172.17.197.69 \
  --image-repository registry.aliyuncs.com/google_containers \
  --kubernetes-version v1.28.15 \
  --service-cidr=10.96.0.0/12 \
  --pod-network-cidr=10.244.0.0/16 \
  --ignore-preflight-errors=all \
  --cri-socket /var/run/containerd/containerd.sock
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参数说明：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;   --apiserver-advertise-address  # 集群master地址
   --image-repository             # 指定k8s镜像仓库地址
   --kubernetes-version           # 指定K8s版本（与kubeadm、kubelet版本保持一致）
   --service-cidr                 # Pod统一访问入口
   --pod-network-cidr             # Pod网络（与CNI网络保持一致）
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;初始化后输出如下内容，说明成功。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;.....
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &amp;quot;kubectl apply -f [podnetwork].yaml&amp;quot; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 172.17.197.69:6443 --token ipqfom.r9ltq4t3in53cd6w \
        --discovery-token-ca-cert-hash sha256:0f01242802eae4b69408c34070a3ad8d017229faba9f8b30623ed1e9dd69d66c 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;5-2-根据输出提示创建相关文件&#34;&gt;5.2. 根据输出提示创建相关文件&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;master节点上执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master ~]# mkdir -p $HOME/.kube
[root@k8s-master ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
[root@k8s-master ~]# chown $(id -u):$(id -g) $HOME/.kube/config
[root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;5-3-查看-k8s-运行的容器&#34;&gt;5.3. 查看 k8s 运行的容器&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;master节点上执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 ~]# kubectl  get pod -A -o wide
NAMESPACE     NAME                                  READY   STATUS    RESTARTS   AGE   IP              NODE          NOMINATED NODE   READINESS GATES
kube-system   coredns-66f779496c-lq5rj              0/1     Pending   0          26m   &amp;lt;none&amp;gt;          &amp;lt;none&amp;gt;        &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
kube-system   coredns-66f779496c-q5pxk              0/1     Pending   0          26m   &amp;lt;none&amp;gt;          &amp;lt;none&amp;gt;        &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
kube-system   etcd-k8s-master1                      1/1     Running   1          26m   172.17.197.69   k8s-master1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
kube-system   kube-apiserver-k8s-master1            1/1     Running   1          26m   172.17.197.69   k8s-master1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
kube-system   kube-controller-manager-k8s-master1   1/1     Running   1          26m   172.17.197.69   k8s-master1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
kube-system   kube-proxy-88trd                      1/1     Running   0          26m   172.17.197.69   k8s-master1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
kube-system   kube-scheduler-k8s-master1            1/1     Running   1          26m   172.17.197.69   k8s-master1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@k8s-master1 ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;5-4-查看-k8s-节点&#34;&gt;5.4. 查看 k8s 节点&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;master节点上执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@k8s-master1 ~]# kubectl  get node -o wide
NAME          STATUS     ROLES           AGE   VERSION    INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                                              KERNEL-VERSION           CONTAINER-RUNTIME
k8s-master1   NotReady   control-plane   36m   v1.28.15   172.17.197.69   &amp;lt;none&amp;gt;        Alibaba Cloud Linux 3.2104 U11 (OpenAnolis Edition)   5.10.134-18.al8.x86_64   containerd://1.6.32
[root@k8s-master1 ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可看到当前只有 k8s-master 节点，而且状态是 NotReady（未就绪），因为我们还没有部署网络插件（kubectl apply -f [podnetwork].yaml），于是接着部署容器网络（CNI）。&lt;/p&gt;

&lt;h2 id=&#34;5-5-容器网络-cni-部署&#34;&gt;5.5. 容器网络（CNI）部署&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Master 节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;插件地址：&lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/addons/&#34;&gt;https://kubernetes.io/docs/concepts/cluster-administration/addons/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;该地址在 k8s-master 初始化成功时打印出来。&lt;/p&gt;

&lt;h3 id=&#34;5-5-1-选择一个主流的容器网络插件部署-calico&#34;&gt;5.5.1. 选择一个主流的容器网络插件部署（Calico）&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-15-kubeadm-install-k8s/IMG_20250116-164005909.png&#34; alt=&#34;picture 4&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;5-5-2-下载yml文件&#34;&gt;5.5.2. 下载yml文件&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget https://docs.projectcalico.org/manifests/calico.yaml --no-check-certificate 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-5-3-看看该yaml文件所需要启动的容器&#34;&gt;5.5.3. 看看该yaml文件所需要启动的容器&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 install-k8s-cluster]# cat calico.yaml |grep image
          image: docker.io/calico/cni:v3.25.0
          imagePullPolicy: IfNotPresent
          image: docker.io/calico/cni:v3.25.0
          imagePullPolicy: IfNotPresent
          image: docker.io/calico/node:v3.25.0
          imagePullPolicy: IfNotPresent
          image: docker.io/calico/node:v3.25.0
          imagePullPolicy: IfNotPresent
          image: docker.io/calico/kube-controllers:v3.25.0
          imagePullPolicy: IfNotPresent
[root@k8s-master1 install-k8s-cluster]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-5-4-修改为国内可下载镜像&#34;&gt;5.5.4. 修改为国内可下载镜像&lt;/h3&gt;

&lt;p&gt;使用docker.m.daocloud.io代替docker.io&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sed -i s/docker.io/docker.m.daocloud.io/g calico.yaml 
$ cat calico.yaml | grep image

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-15-kubeadm-install-k8s/IMG_20250116-205457826.png&#34; alt=&#34;picture 5&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;5-5-5-安装calico&#34;&gt;5.5.5. 安装calico&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 calicodir]# kubectl  apply -f calico.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-15-kubeadm-install-k8s/IMG_20250116-205731350.png&#34; alt=&#34;picture 6&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;5-5-6-查看pod和node状态正常&#34;&gt;5.5.6. 查看pod和node状态正常&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 calicodir]# kubectl  get pod -A
[root@k8s-master1 calicodir]# kubectl  get node
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-15-kubeadm-install-k8s/IMG_20250116-210017047.png&#34; alt=&#34;picture 7&#34; /&gt;&lt;br /&gt;
可以看出pod已全部Running， node已变成Ready状态，说明master节点已安装成功完成。&lt;/p&gt;

&lt;h1 id=&#34;6-worker-节点&#34;&gt;6. worker 节点&lt;/h1&gt;

&lt;h2 id=&#34;6-1-worker-节点加入-k8s-集群&#34;&gt;6.1. worker 节点加入 k8s 集群&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;所有 work 节点执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;复制k8s-master初始化屏幕输出的语句并在work节点执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;root@k8s-worker1 ~]# kubeadm join 172.17.197.69:6443 --token ipqfom.r9ltq4t3in53cd6w         --discovery-token-ca-cert-hash sha256:0f01242802eae4b69408c34070a3ad8d017229faba9f8b30623ed1e9dd69d66c
[preflight] Running pre-flight checks
        [WARNING FileExisting-tc]: tc not found in system path
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -o yaml&#39;
[kubelet-start] Writing kubelet configuration to file &amp;quot;/var/lib/kubelet/config.yaml&amp;quot;
[kubelet-start] Writing kubelet environment file with flags to file &amp;quot;/var/lib/kubelet/kubeadm-flags.env&amp;quot;
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run &#39;kubectl get nodes&#39; on the control-plane to see this node join the cluster.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;6-2-查询集群信息&#34;&gt;6.2. 查询集群信息&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Master节点上执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 calicodir]# kubectl  get pod -A -o wide
[root@k8s-master1 calicodir]# kubectl  get node -o wide
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-15-kubeadm-install-k8s/IMG_20250116-213420388.png&#34; alt=&#34;picture 8&#34; /&gt;&lt;/p&gt;

&lt;p&gt;查看crictl和ctr是否安装成功。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 calicodir]# crictl version
[root@k8s-master1 calicodir]# ctr version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;post/2024/images/2024-01-15-kubeadm-install-k8s/IMG_20250116-213647229.png&#34; alt=&#34;picture 9&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;7-验证&#34;&gt;7. 验证&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Master节点上执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;k8s 集群部署 nginx 服务，并通过浏览器进行访问验证。&lt;/p&gt;

&lt;h2 id=&#34;7-1-创建pod&#34;&gt;7.1. 创建Pod&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 calicodir]# kubectl create deployment nginx --image=docker.m.daocloud.io/library/nginx:latest
deployment.apps/nginx created
[root@k8s-master1 calicodir]# kubectl expose deployment nginx --port=80 --type=NodePort
service/nginx exposed
[root@k8s-master1 calicodir]# kubectl  get all
NAME                        READY   STATUS    RESTARTS   AGE
pod/nginx-fbf584587-pp6ks   1/1     Running   0          2m45s

NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
service/kubernetes   ClusterIP   10.96.0.1       &amp;lt;none&amp;gt;        443/TCP        5h45m
service/nginx        NodePort    10.110.34.104   &amp;lt;none&amp;gt;        80:30884/TCP   28s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx   1/1     1            1           2m45s

NAME                              DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-fbf584587   1         1         1       2m45s
[root@k8s-master1 calicodir]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;7-2-访问nginx&#34;&gt;7.2. 访问nginx&lt;/h2&gt;

&lt;h3 id=&#34;7-2-1-curl访问&#34;&gt;7.2.1. curl访问&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@k8s-master1 calicodir]# curl 10.110.34.104:80
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&amp;lt;style&amp;gt;
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
&amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;p&amp;gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&amp;lt;/p&amp;gt;

&amp;lt;p&amp;gt;For online documentation and support please refer to
&amp;lt;a href=&amp;quot;http://nginx.org/&amp;quot;&amp;gt;nginx.org&amp;lt;/a&amp;gt;.&amp;lt;br/&amp;gt;
Commercial support is available at
&amp;lt;a href=&amp;quot;http://nginx.com/&amp;quot;&amp;gt;nginx.com&amp;lt;/a&amp;gt;.&amp;lt;/p&amp;gt;

&amp;lt;p&amp;gt;&amp;lt;em&amp;gt;Thank you for using nginx.&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
[root@k8s-master1 calicodir]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用nodePort方式访问现象同上
&lt;img src=&#34;post/2024/images/2024-01-15-kubeadm-install-k8s/IMG_20250116-220403508.png&#34; alt=&#34;picture 10&#34; /&gt;&lt;/p&gt;

&lt;p&gt;至此：kubeadm方式的k8s集群已经部署完成。&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>如何安装使用newbing和chatgpt</title>
            <link>http://mospany.github.io/2023/06/23/how-about-install-newbing-and-chatgpt/</link>
            <pubDate>Fri, 23 Jun 2023 17:36:37 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2023/06/23/how-about-install-newbing-and-chatgpt/</guid>
            <description>

&lt;p&gt;&lt;a id=&#34;org5c16ff5&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;简介&#34;&gt;简介&lt;/h1&gt;

&lt;p&gt;chatgpt在2022年开始爆发，随着越来越多的人在使用，于是也打算尝试安装使用。&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;org53977af&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;chatgpt&#34;&gt;chatgpt&lt;/h2&gt;

&lt;p&gt;ChatGPT是一种基于人工智能技术的聊天机器人，它可以与用户进行自然语言交互，回答用户的问题，提供有用的信息和建议，甚至玩一些有趣的游戏。ChatGPT是由OpenAI开发，使用了GPT（Generative Pre-trained Transformer）技术，这是一种具有强大生成能力的神经网络模型。ChatGPT通过学习海量的语言数据集来不断提高其对自然语言的理解能力，从而能够更好地理解和回答用户的问题。与其他聊天机器人相比，ChatGPT的对话流畅度和回答准确度都很高，因此备受用户欢迎。&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;org292f1ea&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;newbing&#34;&gt;newbing&lt;/h2&gt;

&lt;p&gt;必应chat是微软旗下的聊天机器人服务，它是基于必应AI开发的一款智能对话系统。必应chat可以理解自然语言，能够回答用户的问题、提供服务、开玩笑等，使得用户可以与机器人进行自然的对话。必应chat的功能包括天气查询、地图导航、音乐播放、闲聊聊天、计算数学问题等，可帮助用户解决生活中的各种疑问和问题。必应chat还支持多种语言，包括英语、中文、西班牙语、法语、德语等。使用必应chat，您可以轻松地与机器人进行互动，获得便捷的服务和娱乐体验。&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;org79da4ca&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;安装&#34;&gt;安装&lt;/h1&gt;

&lt;p&gt;&lt;a id=&#34;org8197e6e&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;科学上网&#34;&gt;科学上网&lt;/h2&gt;

&lt;p&gt;&lt;a id=&#34;org9014292&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;自由鲸&#34;&gt;自由鲸&lt;/h3&gt;

&lt;p&gt;自由鲸 FreeWhale 是一家长期走中高端路线的 ShadowsocksR(SSR) 机场，也提供部分 V2Ray 线路，已经稳定运行多年。实际对比下来，它的性价比还是相当高的，线路又多，提供的流量也十分充足，主要推荐的套餐充分考虑了当前主流用户能够接受的价位，可以说是无可挑剔。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;特点&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;封闭邀请机制&lt;/p&gt;

&lt;p&gt;自由鲸 FreeWhale 需要邀请码才能注册成功，这样的注册机制一定程度确保了服务的稳定性。&lt;/p&gt;

&lt;p&gt;如果需要邀请码，可以使用我的邀请码:&lt;/p&gt;

&lt;p&gt;也可以直接点击我的邀请链接，进入注册。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;套餐便宜&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.mospan.cn/post/img/chatgpt/freewhale.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;使用&lt;/p&gt;

&lt;p&gt;登录地址：&lt;a href=&#34;https://www.freewhale.world/auth/register?code=XXXX&#34;&gt;https://www.freewhale.world/auth/register?code=XXXX&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;选的是512G/360 天的套餐124元，相当于每月10元还算便宜。&lt;/p&gt;

&lt;p&gt;购买成功后将出现一堆节点列表，在用户中心里将出现订阅地址用做vpn客户端的链接信息。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a id=&#34;org9d5fbb8&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;clash&#34;&gt;clash&lt;/h3&gt;

&lt;p&gt;Clash是一款开源的多平台代理软件，支持 Windows、macOS、Linux、Android 等平台。Clash可以运行在本地并代理 HTTP、HTTPS、SOCKS5等协议，同时还支持 SS、V2Ray、Trojan 等协议，可以实现对于许多网站和应用的科学上网。Clash 的特点是支持多种协议，使用方便，功能强大，且更新频繁。Clash的开源代码托管在GitHub上，用户可以参与其开发和改进。&lt;/p&gt;

&lt;p&gt;把freeWhale上面的订阅地址粘贴到clash的配置-&amp;gt;托管配置-&amp;gt;管理里， 配置名称写为xinjieCloud。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.mospan.cn/post/img/chatgpt/clash-face.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;使用科学上网时，查看 ip 地址可能显示在国内，以下是解决办法:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一定挂全局模式 + 支持 OpenAI 的国家（目前中俄等国不支持，推荐北美、日本等国家）；&lt;/li&gt;
&lt;li&gt;一定设置为系统代理 + 手动选择节点(DIRECT), 否则上不了外网。&lt;/li&gt;
&lt;li&gt;上面步骤完成后依然不行的话，就清空浏览器缓存然后重启浏览器或者电脑；或者直接新开一个无痕模式的窗口。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a id=&#34;org208d97c&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;pchat&#34;&gt;Pchat&lt;/h2&gt;

&lt;p&gt;Pchat 是一款可以免费、简单易用的聊天机器人，翻墙后可以使用，不用做任何配置。它包括Pchat free版、Pchat Pro高级版本。&lt;br /&gt;
访问地址为：&lt;a href=&#34;https://www.promptboom.com&#34;&gt;https://www.promptboom.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.mospan.cn/post/img/chatgpt/pchat.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Pchat Free，一个由PromptBoom和OpenAI合作开发的AI助手。&lt;/li&gt;
&lt;li&gt;Pchat Pro，是Pchat免费版的高级版本。相比之下，Pchat免费版提供了基本的聊天功能，而Pchat Pro则包括更多的高级功能，例如语音和视频通话，自定义表情符号等等。此外，Pchat Pro还具有更高的智能和更好的性能，因为它采用了最先进的技术和算法。&lt;br /&gt;
试用期为14天。在试用期结束之前，您可以决定是否购买Pchat Pro的许可证。如果您决定购买，您将获得无限制的访问权限，并可以享受Pchat Pro提供的所有功能。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a id=&#34;org8b69e3f&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;newbing-1&#34;&gt;newBing&lt;/h2&gt;

&lt;p&gt;微软 New Bing 是微软推出的全新搜索引擎，它使用了最新的人工智能技术和自然语言处理技术来提供更好的搜索结果和更智能的搜索体验。它可以帮助用户更快、更准确地找到他们需要的信息，并且能够根据用户的搜索历史和兴趣爱好提供更加个性化的搜索结果。&lt;/p&gt;

&lt;p&gt;1、下载最新/已支持newbing的edge浏览器&lt;/p&gt;

&lt;p&gt;2、设置bing4为默认搜索引擎&lt;br /&gt;
   URL地址写为：&lt;a href=&#34;https://www4.bing.com/search?q=%s&amp;amp;PC=U316&amp;amp;FROM=CHROMN&#34;&gt;https://www4.bing.com/search?q=%s&amp;amp;PC=U316&amp;amp;FROM=CHROMN&lt;/a&gt;&lt;br /&gt;
   &lt;img src=&#34;http://blog.mospan.cn/post/img/chatgpt/bing4-engine.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;3、设置外网DNS&lt;br /&gt;
   选择openDNS&lt;br /&gt;
   &lt;img src=&#34;http://blog.mospan.cn/post/img/chatgpt/select-dns.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;4、禁止和清理cookies&lt;br /&gt;
   禁止保存一些cn.bing.com或c.bing.com的cookies，免得老跳转到国内bing上。&lt;br /&gt;
   &lt;img src=&#34;http://blog.mospan.cn/post/img/chatgpt/forbiden-cookies.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;5、登录&lt;br /&gt;
   新建标签页，把语言设置为非国内地区&lt;br /&gt;
  &lt;img src=&#34;http://blog.mospan.cn/post/img/chatgpt/newbing-index.png&#34; alt=&#34;img&#34; /&gt;&lt;br /&gt;
   登录账号，如我个人账号为: moshengping210@gmail.com&lt;/p&gt;

&lt;p&gt;点击AI，就可以用bingChat了(不太正常，如跳转到国内bing后需清理cookies后重启浏览器)&lt;br /&gt;
&lt;img src=&#34;http://blog.mospan.cn/post/img/chatgpt/newbing.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;org554ec02&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;chatgpt-1&#34;&gt;chatgpt&lt;/h2&gt;

&lt;p&gt;1、申请账号&lt;br /&gt;
   某宝上购买账号&lt;/p&gt;

&lt;p&gt;2、登录官网(需提前科学上网)&lt;br /&gt;
   ChatGPT的官方网址： &lt;a href=&#34;https://chat.openai.com/auth/login&#34;&gt;https://chat.openai.com/auth/login&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;3、查询&lt;br /&gt;
  &lt;img src=&#34;http://blog.mospan.cn/post/img/chatgpt/chatgpt.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;org415b7ac&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;

&lt;p&gt;【01】 &lt;a href=&#34;https://zhuanlan.zhihu.com/p/618495330&#34;&gt;当前最新稳定访问NewBing方法（操作简单）&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>K8S项目实践(06): 动手实现webhook</title>
            <link>http://mospany.github.io/2023/03/05/k8s-webhook-example/</link>
            <pubDate>Sun, 05 Mar 2023 11:32:18 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2023/03/05/k8s-webhook-example/</guid>
            <description>

&lt;p&gt;&lt;a id=&#34;orgabac5c2&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;简介&#34;&gt;简介&lt;/h1&gt;

&lt;p&gt;Webhook就是一种HTTP回调，用于在某种情况下执行某些动作，Webhook不是K8S独有的，很多场景下都可以进行Webhook，比如在提交完代码后调用一个Webhook自动构建docker镜像&lt;/p&gt;

&lt;p&gt;K8S中提供了自定义资源类型和自定义控制器来扩展功能，还提供了动态准入控制，其实就是通过Webhook来实现准入控制，分为两种：验证性质的准入 Webhook （Validating Admission Webhook） 和 修改性质的准入 Webhook （Mutating Admission Webhook）&lt;/p&gt;

&lt;p&gt;Admission Webhook有哪些使用场景？如下&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在资源持久化到ETCD之前进行修改（Mutating Webhook），比如增加init Container或者sidecar Container&lt;/li&gt;
&lt;li&gt;在资源持久化到ETCD之前进行校验（Validating Webhook），不满足条件的资源直接拒绝并给出相应信息&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.mospan.cn/post/img/webhook/webhook.webp&#34;&gt;http://blog.mospan.cn/post/img/webhook/webhook.webp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Webhook可以理解成Java Web开发中的Filter，每个请求都会经过Filter处理，从图中可以看到，先执行的是Mutating Webhook，它可以对资源进行修改，然后执行的是Validating Webhook，它可以拒绝或者接受请求，但是它不能修改请求。&lt;/p&gt;

&lt;p&gt;K8S中有已经实现了的Admission Webhook列表，详情参考每个准入控制器的作用是什么？&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;org5a64fe0&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;示例原理&#34;&gt;示例原理&lt;/h1&gt;

&lt;p&gt;我们以一个简单的Webhook作为例子，该Webhook会在创建Deployment资源的时候检查它是否有相应的标签，如果没有的话，则加上（Mutating Webhook），然后在检验它是否有相应的标签（Validating Webhook），有则创建该Deployment，否则拒绝并给出相应错误提示。&lt;/p&gt;

&lt;p&gt;所有代码都在：&lt;br /&gt;
git@github.com:mospany/admission-webhook-example.git&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;org02043ed&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;验证&#34;&gt;验证&lt;/h1&gt;

&lt;p&gt;&lt;a id=&#34;org122233e&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;编译打包&#34;&gt;编译打包&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;cd admission-webhook-example/v1
DOCKER_USER=mospany bash ./build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;它将生成镜像并上传到docker.io/mospany/admission-webhook-example:v1。&lt;br /&gt;
&lt;img src=&#34;http://blog.mospan.cn/post/img/webhook/build.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;org0aa6c11&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;检查是否开启了动态准入控制&#34;&gt;检查是否开启了动态准入控制&lt;/h2&gt;

&lt;p&gt;查看APIServer是否开启了MutatingAdmissionWebhook和ValidatingAdmissionWebhook&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 获取apiserver pod名字
apiserver_pod_name=`kubectl get --no-headers=true po -n kube-system | grep kube-apiserver | awk &#39;{ print $1 }&#39;`
# 查看api server的启动参数plugin
kubectl get po $apiserver_pod_name -n kube-system -o yaml | grep plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果输出如下，说明已经开启&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- --enable-admission-plugins=NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;否则，需要修改启动参数，请不然直接修改Pod的参数，这样修改不会成功，请修改配置文件/etc/kubernetes/manifests/kube-apiserver.yaml，加上相应的插件参数后保存，APIServer的Pod会监控该文件的变化，然后重新启动。&lt;br /&gt;
&lt;img src=&#34;http://blog.mospan.cn/post/img/webhook/check-apiserver.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;orga56c5e4&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;创建rbac&#34;&gt;创建RBAC&lt;/h2&gt;

&lt;p&gt;由于我们的webhook会对资源进行修改，所以需要单独给一个ServiceAccount，在K8S集群中直接创建即可&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl apply -f deployment/rbac.yaml 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;效果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master deployment]# kubectl apply -f rbac.yaml
serviceaccount/admission-webhook-example-sa unchanged
clusterrole.rbac.authorization.k8s.io/admission-webhook-example-cr unchanged
clusterrolebinding.rbac.authorization.k8s.io/admission-webhook-example-crb unchanged
[root@k8s-master deployment]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;org57c61b3&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;证书认证&#34;&gt;证书认证&lt;/h2&gt;

&lt;p&gt;K8S集群默认是HTTPS通信的，所以APiserver调用webhook的过程也是HTTPS的，所以需要进行证书认证，证书认证相当于是给Service的域名进行认证（Service后面会创建），将Service域名放到认证请求server.csr文件中，然后创建一个K8S证书签署请求资源CertificateSigningRequest，APIServer签署该证书后生成server-cert.pem，再将最初创建的私钥server-key.pem和签署好的证书server-cert.pem放到Secret中供Deployment调用，详细过程看脚本&lt;br /&gt;
webhook-create-signed-cert.sh&lt;/p&gt;

&lt;p&gt;认证很简单，执行该脚本即可，会创建一个名为admission-webhook-example-certs的Secret&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./deployment/webhook-create-signed-cert.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这一步顺便把Service创建了，因为证书是给该Service的域名颁发的&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl apply -f deployment/service.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;org9750af4&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;部署deployment&#34;&gt;部署Deployment&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;kubectl  apply -f deployment.yaml 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;稍等片刻如果有类似如下输出说明Pod已经运行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master deployment]# kubectl  apply -f deployment.yaml
deployment.apps/admission-webhook-example-deployment unchanged
[root@k8s-master deployment]# kubectl  get pod -A -o wide | grep web
default       admission-webhook-example-deployment-7dd75cffb6-24bhg   1/1     Running   2 (13d ago)    57d    10.244.235.217   k8s-master   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@k8s-master deployment]# kubectl  get pod -A  | grep web
default       admission-webhook-example-deployment-7dd75cffb6-24bhg   1/1     Running   2 (13d ago)    57d
[root@k8s-master deployment]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;org7111e46&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;部署validatingwebhook&#34;&gt;部署ValidatingWebhook&lt;/h2&gt;

&lt;p&gt;首先包含一个namespaceSelector，表示此webhook只针对有admission-webhook-example标签的namespace生效，当然也可以去掉&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;namespaceSelector:
   matchLabels:
     admission-webhook-example: enabled
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看编排文件deployment/validatingwebhook.yaml，里面有一个占位符${CA_BUNDLE}&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;clientConfig:
 service:
 name: admission-webhook-example-svc
 namespace: default
 path: &amp;quot;/validate&amp;quot;  # Path是我们自己定义的
 caBundle: ${CA_BUNDLE}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个是什么呢？webhook是APIServer调用的，此时APIServer相当于是一个客服端，webhook是一个服务端，可以对比下平时上网，打开https网站时是谁在验证域名的证书？是内置在浏览器里面的根证书在做验证，所以这里的CA_BUNDLE就类似于APIServer调用webhook的根证书，它去验证webhook证书。&lt;/p&gt;

&lt;p&gt;所以先填充这个CA_BUNDLE后再执行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 填充占位符
cat deployment/validatingwebhook.yaml | ./deployment/webhook-patch-ca-bundle.sh &amp;gt; /tmp/validatingwebhook.yaml

# 部署
kubectl apply -f /tmp/validatingwebhook.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;orge4b820e&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;验证-1&#34;&gt;验证&lt;/h2&gt;

&lt;p&gt;1、给default namespace添加label&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl label namespace default admission-webhook-example=enabled
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2、部署sleep.yaml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl apply -f deployment/sleep.yaml 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;org3ee59df&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;faq&#34;&gt;FAQ&lt;/h1&gt;

&lt;p&gt;&lt;a id=&#34;org896c547&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;error-unable-to-recognize-stdin-no-matches-for-kind-certificatesigningrequest-in-version-certificates-k8s-io-v1beta1&#34;&gt;error: unable to recognize &amp;ldquo;STDIN&amp;rdquo;: no matches for kind &amp;ldquo;CertificateSigningRequest&amp;rdquo; in version &amp;ldquo;certificates.k8s.io/v1beta1&amp;rdquo;&lt;/h2&gt;

&lt;p&gt;当执行`bash webhook-create-signed-cert.sh`时出现如下错误：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;error: unable to recognize &amp;ldquo;STDIN&amp;rdquo;: no matches for kind &amp;ldquo;CertificateSigningRequest&amp;rdquo; in version &amp;ldquo;certificates.k8s.io/v1beta1&amp;rdquo;`&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;需修改webhook-create-signed-cert.sh相关内容为:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# create  server cert/key CSR and  send to k8s API
cat &amp;lt;&amp;lt;EOF | kubectl create -f -
apiVersion: certificates.k8s.io/v1
kind: CertificateSigningRequest
metadata:
  name: ${csrName}
spec:
  groups:
  - system:authenticated
  request: $(cat ${tmpdir}/server.csr | base64 | tr -d &#39;\n&#39;)
  signerName: kubernetes.io/kube-apiserver-client
  usages:
  - digital signature
  - key encipherment
  - client auth
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;详见：&lt;a href=&#34;https://bytemeta.vip/repo/morvencao/kube-sidecar-injector/issues/29&#34;&gt;missing required field &amp;ldquo;signerName&amp;rdquo; #29&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;orga1e1728&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;no-matches-for-kind-validatingwebhookconfiguration-in-version-admissionregistration-k8s-io-v1beta1&#34;&gt;no matches for kind &amp;ldquo;ValidatingWebhookConfiguration&amp;rdquo; in version &amp;ldquo;admissionregistration.k8s.io/v1beta1&amp;rdquo;&lt;/h2&gt;

&lt;p&gt;当执行`kubectl apply -f validatingwebhook.yaml`时出现错误：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;no matches for kind &amp;ldquo;ValidatingWebhookConfiguration&amp;rdquo; in version &amp;ldquo;admissionregistration.k8s.io/v1beta1&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;需改为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;admissionReviewVersions: [&amp;quot;v1&amp;quot;,&amp;quot;v1beta1&amp;quot;]
sideEffects: None
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;详见： &lt;a href=&#34;https://kodekloud.com/community/t/pls-help-me-in-configuring-using-opa-in-minikbe/28428/5&#34;&gt;Pls help me in configuring/using OPA in minikbe&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;orgc3c8eba&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;x509-certificate-specifies-an-incompatible-key-usage&#34;&gt;x509: certificate specifies an incompatible key usage&lt;/h2&gt;

&lt;p&gt;&lt;a id=&#34;orga94e650&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;参考资料&#34;&gt;参考资料&lt;/h1&gt;

&lt;p&gt;【01】&lt;a href=&#34;https://zhuanlan.zhihu.com/p/404764407&#34;&gt;从0到1开发K8S_Webhook最佳实践&lt;/a&gt;]&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>CentOS7 下安装和配置 NFS</title>
            <link>http://mospany.github.io/2023/01/15/aliyun-ecs-install-nfs/</link>
            <pubDate>Sun, 15 Jan 2023 10:44:29 CST</pubDate>
            <author>Mospan</author>
            <guid>http://mospany.github.io/2023/01/15/aliyun-ecs-install-nfs/</guid>
            <description>

&lt;p&gt;&lt;a id=&#34;org629d3e2&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;简介&#34;&gt;简介&lt;/h1&gt;

&lt;p&gt;NFS（Network File System，网络文件系统）是当前主流异构平台共享文件系统之一。主要应用在UNIX环境下。最早是由Sun Microsystems开发，现在能够支持在不同类型的系统之间通过网络进行文件共享，广泛应用在FreeBSD、SCO、Solaris等异构操作系统平台，允许一个系统在网络上与他人共享目录和文件。通过使用NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件，使得每个计算机的节点能够像使用本地资源一样方便地使用网上资源。换言之，NFS可用于不同类型计算机、操作系统、网络架构和传输协议运行环境中的网络文件远程访问和共享。&lt;/p&gt;

&lt;p&gt;NFS的工作原理是使用客户端/服务器架构，由一个客户端程序和服务器程序组成。服务器程序向其他计算机提供对文件系统的访问，其过程称为输出。NFS客户端程序对共享文件系统进行访问时，把它们从NFS服务器中“输送”出来。文件通常以块为单位进行传输。其大小是8KB（虽然它可能会将操作分成更小尺寸的分片）。NFS传输协议用于服务器和客户机之间文件访问和共享的通信，从而使客户机远程地访问保存在存储设备上的数据。&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;org043eb1b&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;服务端搭建&#34;&gt;服务端搭建&lt;/h1&gt;

&lt;p&gt;由于实现CSI需要一个后端存储，Linux提供NFS功能可以免费搭建一个NSC存储功能用来验证。&lt;br /&gt;
搭建办法详见: &lt;a href=&#34;https://www.codeleading.com/article/35162638950/&#34;&gt;阿里云服务器 CentOS7 下安装和配置 NFS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;org31fb10d&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;服务端安装&#34;&gt;服务端安装&lt;/h2&gt;

&lt;p&gt;使用 yum 安装 NFS 安装包。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yum install nfs-utils -y 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;org768e380&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;服务端配置&#34;&gt;服务端配置&lt;/h2&gt;

&lt;p&gt;设置 NFS 服务开机启动&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# systemctl enable rpcbind
[root@k8s-master ~]# systemctl enable nfs
[root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;org79e8e0b&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;配置共享目录&#34;&gt;配置共享目录&lt;/h2&gt;

&lt;p&gt;服务启动之后，我们在服务端配置一个共享目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# mkdir /data
[root@k8s-master ~]# chmod 755 /data
[root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根据这个目录，相应配置导出目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vim /etc/exports
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;添加如下配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/data/     *(rw,sync,no_root_squash,no_all_squash)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;data: 共享目录位置。&lt;br /&gt;
192.168.0.0/24: 客户端 IP 范围，* 代表所有，即没有限制（我在实验中会设置为*）。&lt;br /&gt;
rw: 权限设置，可读可写。&lt;br /&gt;
sync: 同步共享目录。&lt;br /&gt;
no_root_squash: 可以使用 root 授权。&lt;br /&gt;
no_all_squash: 可以使用普通用户授权。&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;orge7422da&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;启动-nfs-服务&#34;&gt;启动 NFS 服务&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# systemctl start rpcbind
[root@k8s-master ~]# systemctl start nfs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;org2db5bbe&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;防火墙需要打开-rpc-bind-和-nfs-的服务&#34;&gt;防火墙需要打开 rpc-bind 和 nfs 的服务&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# firewall-cmd --zone=public --permanent --add-service={rpc-bind,mountd,nfs}
FirewallD is not running
[root@k8s-master ~]# firewall-cmd --reload
FirewallD is not running
[root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;org9febc6e&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;检查&#34;&gt;检查&lt;/h2&gt;

&lt;p&gt;可以检查一下本地的共享目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# showmount -e localhost
Export list for localhost:
/data *
[root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样，服务端就配置好了。&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;orgbfea31c&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;查看端口&#34;&gt;查看端口&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# rpcinfo -p localhost
program vers proto   port  service
 100000    4   tcp    111  portmapper
 100000    3   tcp    111  portmapper
 100000    2   tcp    111  portmapper
 100000    4   udp    111  portmapper
 100000    3   udp    111  portmapper
 100000    2   udp    111  portmapper
 100005    1   udp  20048  mountd
 100005    1   tcp  20048  mountd
 100005    2   udp  20048  mountd
 100024    1   udp  54689  status
 100005    2   tcp  20048  mountd
 100024    1   tcp  46564  status
 100005    3   udp  20048  mountd
 100005    3   tcp  20048  mountd
 100003    3   tcp   2049  nfs
 100003    4   tcp   2049  nfs
 100227    3   tcp   2049  nfs_acl
 100003    3   udp   2049  nfs
 100003    4   udp   2049  nfs
 100227    3   udp   2049  nfs_acl
 100021    1   udp  40110  nlockmgr
 100021    3   udp  40110  nlockmgr
 100021    4   udp  40110  nlockmgr
 100021    1   tcp  33742  nlockmgr
 100021    3   tcp  33742  nlockmgr
 100021    4   tcp  33742  nlockmgr
 [root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;orga16c2a2&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;客户端连接-nfs&#34;&gt;客户端连接 NFS&lt;/h1&gt;

&lt;p&gt;&lt;a id=&#34;orge9dc5a1&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;在客户端创建目录&#34;&gt;在客户端创建目录&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# mkdir -p /mnt/nfs-data/
[root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;orgce10511&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;挂载&#34;&gt;挂载&lt;/h2&gt;

&lt;p&gt;为了测试方便， 服务端和客户端均在同一台服务器上。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# mount -t nfs 127.0.0.1:/data /mnt/nfs-data
[root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;挂载之后，可以使用 mount 命令查看一下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# mount | grep nfs
nfsd on /proc/fs/nfsd type nfsd (rw,relatime)
sunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw,relatime)
127.0.0.1:/data on /mnt/nfs-data type nfs4 (rw,relatime,vers=4.1,rsize=524288,wsize=524288,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=127.0.0.1,local_lock=none,addr=127.0.0.1)
[root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这说明已经挂载成功了。&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;orgc315b27&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;测试nfs&#34;&gt;测试NFS&lt;/h1&gt;

&lt;p&gt;测试一下，在客户端向共享目录创建一个文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# echo test &amp;gt; /mnt/nfs-data/bbb.txt
[root@k8s-master ~]#
[root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后取 NFS 服务端查看一下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# echo test &amp;gt; /mnt/nfs-data/bbb.txt
[root@k8s-master ~]#
[root@k8s-master ~]# cat /data/bbb.txt
test
[root@k8s-master ~]# 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，共享目录已经写入了。&lt;/p&gt;

&lt;p&gt;&lt;a id=&#34;org6f32303&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;客户端自动挂载&#34;&gt;客户端自动挂载&lt;/h1&gt;

&lt;p&gt;自动挂载很常用，客户端设置一下即可。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vim /etc/fstab
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在结尾添加类似如下配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# cat /etc/fstab

 #
 # /etc/fstab
 # Created by anaconda on Thu Jul 11 02:52:01 2019
 #
 # Accessible filesystems, by reference, are maintained under &#39;/dev/disk&#39;
 # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info
 #
 UUID=1114fe9e-2309-4580-b183-d778e6d97397 /                       ext4    defaults        1 1
 127.0.0.1:/data     /mnt/nfs-data                   nfs     defaults        0 0
 [root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于修改了 /etc/fstab，需要重新加载 systemctl。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@k8s-master ~]# systemctl daemon-reload
[root@k8s-master ~]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a id=&#34;org284ecce&#34;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;

&lt;p&gt;【01】&lt;a href=&#34;https://www.codeleading.com/article/35162638950/&#34;&gt;阿里云服务器 CentOS7 下安装和配置 NFS&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
