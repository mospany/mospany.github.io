<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>人工智能 on 墨斯潘園</title>
    <link>http://mospany.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/</link>
    <description>Recent content in 人工智能 on 墨斯潘園</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 27 Jan 2024 19:31:10 +0800</lastBuildDate>
    
	<atom:link href="http://mospany.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>K8S项目实践(11): Pod 是如何使用到 GPU 的及源码分析</title>
      <link>http://mospany.github.io/2024/01/27/pod-use-gpu/</link>
      <pubDate>Sat, 27 Jan 2024 19:31:10 +0800</pubDate>
      
      <guid>http://mospany.github.io/2024/01/27/pod-use-gpu/</guid>
      <description>本文主要分析了在 K8s 中创建一个 Pod 并申请 GPU 资源，最终该 Pod 时怎么能够使用 GPU 的，具体的实现原理，以及 device plugin、nvidia-container</description>
    </item>
    
    <item>
      <title>K8S项目实践(10): device-plugin原理到实现</title>
      <link>http://mospany.github.io/2024/01/24/device-plugin/</link>
      <pubDate>Wed, 24 Jan 2024 19:31:10 +0800</pubDate>
      
      <guid>http://mospany.github.io/2024/01/24/device-plugin/</guid>
      <description>本文主要分析 k8s 中的 device-plugin 机制工作原理，并通过实现一个简单的 device-plugin 来加深理解。 1. 背景 默认情况下，k8s 中的 Pod 只能申请 CPU 和 Memory 这两种资源，就像下面这样： resources:</description>
    </item>
    
    <item>
      <title>K8S项目实践(09): 使用 GPU Operator搭建AI算力环境</title>
      <link>http://mospany.github.io/2024/01/17/gpu-operator/</link>
      <pubDate>Wed, 17 Jan 2024 19:31:10 +0800</pubDate>
      
      <guid>http://mospany.github.io/2024/01/17/gpu-operator/</guid>
      <description>1. 引言 为了学习AI应用、算法与算力等技术，应用需跑在GPU卡上，需要在节点上安装 GPU Driver、Container Toolkit 等组件，当集群规模较大时</description>
    </item>
    
    <item>
      <title>K8S项目实践(08): 在ECS、Docker、K8s 等环境中使用 GPU</title>
      <link>http://mospany.github.io/2024/01/16/gpu-on-k8s/</link>
      <pubDate>Tue, 16 Jan 2024 19:31:10 +0800</pubDate>
      
      <guid>http://mospany.github.io/2024/01/16/gpu-on-k8s/</guid>
      <description>1. 引言 本文主要分享在不同环境，例如ECS、Docker 和 Kubernetes 等环境中如何使用 GPU。 注：由于没有物理机裸机，在阿里云上申请ECS也可满足学习使</description>
    </item>
    
    <item>
      <title>K8S项目实践(07): kubeadm安装k8s集群(containerd版)</title>
      <link>http://mospany.github.io/2024/01/15/kubeadm-install-k8s/</link>
      <pubDate>Mon, 15 Jan 2024 15:42:11 +0800</pubDate>
      
      <guid>http://mospany.github.io/2024/01/15/kubeadm-install-k8s/</guid>
      <description>1. 规划 使用 kubeadm 安装 Kubernetes 集群并使用 containerd 作为容器运行时（container runtime）是一种常见的安装方法。 OS 配置 用途 备注 aliOS(172.17.197.69) 2核(vCPU) 4GiB 5 Mbps</description>
    </item>
    
  </channel>
</rss>