+++
#+OPTIONS: \n:t
categories = ["技术文章"]
date = "2022-11-22T22:42:55+08:00"
description = ""
keywords = ["K8S","云原生"]
tags = ["K8S","云原生"]
title = "K8S项目实践(02): 动手实现minicni"
url = "/2022/11/22/k8s-practice-minicni/"

+++

* 简介
  不管是容器网络还是 Kubernetes 网络都需要解决以下两个核心问题：

  - 容器/Pod IP 地址的管理
  - 容器/Pod 之间的相互通信
  容器/Pod IP 地址的管理包括容器 IP 地址的分配与回收，而容器/Pod 之间的相互通信包括同一主机的容器/Pod 之间和跨主机的容器/Pod 之间通信两种场景。这两个问题也不能完全分开来看，因为不同的解决方案往往要同时考虑以上两点。对于同一主机的容器/Pod 之间的通信来说实现相对容易，实际的挑战在于，不同容器/Pod 完全可能分布在不同的集群节点上，如何实现跨主机节点的通信不是一件容易的事情。

如果不采用 SDN(Software define networking) 方式来修改底层网络设备的配置，主流方案是在主机节点的 underlay 网络平面构建新的 overlay 网络负责传输容器/Pod 之间通信数据。这种网络方案在如何复用原有的 underlay 网络平面也有不同的实现方式：

  - 将容器的数据包封装到原主机网络（underlay 网络平面）的三层或四层数据包中，然后使用主机网络的三层或者四层协议传输到目标主机，目标主机拆包后再转发给目标容器；
  - 把容器网络加到主机路由表中，把主机网络（underlay 网络平面）设备当作容器网关，通过路由规则转发到指定的主机，实现容器的三层互通；

* CNI原理
  CNI 规范相对于 CNM(Container Network Model) 对开发者的约束更少、更开放，不依赖于容器运行时，因此也更简单。关于 CNI 规范的详情请查看[[https://github.com/containernetworking/cni/blob/master/SPEC.md][官方文档]]。

  实现一个 CNI 网络插件只需要一个配置文件和一个可执行文件：

  - 配置文件描述插件的版本、名称、描述等基本信息；
  - 可执行文件会被上层的容器管理平台调用，一个 CNI 可执行文件需要实现将容器加入到网络的 ADD 操作以及将容器从网络中删除的 DEL 操作等；

  Kubernetes 使用 CNI 网络插件的基本工作流程是：

  - kubelet 先创建 pause 容器创建对应的网络命名空间；
  - 根据配置调用具体的 CNI 插件，可以配置成 CNI 插件链来进行链式调用；
  - 当 CNI 插件被调用时，它根据环境变量以及命令行参数来获得网络命名空间、容器的网络设备等必要信息，然后执行 ADD 或者其他操作；
  - CNI 插件给 pause 容器配置正确的网络，pod 中其他的容器都是复用 pause 容器的网络；
  
* 编译部署
** 1、编译
   #+BEGIN_SRC sh
   make build
   make image
   #+END_SRC
    [[http://blog.mospan.cn/post/img/k8s/minicni/make-image-minicni.png]]

    在docker hub里已看到了minicni镜像：
    
    [[http://blog.mospan.cn/post/img/k8s/minicni/docker-hub-minicni.png]]

** 部署
   1、登录已安装好的k8s集群，把之前已存在的cni如(calico)卸载掉再安装minici:
   #+BEGIN_SRC sh
   [root@k8s-master minicni]# kubectl  apply -f minicni.yaml
   clusterrole.rbac.authorization.k8s.io/minicni created
   serviceaccount/minicni created
   clusterrolebinding.rbac.authorization.k8s.io/minicni created
   configmap/minicni-config created
   Warning: spec.template.spec.nodeSelector[beta.kubernetes.io/os]: deprecated since v1.14; use "kubernetes.io/os" instead
   Warning: spec.template.metadata.annotations[scheduler.alpha.kubernetes.io/critical-pod]: non-functional in v1.16+; use the "priorityClassName" field instead
   daemonset.apps/minicni-node created
   [root@k8s-master minicni]#
   
   #+END_SRC

   2、查看minicni部署状态：
   #+BEGIN_SRC sh
   [root@k8s-master minicni]# kubectl get pod -A -o wide
    NAMESPACE     NAME                                       READY   STATUS        RESTARTS        AGE     IP               NODE         NOMINATED NODE   READINESS GATES
    default       nginx-85b98978db-qkd6h                     0/1     Completed     5               4d21h   <none>           k8s-work1    <none>           <none>
    kube-system   calico-kube-controllers-7b8458594b-p2fqj   0/1     Terminating   2               4d12h   <none>           k8s-work2    <none>           <none>
    kube-system   coredns-6d8c4cb4d-ck2x5                    0/1     Completed     7               4d22h   <none>           k8s-master   <none>           <none>
    kube-system   coredns-6d8c4cb4d-mbctj                    0/1     Completed     7               4d22h   <none>           k8s-master   <none>           <none>
    kube-system   etcd-k8s-master                            1/1     Running       8 (8m14s ago)   4d22h   172.25.140.216   k8s-master   <none>           <none>
    kube-system   kube-apiserver-k8s-master                  1/1     Running       8 (8m4s ago)    4d22h   172.25.140.216   k8s-master   <none>           <none>
    kube-system   kube-controller-manager-k8s-master         1/1     Running       8 (8m14s ago)   4d22h   172.25.140.216   k8s-master   <none>           <none>
    kube-system   kube-proxy-dnsjg                           1/1     Running       8 (8m14s ago)   4d21h   172.25.140.215   k8s-work1    <none>           <none>
    kube-system   kube-proxy-r84lg                           1/1     Running       8 (8m14s ago)   4d22h   172.25.140.216   k8s-master   <none>           <none>
    kube-system   kube-proxy-tbkx2                           1/1     Running       7 (8m14s ago)   4d21h   172.25.140.214   k8s-work2    <none>           <none>
    kube-system   kube-scheduler-k8s-master                  1/1     Running       8 (8m14s ago)   4d22h   172.25.140.216   k8s-master   <none>           <none>
    kube-system   minicni-node-8lmxc                         1/1     Running       0               5m17s   172.25.140.214   k8s-work2    <none>           <none>
    kube-system   minicni-node-sgjmg                         1/1     Running       0               5m17s   172.25.140.216   k8s-master   <none>           <none>
    kube-system   minicni-node-xslgx                         1/1     Running       0               5m17s   172.25.140.215   k8s-work1    <none>           <none> 
   #+END_SRC
   可以看出minicni处于Running状态。

   
* 测试
  1、环境准备, 分别给node打上相应的标签
  #+BEGIN_SRC sh
  [root@k8s-master minicni]# k label nodes k8s-master role=master
  node/k8s-master labeled
  [root@k8s-master minicni]# k label nodes k8s-work1 role=worker
  node/k8s-work1 labeled
  [root@k8s-master minicni]# k label nodes k8s-work2 role=worker
  node/k8s-work2 labeled
  
  #+END_SRC
   
  2、分别在 master 与 worker 节点部署 netshoot 与 httpbin：
  #+BEGIN_SRC sh
  [root@k8s-master minicni]# k apply -f test-pods.yaml
  pod/httpbin-master created
  pod/netshoot-master created
  pod/httpbin-worker created
  pod/netshoot-worker created
  [root@k8s-master minicni]#
  
  #+END_SRC

  3、确保所有 pod 都启动并开始运行：
  #+BEGIN_SRC sh
  [root@k8s-master minicni]# k get pod
  NAME                     READY   STATUS              RESTARTS   AGE
  httpbin-master           0/1     ContainerCreating   0          8s
  httpbin-worker           0/1     ContainerCreating   0          8s
  netshoot-master          0/1     ContainerCreating   0          8s
  netshoot-worker          0/1     ContainerCreating   0          8s
  [root@k8s-master minicni]# 
  
  #+END_SRC
  发现状态为ContainerCreating, 查看pod描述报错为:
  #+BEGIN_SRC sh
  Warning  FailedCreatePodSandBox  36s                kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = [failed to set up sandbox container "7cb17eace85729539db7d7af1a4955a353a14eb7ffa96f84c117ee6633b3e2b5" network for pod "httpbin-master": networkPlugin cni failed to set up pod "httpbin-master_default" network: error getting ClusterInformation: connection is unauthorized: Unauthorized, failed to clean up sandbox container "7cb17eace85729539db7d7af1a4955a353a14eb7ffa96f84c117ee6633b3e2b5" network for pod "httpbin-master": networkPlugin cni failed to teardown pod "httpbin-master_default" network: error getting ClusterInformation: connection is unauthorized: Unauthorized]
  
  #+END_SRC 
  如果安装了calico网络插件，需要删除calico:
  #+BEGIN_SRC sh
  kubectl delete -f  <yaml>
  #+END_SRC
  还要去所有节点etc/cni/net.d/目录下 删掉与calico相关的所有配置文件, 然后重启机器。 不然pod起不来，会报错 network: error getting ClusterInformation: connection is unauthorized: Unauthorized . 

  4、最后再查看POD都变成Running状态了
  #+BEGIN_SRC sh
  [root@k8s-master minicni]# k get pod -A -o wide
  NAMESPACE     NAME                                 READY   STATUS    RESTARTS       AGE     IP               NODE         NOMINATED NODE   READINESS GATES
  default       httpbin-master                       1/1     Running   0              20m     10.244.0.4       k8s-master   <none>           <none>
  default       httpbin-worker                       1/1     Running   0              20m     10.244.2.2       k8s-work2    <none>           <none>
  default       netshoot-master                      1/1     Running   0              20m     10.244.0.5       k8s-master   <none>           <none>
  default       netshoot-worker                      1/1     Running   0              20m     10.244.2.3       k8s-work2    <none>           <none>
  default       nginx-85b98978db-2hzc9               1/1     Running   0              50m     10.244.1.2       k8s-work1    <none>           <none>
  kube-system   coredns-6d8c4cb4d-ck2x5              1/1     Running   9 (24h ago)    6d23h   10.244.0.2       k8s-master   <none>           <none>
  kube-system   coredns-6d8c4cb4d-mbctj              1/1     Running   9 (24h ago)    6d23h   10.244.0.3       k8s-master   <none>           <none>
  kube-system   etcd-k8s-master                      1/1     Running   10 (24h ago)   6d23h   172.25.140.216   k8s-master   <none>           <none>
  kube-system   kube-apiserver-k8s-master            1/1     Running   12 (24h ago)   6d23h   172.25.140.216   k8s-master   <none>           <none>
  kube-system   kube-controller-manager-k8s-master   1/1     Running   10 (24h ago)   6d23h   172.25.140.216   k8s-master   <none>           <none>
  kube-system   kube-proxy-dnsjg                     1/1     Running   10 (24h ago)   6d22h   172.25.140.215   k8s-work1    <none>           <none>
  kube-system   kube-proxy-r84lg                     1/1     Running   10 (24h ago)   6d23h   172.25.140.216   k8s-master   <none>           <none>
  kube-system   kube-proxy-tbkx2                     1/1     Running   9 (24h ago)    6d22h   172.25.140.214   k8s-work2    <none>           <none>
  kube-system   kube-scheduler-k8s-master            1/1     Running   10 (24h ago)   6d23h   172.25.140.216   k8s-master   <none>           <none>
  kube-system   minicni-node-5w9fn                   1/1     Running   0              55m     172.25.140.215   k8s-work1    <none>           <none>
  kube-system   minicni-node-jb5cj                   1/1     Running   0              55m     172.25.140.214   k8s-work2    <none>           <none>
  kube-system   minicni-node-kp25h                   1/1     Running   0              55m     172.25.140.216   k8s-master   <none>           <none>
  [root@k8s-master minicni]#
  #+END_SRC

  5、之后测试以下四种网络通信是否正常：

  - pod 到宿主机的通信
  #+BEGIN_SRC sh
  [root@k8s-master minicni]# kubectl exec -ti netshoot-master -- /bin/bash
  bash-5.1# ping 172.25.140.216
  PING 172.25.140.216 (172.25.140.216) 56(84) bytes of data.
  64 bytes from 172.25.140.216: icmp_seq=1 ttl=64 time=0.074 ms
  64 bytes from 172.25.140.216: icmp_seq=2 ttl=64 time=0.035 ms
  64 bytes from 172.25.140.216: icmp_seq=3 ttl=64 time=0.033 ms
  64 bytes from 172.25.140.216: icmp_seq=4 ttl=64 time=0.043 ms
  64 bytes from 172.25.140.216: icmp_seq=5 ttl=64 time=0.048 ms
  ^C
  --- 172.25.140.216 ping statistics ---
  5 packets transmitted, 5 received, 0% packet loss, time 3999ms
  rtt min/avg/max/mdev = 0.033/0.046/0.074/0.014 ms
  bash-5.1# 
  
  #+END_SRC   

  - pod 到其他主机的通信
  #+BEGIN_SRC sh
  
  
  #+END_SRC
  
  


 
   



* FAQ
** cannot find package 编译不过
   当出现如下错误时：
   #+BEGIN_SRC sh
   $ make build
   Building the minicni on amd64...
   cmd/main.go:8:2: cannot find package "github.com/morvencao/minicni/pkg/args" in any of:
   	/usr/local/go/src/github.com/morvencao/minicni/pkg/args (from $GOROOT)
   	/Users/mosp/goget/src/github.com/morvencao/minicni/pkg/args (from $GOPATH)
   cmd/main.go:9:2: cannot find package "github.com/morvencao/minicni/pkg/handler" in any of:
   	/usr/local/go/src/github.com/morvencao/minicni/pkg/handler (from $GOROOT)
   	/Users/mosp/goget/src/github.com/morvencao/minicni/pkg/handler (from $GOPATH)
   make: *** [build] Error 1
   #+END_SRC
   需要把GO111MODULE=on或auto，才能使用Go module功能，可在.bashrc或.zshrc里加上：export GO111MODULE=auto
   详见[[http://www.ay1.cc/article/18635.html][go自动下载所有的依赖包go module使用详解_Golang]]：
   
** build constraints exclude all Go files in
   当出现如下错误时:
   #+BEGIN_SRC sh
   $ make build
   Building the minicni on amd64...
   go build github.com/containernetworking/plugins/pkg/ns: build constraints exclude all Go files in /Users/mosp/goget/pkg/mod/github.com/containernetworking/plugins@v1.1.1/pkg/ns
   make: *** [build] Error 1
      
   #+END_SRC
   需要设置如下两个变量：
   export GOOS=“linux”。即：不能为darwin
   export CGO_ENABLED=“1”。 
   详见：[[https://blog.csdn.net/weixin_42845682/article/details/124568715][build constraints exclude all Go files in xxx/xxx/xxx]]


* 参考资料
  【01】 [[https://blog.csdn.net/u012772803/article/details/113703029][find -print0和xargs -0原理及用法]]]
  【02】 [[https://zhuanlan.zhihu.com/p/411181637][Go语言import分组管理利器: goimports-reviser]]
  【03】 [[https://morven.life/posts/create-your-own-cni-with-golang/][使用 Go 从零开始实现 CNI]]
  【04】[[https://blog.csdn.net/a5534789/article/details/112848404][centOS内网安装kubernetes集群]] 
